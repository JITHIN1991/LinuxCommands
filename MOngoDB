
---------------------------------------------------------------------------------------MongoDB-------------------------------------------------------------------------------------------



 [ UI ] => [ Backend(Server eg.java) (Using Mongodb driver) ]   ======>     [  MongoDB SErver -> Storage Engine -> MongoDB DataBase Storage  ]

wired tiger is the default storage engine




sudo systemctl start mongod

sudo systemctl status mongod

https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/





>MongoDB documnet can have embedded documnet upto 100 levels of nesting

>MongoDB can have arrays of embedded documemt

>MongoDB : arrays can hold any data,integer,string,or embedded document etc

>MongoDB document size limit -  16gb





show dbs - shows all dbs

use <db-name> - selects a db



db.products.find()  - to list all data in a collection ,it always gives us the cursor object through which we can cycle through the result .It doesnt give us the array of all the documents in a collection.Actually it givesthe first 20 documents and we need to type 'it' for the next 20 documents

db.products.find().toArray() - gives all the documents without any cursor


>db.passengersData.find().forEach(data=>{ printjson(data)})  -   prints the whole documents using the forEach method on the cursor returned by the find method


>db.passengersData.find({},{name:1,_id:0}).pretty()  --  prints the documents with only name,This is projection,Where the _id is specified with value 0, for others the default value will be 0(here the name is specified with 1,if it is specified with 0, then the default for others will be 1).We     dont need to specify for other fields if we dont want them in the proejection


>db.products.find().pretty() - to list all data in a collection in a pretty way

>db.flightData.find({intercontinental : true}).pretty()  -  Finds the documents that matches the filter condition

>db.flightData.find({}).pretty()  -   Finds all the documents since the filter condition is {}


>db.flightData.find({distance : {$eq:12000}}).pretty()    -   Finds the documents in which the distance is equal to 12000

>db.flightData.find({distance : {$lt:10000}}).pretty();   -   Finds the documents in which the distance is less than 10000

>db.flightData.find({distance : {$gt:10000}}).pretty();   -   Finds the documents in which the distance is greaterb than 10000


>db.flightData.findOne({distance : {$eq:12000}})    -   Finds the first document in which the distance is equal to 12000

>db.flightData.findOne({distance : {$lt:10000}})   -   Finds the first document in which the distance is less than 10000

>db.flightData.findOne({distance : {$gt:10000}})   -   Finds the first document in which the distance is greaterb than 10000

>db.passengersData.findOne({name:"Gordon Black"}).hobbies  -  gives the element(hobbies) of the document.It should be used with fineOne,not with find

   ( pretty is not supported in findOne()  )

   
 [  db.passengersData.find({hobbies:"Music"}).pretty()  -  here assume the hobbies is an array,it will give the dcuments which have the hobbies array with value Music
   


 [ db.passengersData.find({"address.house":"Mambully"})  ]  -  ACCESSING STRUCTURED DATA : Here assume that the addrss is embedded document which has the field house,it will give the result for the house is "mambully" ,we can drill into further level if it has.


 db.flightData.updateOne({"_id" : ObjectId("623b2f95d5526a384e0e40e8")},{$set:{delayed:true}})   -   update the first document that matches the filter condition
 
  db.flightData.update({"_id" : ObjectId("623b2f95d5526a384e0e40e8")},{$set:{delayed:false}})   -   update the first document that matches the filter condition


=>update and updatemany are almost similar except

   db.flightData.update({"_id":ObjectId("623b2f95d5526a384e0e40e8")},{delayed:true}) -This will work,ie without $set.It will patch the object with this id and delayed field,other fields will be lost

   update will overwrite the existing one
   
   but updateMany will not work like this
   



db.flightData.replaceOne({"distance" : 12000},{
...     "departureAirport": "LHR",
...     "arrivalAirport": "TXL",
...     "aircraft": "Airbus A320",
...     "distance": 950,
...     "intercontinental": false
...   })                               -            Here it will replace the document with the given data,But the nid remains unchanges






db.products.insertOne({name:"A pen",price:20,description:"A nice pen"}) - Insert a new document into a collection

db.flightData.insertMany([
			    {
				"departureAirport": "MUC",
				"arrivalAirport": "SFO",     
				"aircraft": "Airbus A380",     
				"distance": 12000,     
				"intercontinental": true   
			    },
			    {
			       "departureAirport": "LHR",     
			       "arrivalAirport": "TXL",     
			       "aircraft": "Airbus A320",     
			       "distance": 950,     
			       "intercontinental": false   
			    } 
			  ]);



db.flightData.deleteOne({"departureAirport" : "MUC"})    -  Deletes the firts documnet that matches the filter criteria 

db.flightData.deleteMany({"departureAirport" : "MUC"})    - Deletes all the documnets that matches the filter criteria,deletes all if filter condition is {}



db.flightData.updateOne({"distance" : 12000},{$set :{marker:"delete"}})    -   Updates the first document that matches the filter condition and set that specified field(marker) in that documnet as a new filed if its not existing or else it will update the value with "delete"





> db.flightData.updateMany({"distance" : 12000},{$set :{marker:"delete"}})  -- Updates all documents that matches the filter condition and set that specified field(marker) in that documnet as a new filed if its not existing or else it will update the value with "delete"


> db.flightData.updateMany({},{$set :{marker:"delete"}})  -- Updates all documents since the filter condition is {}, set that specified field(marker) in all documnets as a new filed if its not existing or else it will update the value with "delete"







db.passengersData.insert({name:"Jithin",age:29})   -   Inserts data ....what is the differnce between insert and insertOne or insertMany?












db.dropDatabase()   -   To drop a database

db.myCollection.drop()    -   To drop a single collection



                                             >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>SCHEMA AND STRUCTURING<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

MongoDB doesnt enforce the scheam

But we can use schema by structuring the document as we want

 
 >>>>Structuring documents

If we want completely different doc structure for all the document in a collection  we can follow the structuring in a way that all documnets having the different structure(ie, fields) - ITs a kind of chaos!!! Not recommended for practice

If we want the same structure for all the document in a collection with some extra fields in some documents,but there are common fields for all docs - we can follow the structuring ina way that all documnets having the same fields and some extra fields (if there is no value for the extra field,that extra field can be omitted or excluded from the doc)- Middle world approach

If we want the same structure for all the document in acollection  we can follow the structuring ina way that all documnets having the same fields (if there is no value for field,it will be null)- ITs SQLish approach





                                              >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>DATA TYPES<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

-----------TEXT------------

Eg : "Jithin" ,"ABC"  etc

---------BOOLEAN-----------

true or false


----------NUmber-----------
 Integer(32 bit long )  <  NumberLong ( 64bit)  <  NumberDecimal(To store high precision floating point value ,more precise than double)


In the shell,if we enter a normal value it will be treated as a float value,that is bcoz the normal shell as we use it in the  course is based on the javascript.Javascript doesnt differentoate bw integers and float values.Value with decimal place.
So everytjing willbe stored as a 64 bit float value in the shell,that is the default value



----------ObjectId-----------

ObjectId('abcdefghi2g34)  - it uses timestamp for the implementation of id
created automatically
if you create two documnets at the same time ,they will not have the same timestamp


-----------ISODate---------------------Timestamp-----------------

ISODate("2020-09-09") --------- Timestamp(12211122687)


-----------Embedded DOcumnet---------------


------------Arrays----------------


















>db.companies.insertOne({name:"Fresh Apples Inc",isStartUp : true,employees:33,funding:12345678901234567890, details:{ceo:"jithin"},tags:[{title:"Super"},{title:"Perfect"}],foundingDate:new Date(),insertedAt:new Timestamp()})


>db.companies.find().pretty();
{
	"_id" : ObjectId("623d0740bc06d37f12d9785d"),
	"name" : "Fresh Apples Inc",
	"isStartUp" : true,
	"employees" : 33,
	"funding" : 12345678901234567000,   // Not same : bcoz,it was too big number, normal number javascript accepts is a 64 bit floating point value and so that could notbe stored in MongoDB if we want to save long digit number then we should save it as a string
	"details" : {
		"ceo" : "jithin"
	},
	"tags" : [
		{
			"title" : "Super"
		},
		{
			"title" : "Perfect"
		}
	],
	"foundingDate" : ISODate("2022-03-25T00:05:20.383Z"),
	"insertedAt" : Timestamp(1648166720, 1)
}




 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Types & Limits<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
MongoDB has a couple of hard limits - most importantly, a single document in a collection (including all embedded documents it might have) must be <= 16mb. Additionally, you may only have 100 levels of embedded documents.

You can find all limits (in great detail) here: https://docs.mongodb.com/manual/reference/limits/

For the data types, MongoDB supports, you find a detailed overview on this page: https://docs.mongodb.com/manual/reference/bson-types/

Important data type limits are:

Normal integers (int32) can hold a maximum value of +-2,147,483,647

Long integers (int64) can hold a maximum value of +-9,223,372,036,854,775,807

Text can be as long as you want - the limit is the 16mb restriction for the overall document

It's also important to understand the difference between int32 (NumberInt), int64 (NumberLong) and a normal number as you can enter it in the shell. The same goes for a normal double and NumberDecimal.

NumberInt creates a int32 value => NumberInt(55)

NumberLong creates a int64 value => NumberLong(7489729384792)

If you just use a number (e.g. insertOne({a: 1}), this will get added as a normal double into the database. The reason for this is that the shell is based on JS which only knows float/ double values and doesn't differ between integers and floats.

NumberDecimal creates a high-precision double value => NumberDecimal("12.99") => This can be helpful for cases where you need (many) exact decimal places for calculations.

When not working with the shell but a MongoDB driver for your app programming language (e.g. PHP, .NET, Node.js, ...), you can use the driver to create these specific numbers.

Example for Node.js: http://mongodb.github.io/node-mongodb-native/3.1/api/Long.html

This will allow you to build a NumberLong value like this:

const Long = require('mongodb').Long;
 
db.collection('wealth').insert( {
    value: Long.fromString("121949898291")
});
By browsing the API docs for the driver you're using, you'll be able to identify the methods for building int32s, int64s etc.









>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Relations<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

>>>>>One to One Relation - Embedded


patient ---------one to one------>  diseaseSummary


>db.patients.insertOne({name:"Dileep",age:43,diseaseSummary:"disease-sum1"});

>db.diseaseSummary.insertOne({id:"disease-sum1",summary:["cold","fever"]});



Here we need 2 steps to retrieve patients diseasesummary details

1) var diseaseSum = db.patients.findOne().diseaseSummary;

2) db.diseaseSummary.find({id:diseaseSum});

{ "_id" : ObjectId("623d21d5bc06d37f12d9785f"), "id" : "disease-sum1", "summary" : [ "cold", "fever" ] }




If we use emnbedded approach we dont need 2 steps

>db.patients.insertOne({name:"Pradeep",age:44,diseaseSummary:{disease:["cold","headache"]}});

>db.patients.findOne();

{ "_id" : ObjectId("623d23dfbc06d37f12d97862"), "name" : "Pradeep", "age" : 44, "diseaseSummary" : { "disease" : [ "cold", "headache" ] } }




>>>>>>One to one Reference


It depends on the application driven requirement

if we dont want extra data which may cuase the unnecessary object mapping results in delayed response, we can avoid embedded documents,instead we can use the references

If we want to keep necessary data inside a documents,then we can use references for one-to-one relation,ie the link -that is the key take away so we can merge the data if we want to.

NB: ? we can also use different collection so as to avoid one-to-one relation,so that we dont need to  use either embedded or reference




>>>>>>>>>>>One to Many Relation - Embedded


If we use reference for the one to many relation ,the Here we need 2 steps to retrieve patients diseasesummary details

If we use emnbedded approach we dont need 2 steps


>>>>>>>>>>>One to Many Relation - Reference

Depends on the application requirement

for example, city -> citizens relations (one to many)

if we embed the citizen data in city document ,then it will be a huge data

if the city document is referenced in citizen document ,then the relation can be established (so that we can avoid the doc limit of 16 mb)


>>>>>>>>>>>Many to many relation  - Embedded


join table
no need to use join table 

insteas use array of references 

lets say
 customer - product relation
 
 order table is required for this many-to-many relations
 
 
 Instaed of using the order docment
 
 we can use the orders details in the customer document
 
 customer : {
 
	 "id": 12233,
	 "name": "jithin",
	 "age": 29,
	 orders:[
		  {
		  	"productId":1232143124,
		  	"quantity" : 5
		  },
		  {
		  	"productId":1232143434t4,
		  	"quantity" : 3
		  },
		  {
		  	"productId":123214343rf34,
		  	"quantity" : 6
		  }
	 ]
 }
 
Thus we can have the many-many reln by two documents

We can also embed the document


 customer : {
 
	 "id": 12233,
	 "name": "jithin",
	 "age": 29,
	 orders:[
		  {
		  	"title":"A book",
		  	"price":12.50
		  	"quantity" : 5
		  },
		  {
		  	"title":"A Pen",
		  	"price":5
		  	"quantity" : 10
		  }
	 ]
 }

In this approach we can see the duplication,if the same products are repaeted in the orders of other customers too
And if we change the product data in product collection,we also need to change this in the customers document also(There are some cases in which this will become an advantage,like if we change the prodcut price,this change should not be applicable for the previous orders,The prodcut should be availabel at that price,,,,But in other cases like persons age,year etc,as in book-author relation ,these details should be updated,In those cases,the reference approach will be better)


>>>>>>>>>>>>>>>>>>>Many to Many - References

Discussed above
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------










-----------------------------------------------------Relations - Options-----------------------------------------------------------------

>>>>>>>>>>>>>>>>Nested/Embedded Documents

Group data together logically

Great for data that belongs together and is not really overlapping  with other data

Avoid  super - deep  nesting (100+ levels ) or  extremely long arrays(16mb size limit  per document)


>>>>>>>>>>>>>>>>References

Split data across collections

Great for related but shared data as well as  for data  which is used in relations and standalone

Allows you to overcome nesting and size limits (by creating new documents)








--------------------------lookup aggregate method for merging reference relations-----------------------------------------

It is helpful tool allows us to fetch two related documents merged together in one documentin one step instead of having  to do two steps

>db.books.aggregate([{ $lookup:{from: "authors", localField: "authors", foreignField:"_id",as:"creators"} }])

Here we are running aggregate on books collection, and the target collection is authors

from -> from which other colection we want to relate

localField -> the local field name of that relatio keys are storedn(here in book,we have one reference field to authors collections,ie authors ,will be simply an array of object ids)

foreignField -> which field are we relating to in the target collection

as -> as an alias,that means the result of aggregate method will be under this alias name



The result will be like


{

"_id" : ObjectId("fjfbcfiwuehfiwhvskvnuwy83ry83"),
"name" : "My Book",
"authors": [
		ObjectId("657cusygcustcutw8fugvcddf"),
		ObjectId("657cusygcustcutw8fuwer3rt")
	],
	
"creators" : [

		{
			"_id" : ObjectId("657cusygcustcutw8fugvcddf"),
			"name" : "Jithin"
			"age" : 29
		
		},
				{
			"_id" : ObjectId("657cusygcustcutw8fuwer3rt"),
			"name" : "Nithin"
			"age" : 31
		
		}


	]

}




_____________________________________________________________SCHEMA VALIDATION________________________________________________________________________


IN Mongodb we can have schema ,we can restrict the collections to follow certain schema


________________________________validation level________________________________________________________________________validation action______________________________________


_________________________which document get validated?__________________________________________________________what happens if validation fals________________________________


_______________________strict=> All inserts and updates______________________________________________________error=>throw error and deny insert / update_______________________


_____________moderate=> All inserts and updates to correct documents______________________________________________warn=>Log warnign but proceed________________________________



Example=>

Normally if we want ot create a collection,then we simply add the data in a new collection simply by

db.posts.insertOne();

But if we want to add some schema validation we need to use "createCollection" as below 

db.createCollection('posts', {
  validator: {
    $jsonSchema: {
      bsonType: 'object',
      required: ['title', 'text', 'creator', 'comments'],
      properties: {
        title: {
          bsonType: 'string',
          description: 'must be a string and is required'
        },
        text: {
          bsonType: 'string',
          description: 'must be a string and is required'
        },
        creator: {
          bsonType: 'objectId',
          description: 'must be an objectid and is required'
        },
        comments: {
          bsonType: 'array',
          description: 'must be an array and is required',
          items: {
            bsonType: 'object',
            required: ['text', 'author'],
            properties: {
              text: {
                bsonType: 'string',
                description: 'must be a string and is required'
              },
              author: {
                bsonType: 'objectId',
                description: 'must be an objectid and is required'
              }
            }
          }
        }
      }
    }
  }
});



Thus we are defining each field and its expected types  of values






































>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>CRUD OPERATIONS IN MONGODB<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<



__________________________CREATE DOCUMENTS___________________________________________


insertOne()
insertMany()
insert() -> Not recommended to use bcoz it makes confusion on whether we are adding one or many documents

  -So it is error prone
  -it doesnt return the id as it does for insertOne and insertMany

mongo import -> mongoimport -d cars -c carsList --drop --jsonArray


================insertyone =>

								=================insertMany=========================

 db.hobbies.insertMany([{"_id": "sports",name: "Sports"},{"_id": "music",name: "Music"},{"_id": "movie",name: "Movie"}])
 
 if we try to add new documnet with the same id using the insertMany,then we will get error and allthe documents added before the error occured will not be roll backed
 

 saying ,
 MongoBulkWriteError: E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "sports" } 
 Result: BulkWriteResult {
  result: {
    ok: 1,
    writeErrors: [
      WriteError {
        err: {
          index: 0,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "sports" }',
          errInfo: undefined,
          op: { _id: 'sports', name: 'Sports' }
        }
      }
    ],
    writeConcernErrors: [],
    insertedIds: [
      { index: 0, _id: 'sports' },
      { index: 1, _id: 'music' },
      { index: 2, _id: 'movie' }
    ],
    nInserted: 0,
    nUpserted: 0,
    nMatched: 0,
    nModified: 0,
    nRemoved: 0,
    upserted: []
  }
}



This is the default behaviour

we can change this behaviour



{ordered :false }  => it allows the user to specifywhetehr mongdb should performan oredered indsert which is the default



 db.hobbies.insertMany([{"_id": "sports",name: "Sports"},{"_id": "music",name: "Music"},{"_id": "movie",name: "Movie"}],{ordered:false})

we will get the same error but it will add the remainign elements


MongoBulkWriteError: E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "sports" }
Result: BulkWriteResult {
  result: {
    ok: 1,
    writeErrors: [
      WriteError {
        err: {
          index: 0,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "sports" }',
          errInfo: undefined,
          op: { _id: 'sports', name: 'Sports' }
        }
      },
      WriteError {
        err: {
          index: 1,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "music" }',
          errInfo: undefined,
          op: { _id: 'music', name: 'Music' }
        }
      },
      WriteError {
        err: {
          index: 2,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "movie" }',
          errInfo: undefined,
          op: { _id: 'movie', name: 'Movie' }
        }
      }
    ],
    writeConcernErrors: [],
    insertedIds: [
      { index: 0, _id: 'sports' },
      { index: 1, _id: 'music' },
      { index: 2, _id: 'movie' },
      { index: 3, _id: 'cooking' }
    ],
    nInserted: 1,
    nUpserted: 0,
    nMatched: 0,
    nModified: 0,
    nRemoved: 0,
    upserted: []
  }
}
 
 

If yoi see nInserted: 1,1 element is added even we got the error

===========================================Write concern===================================================



There is a second option that we can configure in insrtone and insertmany ,ie write concern

client ->  MongoDB Server(Mongod)    ->      Storage Engine -> 
					        |      ||
					        |      \/
					        |    Memory (First it will write to my,bcoz it is faster than working with disk)
					        |      ||
					        |      \/
                                              ||  Data on DIsk	
						\/
	                      		Jurnal(Todo)
			             
Now you can configure a so-called write concern on all the write operations like insert one with an

additional argument, the write concern argument which is in turn a document where you can set settings

	{w:1,j:undefined}

The w simply means

write

and the number here indicates to how many instances, in case you're using multiple instances on one server,


The J stands for the

journal,

the journal is an additional file which the storage engine manages which is like a To-Do file.

The journal can be kept to then for example save operations that the storage engine needs to-do that have

not been completed yet,

like the write. Now it is aware of the write and that it needs to store that data on disk just by the write

being acknowledged and being there in memory,

it doesn't need to keep a journal for that.

The idea of that journal file which is a real file on the disk is just that it is aware of this
and if the server should go down for some reason or anything else happens, that file is still there

and if you restart the server or if it recovers basically, it can look into that file and see what it

needs to-do

and that is of course a nice back up because the memory might have been wiped by then.

So your write could be lost if it's not written to the journal, if it hasn't been written to the real

data files yet, that is the idea of the journal, it's like a back up to-do list.





{w:1,j:true}

obviously enabling the journal confirmation

means that your writes will take longer because you don't just tell the server about them but you also need

to wait for the server to store that write operation in the journal
but you get higher security that the write also succeeded.

Again this is a decision you have to make depending on your application needs,



db.persons.insertOne({name:"Max",age:"30",hobbies:["Sports","Cooking"]},{writeConcern:{w:0}})
{
  acknowledged: false,
  insertedId: ObjectId("626b881e103e5a4db98f21aa")
}



W : 1 is the default,

it simply means I need to be sure that the server acknowledge this,

you can set this to 0. If you do this, you get back acknowledged false

but if I find everything, you see that Chrissy was inserted.

So you get back a different result, also without an objectID

because it can't give you one, the server hasn't really registered this write yet, you just sent the request

and you immediately return,

you don't wait for a response of this request, so to say.

So the storage engine had no chance to store it in memory and generate that objectId and therefore, you get

back acknowledged false because you sent the request, you don't even know if it reached the server.

This is of course super fast because you don't have to wait for any response here, for any ID generation





=> db.persons.insertOne({name:"Max",age:"30",hobbies:["Sports","Cooking"]},{writeConcern:{w:0,j:true}})

the journal can be set to true,

the default is undefined or false,

so if I set it to false, I have the same result as before.

Now if I change it to McKayla and we set the journal to true now, the output for us does not change and

.

it also was super fast here because everything runs locally

and it's not like the journaling will take four hours but it will have been a little bit slower because

the entry will have been added to the journal and we waited for that journal editing to finish here.

So here, we have higher security because we can also be sure that it ended up in this to do list of the

storage engine which will eventually lead to the writes happen to database files.




=>db.persons.insertOne({name:"Max",age:"30",hobbies:["Sports","Cooking"]},{writeConcern:{w:0,j:true,wtimeout:200}})
=>db.persons.insertOne({name:"Max",age:"30",hobbies:["Sports","Cooking"]},{writeConcern:{w:0,j:true,wtimeout:1}})

This will succeed in local because this is super fast here but it is an option which you can set in case

you get shaky, a shaky connection or speed really matters and your connection is generally good but you

can't rule out that once in a year,

it's kind of shaky and you would then rather have that write fail and you recognize this in your client

application of course because you'll get back an error here too.

So you'll have that write fail and therefore you can try again later but you don't wait unnecessarily




==================================Atomcity in MongoDB===============================


it also succeeded because this is super fast here but it is an option which you can set in case

you get shaky, a shaky connection or speed really matters and your connection is generally good but you

can't rule out that once in a year,

it's kind of shaky and you would then rather have that write fail and you recognize this in your client

application of course because you'll get back an error here too.

So you'll have that write fail and therefore you can try again later but you don't wait unnecessarily





====================================import==============================================


mongo import -> mongoimport  cars.json -d cars -c carsList --drop --jsonArray

d -> database

c -> Collection

jsonArray -> if the cars,json contains an array of documents,then we should use the jsonArray

drop -> if the collection already exist,then drop



mongoimport  tv-shows.json -d movieData -c movies --jsonArray --drop

----------------------------------------------------------------------------------R E A D OPERATION------------------------------------------------------------------------------------

      Access    Apply  Equality/Single
      this      This       Value
    COLLECTION  METHOD    FILTER
        |         |         |
        |         |         |
> db . movies . find( { age : 32 } );
   |                     |     |
   |                     |     |
  Access               Field  Value
  Current
  DATABASE





      Access    Apply    Equality/Single
      this      This         Value
    COLLECTION  METHOD       FILTER
        |         |    _________|____________
        |         |   |                      | 

> db . movies . find( { age : { $gt : 32} } );
   |                     |       |     |
   |                     |       |     | 
  Access               Field     |   Value
  Current                        |
  DATABASE                    Operator






___________________________________________________________________________________________________________________________________________________________________

            Read                                 Update                                  Query Modifiers                                 Aggregation
_____________________________|___________________________________________|_____________________________________________|___________________________________________

   Query & Projection                            Update                                                                         Explained in Aggregation Module

    Query Selectors				   Fields                                D E P R E C A T E D

   Projection Operators                          Arrays





___________________________________________________________________________________________________________________________________________________________________

            TYPE                                 PURPOSE                                  Changes data?                                 Example
_____________________________|___________________________________________|_____________________________________________|___________________________________________

       Query Operator                          Locate Data                                     NO                                          $eq

     Projection Operator                 Modify Data Presentation                              NO                                           $

       Update Operator                 Modify+ Add Additional data                             YES                                         $inc








 Query Selectors      Projection Operators
__________________|___________________________

Comparison                       $
Evaluation                   $elemMatch
Logical                        $meta
Array                         $slice
Element
Comment
GeoSPacial











db.movies.find( { runtime : { $eq : 60 } } )    equivalent to =>  db.movies.find({ runtime : 60 } )

db.movies.find( { runtime : { $lt : 60 } } )   no equivalent to this



-----------------------------------------------------Querying Embedded Fields and arrays


db.movies.find({"rating.average":7.8});

 db.movies.find({"rating.average":{$gt:7}});




For array field,
assume the genre filed is an array like

genre:[
	"Drama",
	"Action",
	"Anime",
	"Horror"
      ]


> db.movies.find({genres:"Drama"}).pretty();

 it will return allthe documents in collection with the array field genre containing the value Drama,even if it has any other fields as well
 
> db.movies.find({genres: ["Drama"]}).pretty();

 it will return allthe documents in collection with the array field genre exactly containing the only value Drama



--------------------------------------$in and $nin



> db.movies.find({runtime:{$in:[30,42]}}).pretty();

returns all the documents that has the runtime value in one of the item in the list [30,42]

> db.movies.find({runtime:{$nin:[30,42]}}).pretty();

returns all the documents that has the runtime value not in one of the item in the list [30,42]





-----------count

count() returns the count of documents

> db.movies.find({runtime:{$in:[30,42]}}).count();




----------------------LOgical operators

OR Operator

> db.movies.find({$or:[{"rating.average":{$lt:5}},{"rating.average":{$gt:9.3}}]}).pretty();


NOR Operator

> db.movies.find({$nor:[{"rating.average":{$lt:5}},{"rating.average":{$gt:9.3}}]}).pretty();


AND Operator

> db.movies.find({$and:[{"rating.average":{$gt:8}},{"genres":"Drama"}]}).count();


 By default mongoDb performs and operation in the filter,So that the following command will yield the same result

> db.movies.find({"rating.average":{$gt:8},"genres":"Drama"}).count();





> db.movies.find({"genres":"Horror","genres":"Drama"}).count();

This may not work as expected in mongodb drivers,bcoz Js doesnt support the same key twice in Object(ie the object will be replaced with {"genres":"Drama"} eventually)

In this case we can use AND instead

> db.movies.find({ $and : [{"genres":"Horror"},{"genres":"Drama"}]}).count();




NOT operator

db.movies.find({runtime:{$not:{$eq:60}}}).count();

is equivalent to

db.movies.find({runtime:{$ne:60}}).count();





$exist operator


db.users.insertMany([
	{
		name: "Max",
		hobbies:[
			{
				title:"Sports",
				frequency:3
			},
			{
				title:"Cooking",
				frequency:6
			}

		],
		phone:9896887587
	},
	{
		name: "Manuel",
		hobbies:[
			{
				title:"Cooking",
				frequency:5
			},
			{
				title:"Cars",
				frequency:2
			}

		],
		phone:"897374982379",
		age:30
	}

])






> db.users.find({age:{$exists:true,$gte:30}}).pretty();

This will return

[
  {
    _id: ObjectId("6271c8b4b8fbeaaf269c1e39"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 }
    ],
    phone: '897374982379',
    age: 30
  }
]


Here $exists will check whether the field exist or not





> db.users.find({age:{$exists:true,$ne:null}}).pretty();

This will also check the null values














db.users.find({phone:{$type:"number"}}).pretty();

This will return the documents with field phone is of type double


db.users.find({phone:{$type:["number","string"]}}).pretty();

This will return the documents with field phone is of type double or String







___________________evaluation_____________

REGEX 

> db.movies.find({summary:"musical"}).pretty();

this will seaech for exact match of summary field


> db.movies.find({summary:{$regex: /musical/}}).pretty();

returns the result where the summarycontains the word "musical" using the regex






EXPRESSION

Expression is useful if you want to compare two fields inside of one document and then find all documents






db.sales.insertMany(
	[	
		{	
			volume:100,
			target:120
		},
		{	
			volume:89,
			target:80
		},
		{	
			volume:200,
			target:180
		}
	]

)



We want to compare the volume and target fields ,for that we can use $expr



> db.sales.find({$expr:{$gt:["$volume","$target"]}}).pretty();

this will return the documents where volume is gt target

[
  { _id: ObjectId("6272a50db8fbeaaf269c1e3b"), volume: 89, target: 80 },
  {
    _id: ObjectId("6272a50db8fbeaaf269c1e3c"),
    volume: 200,
    target: 180
  }
]


Here we should use like "$volume" , "$target"

If we want to refer to the field names, we have to add a dollar sign at the beginning,

this tells mongodb hey please look at the volume field and use the value of that in this expression

and you can't use that in every place in your queries,

it does work on the expression query though and later in the aggregation framework module, you'll find

more places where you can use that.



Here we only find two documents where the volume indeed is higher than the target.

The first document where that was not the case is not included in the results subset and that is of

course super useful because with this dynamic approach, we have an easy time of fetching the data where

some condition within the document is met,

so where two kind of related fields have a certain kind of relation that we check here.









More complex expression.This can be useful

If we wantto implement the following expression

if( (doc.volume >=190 ? doc.volume-10 : doc.volume ) > doc.target  ){

//return the document

return doc;
}

> db.sales.find({$expr: {$gt: [{$cond:{if:{$gte:["$volume",190]},then: {$subtract:["$volume",10]} ,else: "$volume" }},"$target"]}}).pretty();

returns...

[
  { _id: ObjectId("6272a50db8fbeaaf269c1e3b"), volume: 89, target: 80 },
  {
    _id: ObjectId("6272a50db8fbeaaf269c1e3c"),
    volume: 200,
    target: 180
  }
]






____________________________Querying Array







Use the db -> user
it has 2 documents in collection users

user> db.users.find().pretty();
[
  {
    _id: ObjectId("6271c8b4b8fbeaaf269c1e38"),
    name: 'Max',
    hobbies: [
      { title: 'Sports', frequency: 3 },
      { title: 'Cooking', frequency: 6 }
    ],
    phone: 9896887587
  },
  {
    _id: ObjectId("6271c8b4b8fbeaaf269c1e39"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 }
    ],
    phone: '897374982379',
    age: 30
  }
]




> db.users.find({hobbies:"Sports"}).pretty();

This will not return any data

bcoz,the array contains object,so we need to use different filter

Like this

user> db.users.find({hobbies:{title:"Sports",frequency:3}}).pretty();
[
  {
    _id: ObjectId("6271c8b4b8fbeaaf269c1e38"),
    name: 'Max',
    hobbies: [
      { title: 'Sports', frequency: 3 },
      { title: 'Cooking', frequency: 6 }
    ],
    phone: 9896887587
  }
]





Instead of this we can use different approach using the 


user> db.users.find({ "hobbies.title":"Sports"}).pretty();



inside the hobbies array, so we can act as if hobbes would hold just an embedded document and dig into

properties of that embedded document

even though here we got multiple embedded documents in an array but mongodb understands this syntax

and what it will do for this query is it will essentially go through all the elements in hobbies and

for each element, it will dig into the document and compare title to our query value, so to sports.






should keep in mind, that you can use this path embedded approach, not only on directly embedded documents,

so if you have one embedded document in a field but also, if you have an array of embedded documents

and then you can use the same query world with greater than and everything you want as before, you don't

just have to look for equality,






_________________Using Array Query Selectors


$size

db.users.insertOne({name:"Chris",hobbies:["Sports","Cooking","Hiking"]});



 now I want to find all users who have three hobbies which should be just Chris because the

other users have two

and it doesn't matter whether a hobby is an embedded document or just a string,

it's just the amount of items in the hobbies array that matters. To find all users with exactly three

hobbies, I can look into my users with find and now the value for find is that I use hobbies and I'm looking

for a size of three, written like this.



user> db.users.find({hobbies:{$size:3}}).pretty();
[
  {
    _id: ObjectId("6272b32eb8fbeaaf269c1e3d"),
    name: 'Chris',
    hobbies: [ 'Sports', 'Cooking', 'Hiking' ]
  }
]











$all



db.moviestars.find({genre:["action","thriller"]}).pretty();


This will return the document that has the genre exactly as ["action","thriller"]

The order does matter


But what if I don't care about the order? Well then, the all operator can help you. For this,

I simply wrap my array in a document where I use $all as operator and that operator receives

my array then and we also need to close that extra curly brace.




> db.moviestars.find({genre:{ $all : ["action","thriller"]} }).pretty();


What this will do is it will now search genre for these keywords and it will make sure that these items

do have to exist in genre and these items could be numbers, could be embedded documents, could be other arrays

even, doesn't matter

but it ensures that these two elements exist in a genre

but it doesn't care about the order. And therefore now I find both documents even though the order is

different within genre.













$elemMatch



>db.users.find({$and: [{"hobbies.title":"Sports"},{"hobbies.frequency":{$gte:3}}]}).pretty();

this will return the documnents that has hobbies array in which the title= sports and frequency >=3


The thing is with this query, we're basically saying find me all documents where in hobbies,

there is a document at least one document with the title sports and a document with the frequency greater

than or equal to three,

it does not have to be the same document,


so the first part is satisfied and the second part is satisfied with that other element.

Now of course it's not that uncommon that you want to ensure that one and the same element should match

your conditions

and for that, you have the elemMatch operator. So this query

and I'll just count it so that we have it still on page, this query can be replaced with another query

that should do what we want. Instead of and,

we specify our array hobbies and then a value which is a document where we use $elemMatch,






>db.users.find({hobbies: {$elemMatch : { title:"Sports",frequency:{$gte:3} }}}).pretty();







---------------CURSOR


we potentially get back thousands or even millions of documents with find, especially if we have no

condition in there

but even with a condition, you easily have a condition that still meets like 1000 documents or more

depending on the scale of your app.

So you get back all these results and that is very inefficient because all these results have to be

fetched from the database,

they have to be sent over the wire and then they have to be loaded into memory in your client application.

So these are three things that are not optimal because chances are you will not need all thouand documents

at the same time and therefore, find gives you a cursor. A cursor is basically a pointer which has the

query you wrote stored and which can therefore quickly go to the database and say hey, give me the next

batch,





					find()
					  |
					  |
					 \"/
					
				Potentially yields 1000s
				 	or
				 millions of documnets
				 
		Client(Cursor)	 ---------------------->    MongoDB Server DB
			|	 <---------------------	|
			|	  				|
			|______  Request Batch #1 ____________|
			|______ Request Batch #2 _____________|
			|__________ .........  _______________|


cursor approach is

great because it saves resources.

If you have a query that meets 1000 documents, but let's say you have a website where you only display

10 items, let's say 10 products you fetched at a time anyways, then there is no need to load all thousand

results that matched your query right at the start.

Instead you would only fetch the first 10,

display them on the screen and then go ahead and fetch the next 10

when the user navigated to the next page or anything like that. This is the idea behind a cursor,

now we'll find out how to work with a cursor













-----------------------------Applying Cursors


db.movies.find().count() => returns the count


 const dataCursor = db.movies.find();
 
 dataCursor.hasNext() => rreturns true if data present in the cursor
 
 dataCursor.next() => returns the next element
 dataCursor.next() => returns the next element
 dataCursor.next() => returns the next element
 dataCursor.next() => returns the next element
 dataCursor.next() => returns the next element






 const dataCursor = db.movies.find();
dataCursor.forEach(d=>{printjson(d)})

If we use the cursor again after this loop we will get error

> dataCursor.next() 

MongoCursorExhaustedError: Cursor is exhausted







_________________________________Sorting Cursor result________________________________




sort isnot avaialable for fndOne



> db.movies.find().sort({"rating.average":-1}).pretty()

  sort based on the rating. average field in the doc in ascending oreder
  
  
> db.movies.find().sort({"rating.average":-1,runtime:-1}).pretty();

  sort based on the rating. average field in the doc in ascending oreder and runtime field in descending order
  
  


____________________________________Skipping and limiting Cursor Results_____________________________-


movieData> db.movies.find().count();
240
movieData> db.movies.find().skip(200).count();
40
movieData> db.movies.find().skip(200).limit(1).count();
1


So skipping does allow us to move through our data set,

if I skip 100, then we can see the ratings are much higher because we skipped all the bad ones, the 100

bad ones, we skipped them,

now skip is also used on a cursor as you can tell. Now related to skip somehow is the limit function, limit

allows you to limit the amount of elements the cursor should retrieve at a time

and that also means the amount of documents you can then move through with a cursor.

You can limit this to 10 for example,

the interesting thing is if you here add count, you still have 240



db.movies.find().skip(200).limit(1);


it will  skip 200 elements and limit 1 element

we can limit first,or skip first => orderis not important

its very usefulfor pagination 






_________________________Using projection to shape our resultSet__________________________________--



now let's talk about how we can shape the data which we do get back into the form we needed in. Because

in the example of our movies, we have all that data for every document we return, that might simply be too

much data,

not only is it a lot of redundant data that we transfer over the wire

if we don't need it, it also makes it harder for it to work with the data

if we have to manually parse all that. Now with projection, we can control which data is returned.

Let's say we are only interested in the name, the genres, the runtime and the rating and all the rest does

not matter to us. If that is the case, I can write a query here without any criteria,








movieData> db.movies.find({},{name:1,genres:1,runtime:1,rating:1})

[
 {
    _id: ObjectId("626b90a3e561b786bc19b5f4"),
    name: 'Once Upon a Time in Wonderland',
    genres: [ 'Adventure', 'Fantasy' ],
    runtime: 60,
    rating: { average: 6.7 }
  },
  {
    _id: ObjectId("626b90a3e561b786bc19b5f5"),
    name: 'True Blood',
    genres: [ 'Drama', 'Romance', 'Supernatural' ],
    runtime: 60,
    rating: { average: 8 }
  },
  {
    _id: ObjectId("626b90a3e561b786bc19b5f6"),
    name: 'The Last Ship',
    genres: [ 'Drama', 'Action', 'Thriller' ],
    runtime: 60,
    rating: { average: 7.8 }
  }
]


Here id is always included in the document

To remove this ,we need to specify the _id as 0 as shown below

movieData> db.movies.find({},{name:1,genres:1,runtime:1,rating:1,_id:0})


[
 {
    name: 'Once Upon a Time in Wonderland',
    genres: [ 'Adventure', 'Fantasy' ],
    runtime: 60,
    rating: { average: 6.7 }
  },
  {
    name: 'True Blood',
    genres: [ 'Drama', 'Romance', 'Supernatural' ],
    runtime: 60,
    rating: { average: 8 }
  },
  {
    name: 'The Last Ship',
    genres: [ 'Drama', 'Action', 'Thriller' ],
    runtime: 60,
    rating: { average: 7.8 }
  }
]







In the embedded documents ,if we are only interested in only a few fields,then we can explicitly specfy those fields(Assuming that the schedule has other fields as well)

movieData> db.movies.find({},{name:1,genres:1,runtime:1,rating:1,"schedule.time":1,_id:0})

[
  {
    name: 'Once Upon a Time in Wonderland',
    genres: [ 'Adventure', 'Fantasy' ],
    runtime: 60,
    schedule: { time: '20:00' },
    rating: { average: 6.7 }
  },
  {
    name: 'True Blood',
    genres: [ 'Drama', 'Romance', 'Supernatural' ],
    runtime: 60,
    schedule: { time: '21:00' },
    rating: { average: 8 }
  },
  {
    name: 'The Last Ship',
    genres: [ 'Drama', 'Action', 'Thriller' ],
    runtime: 60,
    schedule: { time: '21:00' },
    rating: { average: 7.8 }
  }
]







_____________________________________________-Using Projection in Array_______________________________________

	       Filter  Projection
		  |	  |
db.movies.find({   } , {   })


movieData> db.movies.find({genres:"Drama"},{"genres.$":1})
[
  { _id: ObjectId("626b90a3e561b786bc19b5e3"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e4"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e5"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e7"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e8"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e9"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ea"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5eb"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ec"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ed"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ee"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ef"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f0"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f1"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f2"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f5"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f6"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f7"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f9"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5fa"), genres: [ 'Drama' ] }
]



here, I can use a special syntax and set genres.$ to one.

Now what this means is give me the one genre you found and therefore in my genres, I only have drama

now,

now these items will have more genres than just drama,

I only just fetch the drama,

I only just output that because that might be the only thing I'm interested

but the items behind the scenes will have more data, just as they have other fields too.

They have more genres too but with this syntax, I only find the first match for my query here,

if I had a more complex query for different genres, I would still just find the first match,




> movieData> db.movies.find({ genres: { $all: ["Drama", "Horror"] } }, { "genres.$": 1 })
[
  { _id: ObjectId("626b90a3e561b786bc19b5ec"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ed"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f0"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f1"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f7"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f9"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5fe"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b602"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b62c"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b676"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b67e"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69c"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69e"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69f"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6b1"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6bf"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6ce"), genres: [ 'Horror' ] }
]



might look strange at first,

the reason for this is that all works such that it goes through the arrays and checks for the existence

of drama and horror,

so the first element to me both is well found when horror is confirmed to be in there too and that

is why we output horror because that technically is the first matching element,

drama alone didn't match anything,

the main thing here is that it doesn't return both but only one.

Now sometimes you could also have the case where you want to pull out some items from an array in your

document that are not the items you queried for.









> movieData> db.movies.find({ genres: { $all: ["Drama", "Horror"] } }, { "genres":{ $elemMatch:{$eq: "Horror"}}})
[
  { _id: ObjectId("626b90a3e561b786bc19b5ec"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ed"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f0"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f1"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f7"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f9"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5fe"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b602"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b62c"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b676"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b67e"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69c"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69e"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69f"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6b1"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6bf"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6ce"), genres: [ 'Horror' ] }
]




















_________________________________________Understanding $slice _____________________________________________


> movieData> db.movies.find({ genres: { $all: ["Drama", "Horror"] } }, { name:1,"genres":{$slice:2}})



[
  {
    _id: ObjectId("626b90a3e561b786bc19b6b1"),
    name: 'Being Human',
    genres: [ 'Drama', 'Horror' ]
  },
  {
    _id: ObjectId("626b90a3e561b786bc19b6bf"),
    name: 'The River',
    genres: [ 'Drama', 'Horror' ]
  },
  {
    _id: ObjectId("626b90a3e561b786bc19b6ce"),
    name: 'Ravenswood',
    genres: [ 'Drama', 'Horror' ]
  }
]








Here the array of genres is reduced to 2 elements 



movieData> db.movies.find({ genres: { $all: ["Drama", "Horror"] } }, { name:1,"genres":{$slice:[1,2]}})

Here it will skip the first item in the array and shows thye next two items,(ie 2nd and 3rd elements)








___________________________________________________________________UPDATE DOCUMENT____________________________________________________________________



UpdateOne simply takes the first document that matches your filter criteria and updates that even if

multiple documents would normally match your criteria,

updateMany will take your criteria, your filter and update all documents that match it.










we can use a variety of update operators.

Now you can find all update operators in the official docs in the reference under update operators



update operators,we want to update a field or a couple of fields actually.

Now for that, we use $set

and we saw that earlier in the course already. $set simply takes a document where you describe

some fields that should be changed or added to the existing document,


> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$set:{hobbies:[{title:"Sports",frequency:20},{title:"Cooking",frequency:3}]}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}





so $set does not override the existing values

instead it simply just defines some changes that mongodb evaluates and then if they make sense,

it changes the existing document by adding or overriding these fields. All the existing fields are left

untouched,

they are not removed.

You can remove fields and I'll come to that in this module but by default, it simply just adds or edits

the fields which you specify,

so this is update one.






users> db.users.updateMany({"hobbies.title":"Sports"},{$set:{isSporty:true}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 3,
  modifiedCount: 3,
  upsertedCount: 0
}









__________________Updating multiple fields with $set____________________



users> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$set:{age:40,phone:3847345439}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}










__________________________incrementing and decrementing values___________________________




users> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$inc:{age:1},$set:{phone:2384734543911111}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}


This will increment the age by 1 and set the phone field also




> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$inc:{age:-1}});

This will decrement the age by -1

>>>Updating the same filed using inc and set willnot work

users> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$inc:{age:1},$set:{age:30}});
MongoServerError: Updating the path 'age' would create a conflict at 'age'







__________________________using  min max and mul________________________________________



a scenario you might encounter, that you want to set some field to a certain value but only if it currently

is higher and not if it is lower,



users> db.users.updateOne({name:"Chris"},{$min:{age:35}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}




if the user is alraedy lessthan a value it will not update

users> db.users.updateOne({name:"Chris"},{$min:{age:38}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 0,
  upsertedCount: 0
}




Like wise max will update the value if it is less than the specified value


users> db.users.updateOne({name:"Chris"},{$max:{age:50}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}



$mul will multiply the value


users> db.users.updateOne({name:"Chris"},{$mul:{age:2}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}





_______________________________getting rid of the fields_______________________________




users> db.users.updateMany({isSporty:true},{$set:{phone:null}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 3,
  modifiedCount: 3,
  upsertedCount: 0
}



This will set the field value as null


users> db.users.updateMany({isSporty:true},{$unset:{phone:""}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 3,
  modifiedCount: 3,
  upsertedCount: 0
}

This will drop the field fromthe documents


______________________________Renaming the fields______________________-




users> db.users.updateMany({},{$rename:{age:"totalAge"}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 4,
  modifiedCount: 3,
  upsertedCount: 0
}

This will rename the age field to a new name -> totalAge





_________________________________________Understanding Upsert____________________________________


let's say we want to update some document where we are not sure whether it exists in the collection

or not

beause you have an application where you don't know if the data was saved to the database yet and if

it wasn't saved yet, you now want to create a new document,

if it was, you want to override the existing or update the existing document and that is something you can



Here the user Maria doesnt exist,SO this will not work,ie will not update

users> db.users.updateOne({name:"Maria"},{$set:{age:29,hobbies:[{title:"Good Food",frequency:3}],isSporty:true}})
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 0,
  modifiedCount: 0,
  upsertedCount: 0
}









users> db.users.updateOne({name:"Maria"},{$set:{age:29,hobbies:[{title:"Good Food",frequency:3}],isSporty:true}},{upsert:true})
{
  acknowledged: true,
  insertedId: ObjectId("627f9ad146369aecc5196922"),
  matchedCount: 0,
  modifiedCount: 0,
  upsertedCount: 1
}



update one method and there, there is a nice option you can set which is called upsert and you can set this

to true,

the default is false and you don't need to set the default of course. Now upsert

simply is a combination of the word update and insert and means that if the document does not exist,

it will be created.

So now if I set this to true and I hit enter, you see it actually did not find anything, did not update

anything but it upserted a document with this new ID.

And if I now look into my objects, you see that this document was added

and please note that it even set the name to Maria even though I did not add this in my update one

operation, I filtered for this name

but when I set values, I only set the age, the hobbies and isSporty.







So upsert can be very useful for

working with updates where you don't know if something or if a certain document already exists.









__________________________________________Updating matched array elements____________________________________________



This will update the matched array element(only the matched array elements will be updated,Not the others)

users> db.users.updateMany({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } },{ $set : {"hobbies.$":{title:"Sports",frequency:10}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> 




This will add the new field highFrequency in all the matched array elements,other array elements remains unchanged

users> db.users.updateMany({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } },{ $set : {"hobbies.$.highFrequency":true}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 2,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } });
[
  {
    _id: ObjectId("627e825a03670d27402f6ad8"),
    name: 'Max',
    hobbies: [
      { title: 'Sports', frequency: 10, highFrequency: true },
      { title: 'Cooking', frequency: 6 }
    ],
    isSporty: true
  },
  {
    _id: ObjectId("627e825a03670d27402f6ad9"),
    name: 'Chris',
    hobbies: [
      { title: 'Sports', frequency: 20, highFrequency: true },
      { title: 'Cooking', frequency: 5 }
    ],
    isSporty: true,
    totalAge: 100
  }
]





Here $ sign refers to the matchced array elements(refers to the first match in the array ?)

if we dont use $ it will update the all array elements









___________________________________________Updating all array elements__________________________________________________





This will update the all elements in an array with the matched document




users> db.users.updateMany({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } },{ $set : {"hobbies.$[].highFrequency":true}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 2,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } });
[
  {
    _id: ObjectId("627e825a03670d27402f6ad8"),
    name: 'Max',
    hobbies: [
      { title: 'Sports', frequency: 10, highFrequency: true },
      { title: 'Cooking', frequency: 6, highFrequency: true }
    ],
    isSporty: true
  },
  {
    _id: ObjectId("627e825a03670d27402f6ad9"),
    name: 'Chris',
    hobbies: [
      { title: 'Sports', frequency: 20, highFrequency: true },
      { title: 'Cooking', frequency: 5, highFrequency: true }
    ],
    isSporty: true,
    totalAge: 100
  }
]

















__________________________________________finding and updating specific fields____________________________________________




users> db.users.updateMany({"hobbies.frequency":{$gt:10}},{$set:{"hobbies.$[el].goodFrequency":true}},{arrayFilters:[{"el.frequency":{$gt:10}}]});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({"hobbies.frequency":{$gt:10}}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6ad9"),
    name: 'Chris',
    hobbies: [
      {
        title: 'Sports',
        frequency: 20,
        highFrequency: true,
        goodFrequency: true
      },
      {
        title: 'Cooking',
        frequency: 5,
        highFrequency: true,
        goodFrequency: false
      }
    ],
    isSporty: true,
    totalAge: 100,
    'hobbies:$[]': { frequency: -3 }
  }
]








Here array filters works together with this [el] syntax, here

you can define some conditions by which you want to filter elements and these conditions can even differ

from the first conditions here,

so they don't have to be equal.

You could be looking for something totally different

here like age greater than 30 and then still filter out certain array elements in this array and you could even

do that for multiple arrays because with the el here, you set an identifier for the condition you want

to apply for this update expression here. Now in array filters,

you therefore have an array

of the different filters for the different arrays you might be updating.

There you have multiple documents, one for each filter and then you have to repeat your identifier,

so in my case it's el, if you named this differently which you can,

you have to name it differently here too.

Now for us here, el is one element in hobbies which happens to be an embedded document,

so if I want to include or check some fields, some field in that embedded document, I can use el dot and

then frequency here as an example and then check whether frequency is greater than 2.

With that I'm rebuilding this query up here

but you don't have to do that,

you can have totally different queries here.





____________________________________________Adding new elemnents to array__________________________________________



$push will add one element into the array

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]
users> db.users.updateOne({name:"Manuel"},{$push:{hobbies:{title:"Sports",frequency:"2"}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> 

users> 

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Sports', frequency: '2' }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]



















This will add multiple elements into the array and also have the option to sort the elements before adding


users> db.users.updateOne({name:"Manuel"},{$push:{hobbies:{$each: [ {title:"Good wine",frequency:"2"},{title:"Hiking",frequency:1} ] , $sort:{frequency:-1}  } }});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Good wine', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]






___________________________________Removing elements from array using $pull and $pop__________________________________________



$pop is used when we want to remove the first orlast elements from an array

$pull is used to remove an elements based on the matching condition



users> db.users.updateOne({name:"Manuel"},{$pull:{hobbies:{title:"Good wine"}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> 

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]





























$pop

Removing element from the end

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]
users> db.users.updateOne({name:"Manuel"},{$pop:{hobbies: 1}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]





$pop

Removing element from the beginning



users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]
users> db.users.updateOne({name:"Manuel"},{$pop:{hobbies: -1}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]


















____________________________Understanding $addToSet____________________________________


$push will add elements,it may be duplicate element,But addToSet will not allow duplicates






users> db.users.updateOne({name:"Manuel"},{$push:{hobbies:{title:"Sports",frequency:"2"}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.updateOne({name:"Manuel"},{$addToSet:{hobbies:{title:"Sports",frequency:"2"}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 0,
  upsertedCount: 0
}
users> 

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 },
      { title: 'Sports', frequency: '2' }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]











############################################################# D E L E T E   OPERATION  #############################################################

Delete One

users> db.users.deleteOne({totalAge:{$exists:false},isSporty:true});
{ acknowledged: true, deletedCount: 1 }
users> 



Delete Many

users> db.users.deleteMany({totalAge:{$exists:false},isSporty:true});
{ acknowledged: true, deletedCount: 2 }





_______________________Deleting all Entries in a collection_____________________________

users>db.users.deleteMany({})

it is a filter matching all documents in a collection


To drop a collection

db.users.drop();




db.dropDatabase();








##################################################   I N D E X E S  ############################################################


Retrieving Data Efficiently




Now we'll have a look at indexes in this module and indexes are a feature that can drastically speed

up your queries, though if used incorrectly,

they can also slow down some of your operations.

Now we'll take a look at all of that and the different kinds of queries in this module,











So why would we use an index

and what is index to begin with? An index can speed up our find, update or delete queries,









So all the queries where we are looking for certain documents that should match some criteria.



by default if I don't

have an index on seller set,

mongodb will go ahead and do a so-called collection scan,

now that simply means that mongodb to fulfill this query will go through the entire collection,

look at every single document and see if seller equals Max

and as you can imagine for very large collections with thousands or millions of documents, this can take

a while and we'll see this in practice with an example in a second.

So this is the default approach mongodb takes or the only approach it can take when you have no index




Now you can create an index though, an index is not a replacement for a collection but an addition you

could say,

so you would create an index for the seller key of the products collection here and that index then

exists additionally to the collection and the index is essentially an ordered list of all the values

that are placed or stored in the seller key for all the documents.





					db.products.find({seller:"Max"})
						|
						|
		              ______No Index___|_______________Index of Seller_________IndexSCAN___     [Ordered]				
	Products	      |                                                                Products
         {...}											Seller Index
	 {...}	    	      C																
	 {...}		      O								   "Anna"
         {...}	   	      L	 							   "Chris"
         {...}		      L								   "Manu"
	 {...}		      S     =>  							   "Max"	
	 {...}		      C                         				           "Max"
			      A
			      N  [scan all documents]

	

So it's not an ordered list of the documents, just of the values for the field for which you created that

index


and it's not just an ordered list of the values, of course every value, every item in the index has a

pointer to the full document

it belongs to.

Now this allows mongodb to do a so-called index scan to fulfill this query, which means it sees that

for seller, such an index exists and it therefore simply goes to that seller index and can quickly jump

to the right values because there, unlike for the collection,

it knows that the values are sorted by that key,


So it can very efficiently go through that index and then find the matching products because of that ordering

and because of that pointer, every element in this index has, so mongodb finds the value for this query

and then finds the related documents it can return this,

so it's this direct access that mongodb can use here and that speeds up your queries.








creating such indexes can drastically speed up your queries.

However you also shouldn't overdo it with the indexes because you could of course think well ok I got

my product selection and every product has ID, name, age and hobby

and then I could simply create indexes for all fields and I will have the best performance ever, right?

Because no matter for what I look, I got an index for that.

Well this might speed up your find queries,

that is correct, indexes on all fields would speed up find queries because you can query for every field

efficiently but an index does not come for free,

you will pay some performance cost on inserts because that extra index that has to be maintained needs

to be updated with every insert,




 Therefore,

indexes don't come for free and you really have to find out which indexes makes sense and which indexes

don't








_____________________________________Adding a single fieldindex________________________________











now in order to determine whether an index can help us or to see what mongodb actually does,

mongodb gives us a nice tool that we can use to analyze how it executed the query

and this tool is a simple method we add to our query. Here after you reach out to the collection,

you can add the explain method and then chain your normal query,

explain works for find, update, delete

not for insert,




contactData> db.contacts.explain().find({"dob.age":{$gt:60}});
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { 'dob.age': { '$gt': 60 } },
    queryHash: 'FC9E47D2',
    planCacheKey: 'A5FF588D',
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'COLLSCAN',
      filter: { 'dob.age': { '$gt': 60 } },
      direction: 'forward'
    },
    rejectedPlans: []
  },
  command: {
    find: 'contacts',
    filter: { 'dob.age': { '$gt': 60 } },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}




Here the winnignPlan gives tells how the mongodb searched the query

  winningPlan: {
      stage: 'COLLSCAN',
      filter: { 'dob.age': { '$gt': 60 } },
      direction: 'forward'
    },
    
    
    
    
    
    
    
    
=> this will give the executionTime and details    
    
contactData> db.contacts.explain("executionStats").find({"dob.age":{$gt:60}})
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { 'dob.age': { '$gt': 60 } },
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'COLLSCAN',
      filter: { 'dob.age': { '$gt': 60 } },
      direction: 'forward'
    },
    rejectedPlans: []
  },
  executionStats: {
    executionSuccess: true,
    nReturned: 1222,
    executionTimeMillis: 2,
    totalKeysExamined: 0,
    totalDocsExamined: 5000,
    executionStages: {
      stage: 'COLLSCAN',
      filter: { 'dob.age': { '$gt': 60 } },
      nReturned: 1222,
      executionTimeMillisEstimate: 0,
      works: 5002,
      advanced: 1222,
      needTime: 3779,
      needYield: 0,
      saveState: 5,
      restoreState: 5,
      isEOF: 1,
      direction: 'forward',
      docsExamined: 5000
    }
  },
  command: {
    find: 'contacts',
    filter: { 'dob.age': { '$gt': 60 } },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}




Creating index

contactData> db.contacts.createIndex({"dob.age":1})
dob.age_1


After creating the index,lets use explain

contactData> db.contacts.explain("executionStats").find({"dob.age":{$gt:60}})
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { 'dob.age': { '$gt': 60 } },
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'FETCH',
      inputStage: {
        stage: 'IXSCAN',
        keyPattern: { 'dob.age': 1 },
        indexName: 'dob.age_1',
        isMultiKey: false,
        multiKeyPaths: { 'dob.age': [] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { 'dob.age': [ '(60, inf.0]' ] }
      }
    },
    rejectedPlans: []
  },
  executionStats: {
    executionSuccess: true,
    nReturned: 1222,
    executionTimeMillis: 2,
    totalKeysExamined: 1222,
    totalDocsExamined: 1222,
    executionStages: {
      stage: 'FETCH',
      nReturned: 1222,
      executionTimeMillisEstimate: 0,
      works: 1223,
      advanced: 1222,
      needTime: 0,
      needYield: 0,
      saveState: 1,
      restoreState: 1,
      isEOF: 1,
      docsExamined: 1222,
      alreadyHasObj: 0,
      inputStage: {
        stage: 'IXSCAN',
        nReturned: 1222,
        executionTimeMillisEstimate: 0,
        works: 1223,
        advanced: 1222,
        needTime: 0,
        needYield: 0,
        saveState: 1,
        restoreState: 1,
        isEOF: 1,
        keyPattern: { 'dob.age': 1 },
        indexName: 'dob.age_1',
        isMultiKey: false,
        multiKeyPaths: { 'dob.age': [] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { 'dob.age': [ '(60, inf.0]' ] },
        keysExamined: 1222,
        seeks: 1,
        dupsTested: 0,
        dupsDropped: 0
      }
    }
  },
  command: {
    find: 'contacts',
    filter: { 'dob.age': { '$gt': 60 } },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}


This has reduced the execution time

























--------------------Indexes Behind the Scenes---------------------------

What does createIndex() do in detail?

Whilst we can't really see the index, you can think of the index as a simple list of values + pointers to the original document.

Something like this (for the "age" field):

(29, "address in memory/ collection a1")

(30, "address in memory/ collection a2")

(33, "address in memory/ collection a3")

The documents in the collection would be at the "addresses" a1, a2 and a3. The order does not have to match the order in the index (and most likely, it indeed won't).

The important thing is that the index items are ordered (ascending or descending - depending on how you created the index). createIndex({age: 1}) creates an index with ascending sorting, createIndex({age: -1}) creates one with descending sorting.

MongoDB is now able to quickly find a fitting document when you filter for its age as it has a sorted list. Sorted lists are way quicker to search because you can skip entire ranges (and don't have to look at every single document).

Additionally, sorting (via sort(...)) will also be sped up because you already have a sorted list. Of course this is only true when sorting for the age.





Dropping an index

contactData> db.contacts.dropIndex({"dob.age":1})
{ nIndexesWas: 2, ok: 1 }







________________________________Restriction on Indexes___________________________________________________-

if you return all elements but even for the majority it would be faster because

with a full collection scan, you already have all the documents in memory and then an index doesn't offer you

any more because that just is an extra step.

Instead here we got all the documents in memory,

we would have needed to go to the documents anyways to fetch them from the pointers the index gives

us,

so now we already have them and since we need most of them, this is now faster.

So if you have queries that regularly return the majority or all of your documents, an index will not

really help you there,

it might even slow down the execution

and that is important to keep in mind as a first restriction that you need to know when planning your

queries.

If you have a dataset where your queries typically only return fractions, like 10 or 20 percent or lower

than that of the documents, then indexes will almost certainly always speed it up.

If you've got a lot of queries that give you back all the documents or close to all the documents,

indexes can't do that much work for you and logically, that makes sense because the idea of index is to

quickly let you get to a narrow subset of your document list and not to the majority of that.









_______________________________________Creating compound index_______________________________________


contactData> db.contacts.createIndex({"dob.age":1,gender:1})
dob.age_1_gender_1




and this index will not just have the gender but actually as a first key, let's say I want to look for

dob.age and that sorts this in ascending order too.

Now the order of these two fields here does matter because a compound index simply is an index with

more than one field, like here

we got two fields and this will essentially store one index where each entry in the index is now not on

a single value but two combined values. So it does not create two indexes, that's important,

it creates one index but one index where every element is a well, connected value. So now it will simply

create pairs of ages and genders, so we'll have 30 male, 30 male, 30 female, 31 male, 31 female and so on

in the index list and the order here defines which kind of pairs mongodb creates,


So this is a compound index and this speeds up our queries for requests that are well, going to these

two fields because we have these two in an index. Another query that is sped up by that same index



But the compound index can be used from left to right so to say,

so if you have age and gender in there and the leftmost value as you created the index was age and then

the second value was gender, then you can use this index either for all finds that look just for the age,

so for the left part or left and gender. Gender alone won't work though,

so if I try to look for all males with gender male, you'll see that of course works but it uses a collection

scan and not an index scan because it can't look into that second value standalone



If we query gender alone,That wont work here..It will use collection scan



These are some restrictions you have on compound indexes but compound indexes in general allow you

to speed up queries that use multiple values

if you create a compound index on these multiple values.




_________________________________Using indexes for Sorting_____________________________________________



Now this is another cool feature of indexes, since we have an ordered list of values already, mongodb

can utilize that to quickly give us back the order of documents we need.

Now also important to understand or to know here is that if you are not using indexes and you do a sort

on a large amount of documents, you can actually timeout because mongodb has a threshold of

32 megabytes in memory for sorting

and if you have no index, mongodb will essentially fetch all your documents into memory and do the

sort there

and for large collections and large amounts of fetched documents, this can simply be too much to then

sort.

So sometimes, you also need an index not just to speed up the query which always makes sense but also

to be able to sort at all.



contactData> db.contacts.explain().find({"dob.age":35}).sort({gender:1})
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { 'dob.age': { '$eq': 35 } },
    queryHash: '4E9D85A4',
    planCacheKey: '6398D3CC',
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'FETCH',
      inputStage: {
        stage: 'IXSCAN',
        keyPattern: { 'dob.age': 1, gender: 1 },
        indexName: 'dob.age_1_gender_1',
        isMultiKey: false,
        multiKeyPaths: { 'dob.age': [], gender: [] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { 'dob.age': [ '[35, 35]' ], gender: [ '[MinKey, MaxKey]' ] }
      }
    },
    rejectedPlans: []
  },
  command: {
    find: 'contacts',
    filter: { 'dob.age': 35 },
    sort: { gender: 1 },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}






__________________________Understanding the default indexes____________________________________






contactData> db.contacts.getIndexes()
[
  { v: 2, key: { _id: 1 }, name: '_id_' }, //default index..available for all collections
  {
    v: 2,
    key: { 'dob.age': 1, gender: 1 },
    name: 'dob.age_1_gender_1'
  }
]



the first one is actually one on the ID field and this is a default index mongodb maintains for

you and then come your own indexes but you have this default index out of the box for every collection

you create and therefore this is an index that will always be maintained by mongodb here automatically.

And this means that if you are filtering for ID or sorting by ID which is then the default sort order

or the order by which the documents are fetched, you utilize the index for that at least.

















______________________________________Configuring indexes____________________________________________











_id is a unique index
SImilar;y we can create other unique indexes






contactData> db.contacts.createIndex({email:1},{unique:true})
MongoServerError: Index build failed: 67b9c39e-9f13-4cad-9978-78b5c1b92648: Collection contactData.contacts ( fa92ceda-9522-4928-9e93-d5ee75063109 ) :: caused by :: E11000 duplicate key error collection: contactData.contacts index: email_1 dup key: { email: "abigail.clark@example.com" }
contactData> 

This error occurred bcoz the duplicate email ids exist in the collection


and this is already one advantage of the unique index,

we get such a warning if we want to add it or if we already had it in place and we tried to add a document

with a value that already existed, we would have gotten an error during that insert operation.

So unique indexes can help you as a developer

ensure data consistency and help you avoid duplicate data for fields that you need to have unique,

so the id, _id is unique by default but you have other use cases like maybe that email here

too

and the unique index is a great way for you to not just speed up your find queries but also to guarantee

that you have unique values for that given field in that collection.






______________________________Understanding partial filters_________________________________________________



and of course an index

also eats up size on your disk,

additionally the bigger the index is, well the more performance certain queries will take nonetheless.

So if you know that certain values will not be looked at or only very very rarely and you would be fine

using a collection scan if that happens, you can actually create a partial index where you only add the

values you're regularly going to look at,







contactData> db.contacts.createIndex({"dob.age":1},{partialFilterExpression:{"dob.age":{$gte:50}}})
dob.age_1


a side note,

you can also add this to compound index of course because now here, I will define which field is my interesting

field for narrowing down the set of values I want to add and I will use my dob.age field.

Now you could also use a totally different field by the way,



Lets use the below one

contactData> db.contacts.createIndex({"dob.age":1},{partialFilterExpression:{gender:"male"}})
dob.age_1


But partial indexes would not be used if the filter query is not matching for the index keypatterns

as below


contactData> db.contacts.explain().find({"dob.age":{$gte:60}})  => COLLSCAN



because mongodb saw that yes we were looking for a field that is part of an index but it also

determined that since we say nothing about the gender in our query here, it would be too risky to use

the index for that because the index is a partial index and mongodb as a top priority ensures

that you don't lose any data.

So it does not work in a way of naturally filtering out your result sets,

instead what you have to do to use that index is you also have to filter for the gender here,

Here in this case you should use the condition => gender:"male" in the filter along with the dob.age



contactData> db.contacts.explain().find({"dob.age":{$gte:60},gender:"male"})    => IXSCAN

contactData> db.contacts.explain().find({"dob.age":{$gte:60},gender:"female"})  => COLLSCAN






index. And now you might be asking, ok what's the difference between a partial index and a compound index then

if I have to specify both values here? The difference is that for the partial index, the overall index simply

is smaller,

there really are only the ages of males stored in there,

the female keys are not stored in the index and therefore, the index size is smaller leading to a lower

impact on your hard drive and also your right queries are of course also sped up because if you insert

a new female, that will never have to be added to your index.

So this still makes a lot of sense if you often filter for this combination,

so for the age and then only males,

so then a partial index can make sense if you rarely look for your other result, if you rarely look for

women,

this makes a lot of sense.







_____________________________________Applying the partial index_________________________________________________


contactData> db.users.insertMany([{name:"Max",email:"max@test.com"},{name:"Manu"}])
{
  acknowledged: true,
  insertedIds: {
    '0': ObjectId("628276530d7fc3a282425a37"),
    '1': ObjectId("628276530d7fc3a282425a38")
  }
}
contactData> db.users.createIndex({email:1})
email_1
contactData> db.users.dropIndex({email:1})
{ nIndexesWas: 2, ok: 1 }

contactData> db.users.createIndex({email:1},{unique:true})
email_1







But now let me insert some new document, db users insert one and there, I'll insert Anna

also without an email.








contactData> db.users.insertMany([{name:"Anna"}])
Uncaught:
MongoBulkWriteError: E11000 duplicate key error collection: contactData.users index: email_1 dup key: { email: null }
Result: BulkWriteResult {
  result: {
    ok: 1,
    writeErrors: [
      WriteError {
        err: {
          index: 0,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.users index: email_1 dup key: { email: null }',
          errInfo: undefined,
          op: { name: 'Anna', _id: ObjectId("6282776d0d7fc3a282425a39") }
        }
      }
    ],
    writeConcernErrors: [],
    insertedIds: [ { index: 0, _id: ObjectId("6282776d0d7fc3a282425a39") } ],
    nInserted: 0,
    nUpserted: 0,
    nMatched: 0,
    nModified: 0,
    nRemoved: 0,
    upserted: []
  }
}






 And now I get an error, I get a duplicate key error because that non-existing e-mail

for which I have an index is treated as a duplicate key because now I have a no value, so no value stored

twice.

So that is an interesting behavior but some behavior you just have to be aware of, mongodb treats

nonexisting values still as values in your index, so as a not there value

you could say, as a null value and therefore if you have two documents with no value for an indexed field

and that index is unique, you will get this error.




if we do it  like this ,then t will execute



contactData> db.users.dropIndex({email:1})
{ nIndexesWas: 2, ok: 1 }

contactData> db.users.createIndex({email:1},{unique:true,partialFilterExpression:{email:{$exists:true}}})
email_1
contactData> db.users.insertMany([{name:"Anna"}])
{
  acknowledged: true,
  insertedIds: { '0': ObjectId("628277f90d7fc3a282425a3a") }
}
contactData> 

















contactData> db.users.insertMany([{name:"Anna",email:"aaaa@gmail.com"}])
{
  acknowledged: true,
  insertedIds: { '0': ObjectId("6282784c0d7fc3a282425a3b") }
}
contactData> db.users.insertMany([{name:"Anna",email:"aaaa@gmail.com"}])
Uncaught:
MongoBulkWriteError: E11000 duplicate key error collection: contactData.users index: email_1 dup key: { email: "aaaa@gmail.com" }
Result: BulkWriteResult {
  result: {
    ok: 1,
    writeErrors: [
      WriteError {
        err: {
          index: 0,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.users index: email_1 dup key: { email: "aaaa@gmail.com" }',
          errInfo: undefined,
          op: {
            name: 'Anna',
            email: 'aaaa@gmail.com',
            _id: ObjectId("6282784f0d7fc3a282425a3c")
          }
        }
      }
    ],
    writeConcernErrors: [],
    insertedIds: [ { index: 0, _id: ObjectId("6282784f0d7fc3a282425a3c") } ],
    nInserted: 0,
    nUpserted: 0,
    nMatched: 0,
    nModified: 0,
    nRemoved: 0,
    upserted: []
  }
}






___________________________________________Understanding TTL index____________________________________________________



This is a special feature mongodb offers and that only works on date indexes or on date fields, on other

fields it will just be ignored,

you could add it but it will be ignored

and there I could say every element should be removed after 10 seconds.





contactData> db.sessions.createIndex({createdAt:1},{expireAfterSeconds:10})
createdAt_1
contactData> db.sessions.find()

contactData> db.sessions.insertOne({data:"Check",createdAt:new Date()})
{
  acknowledged: true,
  insertedId: ObjectId("62827b890d7fc3a282425a46")
}
contactData> db.sessions.find()
[
  {
    _id: ObjectId("62827b890d7fc3a282425a46"),
    data: 'Check',
    createdAt: ISODate("2022-05-16T16:27:53.729Z")
  }
]

contactData> db.sessions.find()

contactData> 




After 10 secnds all docs were deleted.

The reason for that is

adding a new element basically triggered mongodb to now re-evaluate the entire collection,

so also the already existing documents and see whether this field which is indexed fulfills this criteria

of only being valid for 10 seconds

and therefore then it also reconsidered the existing documents,

it just doesn't do that right

when you add the index but it does do it whenever you add a new element.

So this can be very useful because it allows you to maintain a collection of documents which destroy

themselves after a certain time span and for a lot of applications,

this can be useful things like for example as I just said, session data for a user of your website

or maybe in an online shop where you want to clear the cart after one day,

so whenever you have a use case where data should clean up itself, you don't need to write a complex

script for that,

you can use a time to live index with that expiry after seconds addition we added in our index.

Important to know here by the way,

you can only use that on single field indexes,

it does not work on compound indexes and as I mentioned, it works on date objects.






__________________________________________Query Diagnosis and Query Planning________________________________________________



						explain()
						    |
						    |
						    |
	 __________________________________________|____________________________________________
	 |                                         |						   |
	 |                                         |                                            |
	 |                                         |                                            |
	 |                                         |                                            |
    "queryPlanner"                           "executionStats"                             "allPlansExecution"
    
    
    
    
    
    
    queryPlanner =>  Show summaryn for executed query
    
    executionStats =>	Show detailed summary for executed Query + winning plan + Possibly Rejected Plan
    
    allPlansExceution =>  Show  Detailed Summary for Executed query + winning plan + winning plan decisions
    
    
    
	 
	 
	 
	 
	 
    					 Efficient queries and Query planning
	 
	
	
	 
	 For determining whether a query is efficient,

it's obviously interesting to look at the milliseconds process time and also compare this to a solution

where you don't use an index, so that you'll also have a look whether index scan really beats a collection

scan which it typically does though

but I did already show you some use cases in cases where you fetch almost everything where the index

scan can be slower

and another important measure is that you compare the number of keys in the index, that is what it means

in the output are examined, how many documents that are examined and how many documents that are returned

and the keys and document should be close together and documents or documents, examine the documents returned

should be closed or documents should be zero so that it looked at zero documents



                                  ---------------------Milliseconds Process Time-------------------------------
                                  
                                  
                                  IXSCAN       ----->     Beats   ----->      COLLSCAN
                                                       
                                                       
                                                       no of keys (in index)
                                            __________ examined
         Should be as close as             |            
         possible or                     <=|            
         no of documents should be 0       |           no of documents__________ 
                                           |__________ examined		   |
                                                       			   |	
                                                       			   |=>  Should be as close as possible or 	
                                                       no of documents _________|    no of dcs should be 0
                                                       returned
                                                       
                                                       
                                                       
                                                       
                                                       
______________________________________________________Understanding covered Query__________________________________________________________


If you have some query where you

can optimize your index for that, to reach that covered query state as it is called because the query

is fully covered by the index, then you will of course have a very efficient query because you skipped

that stage of reaching out to the collection getting the documents

and that obviously speeds up your query,

if you can get this to work, you will have a very fast solution.

Now of course it does not make sense to build tens of indexes just to cover all possible queries because

then you'll have a problem with writing again and so on

but if you have an opportunity and you have a query that you typically run and you only typically return

these two fields, it might be worth storing them in a single field or if it's two fields, to store them

in a compound index so that you can fully cover the query from inside your index.

And this is something very interesting to know, that you can reach that covered query state sometimes

at least.
















_____________________________________________How MongoDB rejects a plan_________________________________________________________________




in ascending order and name,

now please note that the order here is important for compound indexes and if I would have put name

first, this index here wouldn't make much sense because then I would have a single field index or

name

even though the name is the first field in a compound index and you learned from left to right, a compound

index can be used well standalone, so each field can be used standalone from left to right.

So in this case, if age comes first, we can also filter just for age and take advantage of this index, for

name,

we can take advantage of this index because name is only the second value is mapped to the respective

ages and only sorted within the age category,

so if you filtered for just name and you didn't have that index, name could not be supported by index.
















Now what we can see is that we now also have a rejected plan and the rejected plan was to use an

index scan just on the name index, that is the single field name index I created.

Of course it made sense for mongodb to also consider this because we have that name index,

we had a query that included a search for name,

so it made sense to consider that name index

but of course since we have another index which simply fits this query better, this compound index,

mongodb chose to use this one as a winning plan and rejected this one.





















mongodb chose to use this one as a winning plan and rejected this one.

Now this is interesting to know,

the question of course is how exactly does mongodb figure out which plan is better? For this, mongodb

uses an approach where it simply

first of all looks for indexes that could help you with the query at hand,

so in our last lecture and example, we had the name single field index and age and name as a compound index.

Since our query, our find method included a look for name, mongodb automatically derived that

both the name single field index and the age name compound index could be helpful.









Winning Plan Algoritm



so let's say we have three approaches, mongodb then simply let's those approaches race against each

other but not for the full dataset

but it sets a certain winning condition, right now that should be one hundred documents.

So it looks who's the first to find 100 documents and of course one of the approaches will be the fastest

to reach that threshold, mongodb will then basically use that approach for the real query

and of course that would be cumbersome if it would have to do this for every find method, for every

query you send to the database because that obviously costs a little bit of performance.

Therefore mongodb caches

this winning plan for this exact query,

so for exactly the query you send with the fields you were looking for and the values for the fields

you were looking for,

so it caches this plan as the winner plan for this kind of query. And for future queries that are looking

exactly equal, it uses this winning plan, for future queries that look different, that use different values

or different keys,

it will of course race again and find a winning plan for that type of query.

Now of course this cache is not there forever,

it is cleared after a certain amount of inserts or a db restart.

To be precise, instead of being stored forever,

this winning plan is removed from cache after you wrote a certain amount of documents to that collection,

currently there should be one thousand,

so after you added that many documents, mongodb says I don't know if the current winning plan will still

win because the collection changed a lot,

so I should reconsider.

The same happens if you rebuild the index, so if you drop it and recreate it for example,

it also gets deleted if you add other indexes because that new index could be better,

so the cache for indexes or winning plans I should say gets cleared when you add new indexes or when

you restart the mongodb server,

then this also gets reset.

So this is how mongodb derives

the winning plan and how it stores it







__________________________________________________________New Multi Key Indexes_______________________________________________________________










We can create an index using the array key too








contactData> db.contacts.insertOne({name:"Max",hobbies:["Cooking","Sports"],addresses:[{street:"Main Street"},{street:"Second Street"}]})
{
  acknowledged: true,
  insertedId: ObjectId("6283b6f30011ae979359282f")
}
contactData> db.contacts.find().count();
1
contactData> 

contactData> db.contacts.find();
[
  {
    _id: ObjectId("6283b6f30011ae979359282f"),
    name: 'Max',
    hobbies: [ 'Cooking', 'Sports' ],
    addresses: [ { street: 'Main Street' }, { street: 'Second Street' } ]
  }
]
contactData> db.contacts.createIndex({hobbies:1})
hobbies_1
contactData> db.contacts.find({hobbies:"Sports"});
[
  {
    _id: ObjectId("6283b6f30011ae979359282f"),
    name: 'Max',
    hobbies: [ 'Cooking', 'Sports' ],
    addresses: [ { street: 'Main Street' }, { street: 'Second Street' } ]
  }
]
contactData> db.contacts.explain("executionStats").find({hobbies:"Sports"});
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { hobbies: { '$eq': 'Sports' } },
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'FETCH',
      inputStage: {
        stage: 'IXSCAN',
        keyPattern: { hobbies: 1 },
        indexName: 'hobbies_1',
        isMultiKey: true,
        multiKeyPaths: { hobbies: [ 'hobbies' ] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { hobbies: [ '["Sports", "Sports"]' ] }
      }
    },
    rejectedPlans: []
  },
  executionStats: {
    executionSuccess: true,
    nReturned: 1,
    executionTimeMillis: 0,
    totalKeysExamined: 1,
    totalDocsExamined: 1,
    executionStages: {
      stage: 'FETCH',
      nReturned: 1,
      executionTimeMillisEstimate: 0,
      works: 2,
      advanced: 1,
      needTime: 0,
      needYield: 0,
      saveState: 0,
      restoreState: 0,
      isEOF: 1,
      docsExamined: 1,
      alreadyHasObj: 0,
      inputStage: {
        stage: 'IXSCAN',
        nReturned: 1,
        executionTimeMillisEstimate: 0,
        works: 2,
        advanced: 1,
        needTime: 0,
        needYield: 0,
        saveState: 0,
        restoreState: 0,
        isEOF: 1,
        keyPattern: { hobbies: 1 },
        indexName: 'hobbies_1',
        isMultiKey: true,
        multiKeyPaths: { hobbies: [ 'hobbies' ] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { hobbies: [ '["Sports", "Sports"]' ] },
        keysExamined: 1,
        seeks: 1,
        dupsTested: 1,
        dupsDropped: 0
      }
    }
  },
  command: {
    find: 'contacts',
    filter: { hobbies: 'Sports' },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}
contactData> 



Here the isMultiKey is true since its an array











the interesting thing is if I explain this with execution stats, I see that the winning plan was an

index scan and we see that there, isMultiKey is set to true for my hobbies index. Mongodb treats

this as a multikey index because it is an index on an array of values and technically, multikey indexes

are working like normal indexes but they are stored up differently.

What mongodb does is it pulls out all the values in your index key,

so in hobbies in my case here, so it pulls out all the values in the array I stored in there and stores

them as separate elements in an index.

This of course means that multikey indexes for a lot of documents are bigger than single field indexes

because if every document has an array with let's say four values on average and you have a thousand

documents and that array field is what you index, you would store four thousand elements because four

times one thousand.

So this is something to keep in mind,

multikey indexes are possible but typically are also bigger,

doesn't mean you shouldn't use them.

If you typically query for an array and the value in an array,





BUt if we create index for Adresses which contains the array of objects,Then it will be using collscan for the query

contactData> db.contacts.createIndex({addresses:1})
addresses_1
contactData> db.contacts.explain("executionStats").find({"addresses.street":"Second Street"});
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { 'addresses.street': { '$eq': 'Second Street' } },
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'COLLSCAN',
      filter: { 'addresses.street': { '$eq': 'Second Street' } },
      direction: 'forward'
    },
    rejectedPlans: []
  },
  executionStats: {
    executionSuccess: true,
    nReturned: 1,
    executionTimeMillis: 0,
    totalKeysExamined: 0,
    totalDocsExamined: 1,
    executionStages: {
      stage: 'COLLSCAN',
      filter: { 'addresses.street': { '$eq': 'Second Street' } },
      nReturned: 1,
      executionTimeMillisEstimate: 0,
      works: 3,
      advanced: 1,
      needTime: 1,
      needYield: 0,
      saveState: 0,
      restoreState: 0,
      isEOF: 1,
      direction: 'forward',
      docsExamined: 1
    }
  },
  command: {
    find: 'contacts',
    filter: { 'addresses.street': 'Second Street' },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}
contactData> 





The reason for that is that our index of course holds the whole documents and not the fields of the

documents,

so mongodb does not go so far to pull out the elements of an array and then pull out all field

values of a nested document

that array might hold.

So our index would only get used if I were not looking for the street in the addresses

I have in that array but if I were looking for addresses holding some document,

so if I were looking for addresses where street is Main Street, if I were looking for that, you see it




like

contactData> db.contacts.explain("executionStats").find({addresses:{street:"Second Street"}});

or 

contactData> db.contacts.explain("executionStats").find({addresses:"Second Street"});
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { addresses: { '$eq': 'Second Street' } },
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'FETCH',
      inputStage: {
        stage: 'IXSCAN',
        keyPattern: { addresses: 1 },
        indexName: 'addresses_1',
        isMultiKey: true,
        multiKeyPaths: { addresses: [ 'addresses' ] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { addresses: [ '["Second Street", "Second Street"]' ] }
      }
    },
    rejectedPlans: []
  },
  executionStats: {
    executionSuccess: true,
    nReturned: 0,
    executionTimeMillis: 0,
    totalKeysExamined: 0,
    totalDocsExamined: 0,
    executionStages: {
      stage: 'FETCH',
      nReturned: 0,
      executionTimeMillisEstimate: 0,
      works: 1,
      advanced: 0,
      needTime: 0,
      needYield: 0,
      saveState: 0,
      restoreState: 0,
      isEOF: 1,
      docsExamined: 0,
      alreadyHasObj: 0,
      inputStage: {
        stage: 'IXSCAN',
        nReturned: 0,
        executionTimeMillisEstimate: 0,
        works: 1,
        advanced: 0,
        needTime: 0,
        needYield: 0,
        saveState: 0,
        restoreState: 0,
        isEOF: 1,
        keyPattern: { addresses: 1 },
        indexName: 'addresses_1',
        isMultiKey: true,
        multiKeyPaths: { addresses: [ 'addresses' ] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { addresses: [ '["Second Street", "Second Street"]' ] },
        keysExamined: 0,
        seeks: 1,
        dupsTested: 0,
        dupsDropped: 0
      }
    }
  },
  command: {
    find: 'contacts',
    filter: { addresses: 'Second Street' },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}


Its an IXSCAN




now you see it uses an index scan for this and it is a multikey index,

so you can also use an index on a field in an embedded document which is part of an array

with that multikey feature. You should just be aware that of course using multi multikey features

on a single collection will quickly lead to some performance issues with rights

because for every new document you add, all these multikey indexes have to be updated

and if you add a new document with 10 values in that array which you happen to store in a multikey

index, then these 10 new entries need to be added to the index registry

and if you then have four or five of these multikey indexes per document, well then you quickly are

in a low performance world.






Still multikey index is super helpful if you have queries that regularly target array values or even

nested values or values in an embedded document in arrays.

There are a couple of restrictions or one important restriction to be precise when using multikey indexes

and that is that if you add an index, a multikey index and you add it as part of a compound index, that

is generally possible,

I can add name in ascending order and name is not an array, it's just a single field and I can then add

hobbies like this,

this works. However what won't work is that I say I want have a compound index made up of two or more

multikey indexes,

so addresses one and hobbies one will not work because you can't index parallel arrays.


contactData> db.contacts.createIndex({addresses:1,hobbies:1})
MongoServerError: Index build failed: 3cd33fac-807a-4618-889c-97b75a257b25: Collection contactData.contacts ( 24126ca8-4f53-4118-819b-e9428a9bb9e0 ) :: caused by :: cannot index parallel arrays [hobbies] [addresses]
contactData> 


The reason for that is simple,

mongodb would have to store the cartesian product of the values of both indexes, of both arrays,

so it would have to pull out all the addresses and for every address, it would have to store all the

hobbies.

So if you have two addresses and five hobbies, you already have to store 10 values and that of course

becomes even worse the more values you have in addresses,

so that is why this is not possible.

Compound indexes with multikey indexes are possible as you see here but only with one multikey index,

so with one array, not with multiple arrays. You can have multiple multikey indexes as you can see here

in separate indexes

but in one and the same index, only one array can be included.





____________________________________________Understanding Text Indexes___________________________________________________





Speaking of multikey indexes, there is a special kind of multikey index, a text index.

Let's say we have this text stored in a field in our document, could be the product description of a

product.


  "This product is a must buy for all fans of modern fiction"
  
  			| |
  			| |
  			\./
  			 .
                   TEXT INDEX
                   
     [product] [must] [buy] [fans] [modern] [fiction]




Now if you want to search that text, we saw before that we can use the regex operator and that

is however not a really great way of searching text,

it offers a very low performance. Better is to use a text index and a text index is a special kind of

index supported by mongodb which will essentially turn this text into an array of single words and

it will store it as such,

so it stores it essentially as if you had an array of these single words, one extra thing it does for

you is it removes all the stop words and it stems all words, so that you have an array of keywords essentially

and things like is or the or a are not stored there because that is typically something you don't search

for because it's all over the place,

the keywords are one matter for text searches typically.






contactData> db.products.insertMany([{title:"A book",description:"This is a book"},{title:"A Pen",description:"This is a mus buy product"}])
{
  acknowledged: true,
  insertedIds: {
    '0': ObjectId("6283be360011ae9793592830"),
    '1': ObjectId("6283be360011ae9793592831")
  }
}
contactData> db.products.find().pretty()
[
  {
    _id: ObjectId("6283be360011ae9793592830"),
    title: 'A book',
    description: 'This is a book'
  },
  {
    _id: ObjectId("6283be360011ae9793592831"),
    title: 'A Pen',
    description: 'This is a mus buy product'
  }
]
contactData> db.products.createIndex({description:1})
description_1




you could do this but then it would simply index this as a single field index and you could then search

for exactly this text to utilize the index but not for individual keywords. You need the text index

so that mongodb splits this up,

so using this will not work so



contactData> db.products.find({description:"This is a book"})
[
  {
    _id: ObjectId("6283be360011ae9793592830"),
    title: 'A book',
    description: 'This is a book'
  }
]
contactData> db.products.find({description:"book"})

contactData> 









contactData> db.products.createIndex({description:1})
description_1
contactData> db.products.explain().find({description:"This is a book"})
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.products',
    indexFilterSet: false,
    parsedQuery: { description: { '$eq': 'This is a book' } },
    queryHash: 'C89C35FA',
    planCacheKey: '0E76FB12',
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'FETCH',
      inputStage: {
        stage: 'IXSCAN',
        keyPattern: { description: 1 },
        indexName: 'description_1',
        isMultiKey: false,
        multiKeyPaths: { description: [] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { description: [ '["This is a book", "This is a book"]' ] }
      }
    },
    rejectedPlans: []
  },
  command: {
    find: 'products',
    filter: { description: 'This is a book' },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}



if we craete index like this 




contactData> db.products.createIndex({description:"text"})
description_text
contactData> 



contactData> db.products.find({$text:{$search:"awesome"}})

contactData> db.products.find({$text:{$search:"book"}})
[
  {
    _id: ObjectId("6283be360011ae9793592830"),
    title: 'A book',
    description: 'This is a book'
  }
]
contactData> 









This is the data we have in there in general

and now let's use products and find and

here

let's now use the special $text key

and search and for that, you pass a document as a value for $text and there, you need

$search.

Now you might be wondering why do I not need to specify the field in which I want to search,

why don't I have to add description,

instead we just add hey I want to search for some text.

The reason for that is that you may only have one text index per collection because text indexes are

pretty expensive as you can imagine,

if you have a lot of long text that has to be split up, you don't want to do this like 10 times per

collection and therefore, you only have one text index where this could look into.

You can actually merge multiple fields into one text index as I will show you in a second and you will

then look through all of them automatically

but you can only do it like this,

you can't say hey I want to search for text and description like this, this won't work.

So now for search, we simply enter the words we want to look for

like awesome and the casing is not important here by the way,

everything is stored as lowercase.





contactData> db.products.find({$text:{$search:"mus ss buy"}})
[
  {
    _id: ObjectId("6283be360011ae9793592831"),
    title: 'A Pen',
    description: 'This is a mus buy product'
  }
]
contactData> 


It will returns the documents that have the description which contains the word mus or ss or buy











____________________________________________Text Indexes and Sorting___________________________________________________



mongodb does something interesting or special when managing such a text index or when searching

for text in a text index, we can find out how it scores its results and let's first of all find out with

the help of projection.

So here I'll add a second argument to my find method to project the results and I will simply output

a score field here

where I can use a special meta operator to add text score. This is a meta field added or managed by mongodb

for text searches

here with the $text

operator on a text index.








So here I'll add a second argument to my find method to project the results and I will simply output

a score field here




where I can use a special meta operator to add text score. This is a meta field added or managed by mongodb




contactData> db.products.find({$text:{$search:" buy"}}).pretty()
[
  {
    _id: ObjectId("6283be360011ae9793592831"),
    title: 'A Pen',
    description: 'This is a mus buy product'
  }
]
contactData> db.products.find({$text:{$search:" buy"}},{score:{$meta:"textScore"}}).pretty()
[
  {
    _id: ObjectId("6283be360011ae9793592831"),
    title: 'A Pen',
    description: 'This is a mus buy product',
    score: 0.6666666666666666
  }
]



for text searches

here with the $text

operator on a text index.

If I do this, you see the score.

mongodb assigned to a result

and here, it even automatically sort it by that score now as you can tell.

So here we see that the score is much higher for T-shirt and awesome than for just awesome and it automatically

sort it for us here

but if we want to make sure, we can of course also add sort here and we can then sort by score where

score is a document with $meta and then textScore written like this as a text and I should add

a dot in front of pretty. And now, it's definitely sorted,

it was before but now we enforce sorting by looking at that meta text score which mongodb manages

for us.


contactData> db.products.find({$text:{$search:" buy"}},{score:{$meta:"textScore"}}).sort({score:{$meta:"textScore"}}).pretty()
[
  {
    _id: ObjectId("6283be360011ae9793592831"),
    title: 'A Pen',
    description: 'This is a mus buy product',
    score: 0.6666666666666666
  }
]




______________________________________Creating Combined Text indexes________________________________________________________













contactData> db.products.getIndexes();
[
  { v: 2, key: { _id: 1 }, name: '_id_' },
  {
    v: 2,
    key: { _fts: 'text', _ftsx: 1 },
    name: 'description_text',
    weights: { description: 1 },
    default_language: 'english',
    language_override: 'language',
    textIndexVersion: 3
  }
]


contactData> db.products.createIndex({title:"text"})
MongoServerError: An equivalent index already exists with a different name and options. Requested index: { v: 2, key: { _fts: "text", _ftsx: 1 }, name: "title_text", weights: { title: 1 }, default_language: "english", language_override: "language", textIndexVersion: 3 }, existing index: { v: 2, key: { _fts: "text", _ftsx: 1 }, name: "description_text", weights: { description: 1 }, default_language: "english", language_override: "language", textIndexVersion: 3 }
contactData> 




Now this is a bit hard to read but in the end, it's tried to create the index which we already have because

you can only have one text index.




What we can do though is we can merge the text of multiple fields together into one text index,

for this I first of all need to drop my existing text index and now dropping text index is a bit harder,

you can't do title text,

this doesn't work as you can see but what you can do is you can drop it by the name, by the index name

so you can copy that index name you have up there with get indexes and then you can simply drop it by the




Dropping the text index

contactData> db.products.dropIndex("description_text")
{ nIndexesWas: 2, ok: 1 }
contactData> 


















we can create a text index again

but now we can actually merge together multiple fields by simply adding them like this, description text.


contactData> db.products.createIndex({title:"text",description:"text"})
title_text_description_text
contactData> 


contactData> db.products.getIndexes();
[
  { v: 2, key: { _id: 1 }, name: '_id_' },
  {
    v: 2,
    key: { _fts: 'text', _ftsx: 1 },
    name: 'title_text_description_text',
    weights: { description: 1, title: 1 },
    default_language: 'english',
    language_override: 'language',
    textIndexVersion: 3
  }
]
contactData> 




Now there is still will only be one text index but it will contain the keywords of both the title and

the description field, so if I hit

enter, this works and now I can of course also search for items we have in a title.

So if I find one, you see for example I could search for book because I also have that here,

now we won't see a difference because we had book there before but now we will search for both. And I

can prove this by simply inserting a new product

with a title of a ship and a description of floats perfectly and as you see, we have ship only in the title,

not in the description.



contactData> db.products.find({$text:{$search:"Pen"}}).pretty()
[
  {
    _id: ObjectId("6283be360011ae9793592831"),
    title: 'A Pen',
    description: 'This is a mus buy product'
  }
]
contactData> 




______________________________________Using Text indexes to exclude words___________________________--




Now let's say I only want to find awesome products which are not T-shirts, so I could do this by adding

awesome and then minus T-shirt. If I do this I only find the book because the minus in front of a word


contactData> db.products.find({$text:{$search:"Pen -buy"}}).pretty()



means that this word should be excluded

and this is really helpful of course because it allows you to run narrowed down queries like this one

where you only find awesome products which are not T-shirts or which at least don't have T-shirt in

the title or in the description.






______________________________________Setting the default language and using widgets_____________________________-




contactData> db.products.createIndex({title:"text",description:"text"},{default_language:"german"})
title_text_description_text
contactData> db.products.getIndexes();
[
  { v: 2, key: { _id: 1 }, name: '_id_' },
  {
    v: 2,
    key: { _fts: 'text', _ftsx: 1 },
    name: 'title_text_description_text',
    weights: { description: 1, title: 1 },
    default_language: 'german',
    language_override: 'language',
    textIndexVersion: 3
  }
]
contactData> 

I can manually assign default language here to a new value.

You saw earlier that the default language it assumed was English and if that is the case,



Adding weight

contactData> db.products.createIndex({title:"text",description:"text"},{default_language:"german",weights:{title:1,description:10}})
title_text_description_text
contactData> 





______________________________________BUilding indexes___________________________________________________________






































#############################################  A G G R E G A T I O N    F R A M E W O  R K   #######################################################




Retrieving Data Efficiently and in a structured way



_____________________________________MOdule Introduction________________________________________________



Now of course we talked about the fact that you want to store the data in your database in the format

you need it in in your application

but this is not always possible.


You might have an online shop where the sellers can also generate detailed reports on their sales data,

now it will probably be hard to store the data in exactly that format because these reports might be

customizable by the sellers or let's say you have a customer facing application on which your data scientists

in your company also work, of course you will gear your data towards your customers and you will

store it in a way that allows your customers to quickly interact with your application and your data scientists

might not be that important for you from a data modeling perspective

therefore, hence you also need more complex data transformation capabilities.







_____________________________________What is aggregation framework________________________________________



So what is the aggregation framework? The aggregation framework in its core is just an alternative to

the find method you could say. You have your collection and now the aggregation framework is all about

building a pipeline of steps that runs on the data that is retrieved from your collection and then gives

you the output in the form you needed


	    Collecton

		|
		|	
	    {$match}
		|
		|
	     {$sort}
		|
		|
	    {$group}
		|
		|
	   {$project}
		|
		|
		|
     Output (List of document)
		
		
		
		
		
		
a lot of different steps you can combine as you want.

You can reuse certain stages,






______________________________________Using the aggreagtion Framework________________________________________







The aggregate method takes an array and it takes an array because we define

a series of steps that should be run on our data.

The first step will receive the entire data right from the collection you could say

and the next step can then do something with the data returned by the first step and so on.




Now one important piece of information, aggregate does not go ahead, fetch all the data from the database

and then give it to you and then do something on it,

of course the first step runs on the database and can take advantage of indexes,

so if you filter in the first step or you sort there, you can take advantage of your indexes,

so you don't have to fetch all the documents just because you're using aggregate. Aggregate as find executes

on the mongodb server and therefore can take advantages of things like indexes

and it will.





The first step is then a document, every step is a document

I should say. Now the first step here could be a match phase and match essentially is just a filtering step,

so you define some criteria on which you want to filter your data in that persons collection.

Now you can filter here, in the same way you can filter in find,







analytics> db.persons.aggregate([{$match:{gender:"male"}}])



Now we can already finish our pipeline at this point if we want to,

we can close the square brackets around our stages and close the parentheses of aggregate and I get

back a cursor here,





This was of course only one step, the match step and the match step is not that exciting because there,

we as I said query it exactly the same way we can query in the find method or we filter in the same

way I should say. More interesting is the group stage\\\









_______________________________________________Understanding the group Stage__________________________________________





So we saw the match stage in the last lecture and match is essentially just taking a filter as you

define it as an argument to the find method.


the group stage, the group stage allows you to well group your data by a certain

field or by multiple fields



In group, we need to define a couple of parameters,

the first one always is _id



Now _id defines by which fields you want to group

and now we will use _id in a way we haven't seen it before,

the value for _id will be a document.

Thus far, we always used an objectid, a string or maybe a number but we never use the document

but just as with any other field, you can assign a document to _id.

It's just not that common to be honest

but for the group method here, for the group stage, you often see that syntax because that will be interpreted

in a special way and it will basically allow you to define multiple fields by which you want to group.






db.persons.aggregate([
	
	{$match: {gender:"male"} },
	{$group: {_id:{ state: "$location.state" } ,totalPersons:{ $sum:1 } } }
	
	])




state for example and then $location.state. The dollar sign is important here because

it tells mongodb that I'm referring to a field of our document which is passed into the group stage,

so I'm referring to a field of this document,

the location field and then I can access a nested field just with a dot, here

no dollar sign is required. So this should now group our results by the state.




analytics> db.persons.aggregate([
... 
... 	{$match: {gender:"male"} },
... 	{$group: {_id:{ state: "$location.state" } ,totalPersons:{ $sum:1 } } }
... 
... 	])
Browserslist: caniuse-lite is outdated. Please run:
  npx browserslist@latest --update-db
  Why you should do it regularly: https://github.com/browserslist/browserslist#browsers-data-updating
[
  { _id: { state: 'waikato' }, totalPersons: 2 },
  { _id: { state: 'otago' }, totalPersons: 11 },
  { _id: { state: 'southern savonia' }, totalPersons: 5 },
  { _id: { state: 'maryland' }, totalPersons: 3 },
  { _id: { state: 'carlow' }, totalPersons: 5 },
  { _id: { state: 'hedmark' }, totalPersons: 8 },
  { _id: { state: 'new mexico' }, totalPersons: 2 },
  { _id: { state: 'rheinland-pfalz' }, totalPersons: 10 },
  { _id: { state: 'alpes-maritimes' }, totalPersons: 5 },
  { _id: { state: '' }, totalPersons: 3 },
  { _id: { state: 'bartn' }, totalPersons: 2 },
  { _id: { state: 'utah' }, totalPersons: 7 },
  { _id: { state: 'fingal' }, totalPersons: 7 },
  { _id: { state: '' }, totalPersons: 5 },
  { _id: { state: 'aust-agder' }, totalPersons: 6 },
  { _id: { state: 'edirne' }, totalPersons: 3 },
  { _id: { state: 'northern ostrobothnia' }, totalPersons: 10 },
  { _id: { state: 'rio grande do norte' }, totalPersons: 5 },
  { _id: { state: 'savoie' }, totalPersons: 2 },
  { _id: { state: 'drenthe' }, totalPersons: 10 }
]
Type "it" for more

















___________________________________________________Diving Deeper into the Group Stage____________________________________________



Sorting is the next pipeline operation after grouping,We can not sort the result before grouing ,we can use sorting that for other fields other than the new fileds that we  got from pipeline result(ie, here its totalPersons )

ie sorting can be done based on the output from the previous state





db.persons.aggregate([
	
	{$match: {gender:"female"} },
	{$group: {_id:{ state: "$location.state" } ,totalPersons:{ $sum:1 } } },
	{$sort: { totalPersons:-1 } }
	
	])













analytics> db.persons.aggregate([ { $match: { gender: "female" } }, { $group: { _id: { state: "$location.state" }, totalPersons: { $sum: 1 } } }, { $sort: { totalPersons: -1 } }])
[
  { _id: { state: 'midtjylland' }, totalPersons: 33 },
  { _id: { state: 'nordjylland' }, totalPersons: 27 },
  { _id: { state: 'new south wales' }, totalPersons: 24 },
  { _id: { state: 'syddanmark' }, totalPersons: 24 },
  { _id: { state: 'australian capital territory' }, totalPersons: 24 },
  { _id: { state: 'south australia' }, totalPersons: 22 },
  { _id: { state: 'danmark' }, totalPersons: 21 },
  { _id: { state: 'hovedstaden' }, totalPersons: 21 },
  { _id: { state: 'queensland' }, totalPersons: 20 },
  { _id: { state: 'overijssel' }, totalPersons: 20 },
  { _id: { state: 'sjlland' }, totalPersons: 19 },
  { _id: { state: 'nova scotia' }, totalPersons: 17 },
  { _id: { state: 'canterbury' }, totalPersons: 16 },
  { _id: { state: 'northwest territories' }, totalPersons: 16 },
  { _id: { state: 'gelderland' }, totalPersons: 16 },
  { _id: { state: 'yukon' }, totalPersons: 16 },
  { _id: { state: 'bayern' }, totalPersons: 15 },
  { _id: { state: 'tasmania' }, totalPersons: 15 },
  { _id: { state: 'northern territory' }, totalPersons: 15 },
  { _id: { state: 'victoria' }, totalPersons: 14 }
]
Type "it" for more
analytics> it
[
  { _id: { state: 'zeeland' }, totalPersons: 14 },
  { _id: { state: 'limburg' }, totalPersons: 14 },
  { _id: { state: 'northern savonia' }, totalPersons: 14 },
  { _id: { state: 'nunavut' }, totalPersons: 14 },
  { _id: { state: 'noord-brabant' }, totalPersons: 14 },
  { _id: { state: 'western australia' }, totalPersons: 13 },
  { _id: { state: 'british columbia' }, totalPersons: 13 },
  { _id: { state: 'marlborough' }, totalPersons: 12 },
  { _id: { state: 'ontario' }, totalPersons: 12 },
  { _id: { state: 'brandenburg' }, totalPersons: 12 },
  { _id: { state: 'hamburg' }, totalPersons: 12 },
  { _id: { state: 'castilla y len' }, totalPersons: 12 },
  { _id: { state: 'uusimaa' }, totalPersons: 12 },
  { _id: { state: 'utrecht' }, totalPersons: 12 },
  { _id: { state: 'wellington' }, totalPersons: 12 },
  { _id: { state: 'prince edward island' }, totalPersons: 11 },
  { _id: { state: 'mecklenburg-vorpommern' }, totalPersons: 11 },
  { _id: { state: 'thringen' }, totalPersons: 11 },
  { _id: { state: 'so paulo' }, totalPersons: 11 },
  { _id: { state: 'saskatchewan' }, totalPersons: 11 }
]
Type "it" for more


















we see the sorting works and the interesting thing here really is that the sorting was done on the

output of our previous stage,

so on the output of the group stage. And I hope this already shows you that you have a lot of power with

these tools already because this is essentially a kind of operation we couldn't do with the normal find

method because there, we can't group and then sort on the result of our group. We would have to do that in

the client side code with just find, well with aggregate we can run it on the mongodb server and

then simply get back the data in the client that we need in our client to work with.









_________________________________________________Working with Projection_______________________________________________________


Now let's have a look at a different pipeline stage that allows us to transform every document instead of grouping

multiple together

and that will be the project stage.

Now we already know projection from the find method,

well as an aggregate stage, project became more powerful,



Let's now start simple and not have any other set, I should say we don't do any filtering,

we just want to transform every document.

Then we can use the project stage and as all stages, the value for $project here is simply a document

where you well configure that stage so to say

and in its most simple form, project works in the same way as the projection works in the find method.

So you can for example say I don't want to have the ID by setting it to zero here,



db.persons.aggregate([
	
	{$project: { _id:0,gender:1 ,fullName:{ $concat:['$name.first',' ','$name.last']} } }
	
	]).pretty()
	
	
	
	Here the concat is used to concatenate the fields name.first and name.last
	
	we can concatenate any string values
	
	
	

We can also use uppercase conversion using $toUpper	
	
	
analytics> db.persons.aggregate([
... 
... 	{$project: { _id:0,gender:1 ,fullName:{ $concat:[ {$toUpper:'$name.first' } ,' ',{$toUpper: '$name.last' }]} } }
... 
... 	]).pretty()
[
  { gender: 'female', fullName: ' ' },
  { gender: 'male', fullName: 'HARVEY CHAMBERS' },
  { gender: 'male', fullName: 'GIDEON VAN DRONGELEN' },
  { gender: 'female', fullName: 'MAEVA WILSON' },
  { gender: 'female', fullName: 'OLAV OEHME' },
  { gender: 'male', fullName: 'VICTOR PEDERSEN' },
  { gender: 'male', fullName: 'ZACHARY LO' },
  { gender: 'male', fullName: 'ELIJAH LEWIS' },
  { gender: 'male', fullName: 'CARL JACOBS' },
  { gender: 'female', fullName: 'MADELEINE TILL' },
  { gender: 'male', fullName: 'ISOLINO VIANA' },
  { gender: 'female', fullName: 'SHONA KEMPERMAN' },
  { gender: 'female', fullName: 'LOUISE GRAHAM' },
  { gender: 'female', fullName: 'MESTAN KAPLANG' },
  { gender: 'female', fullName: 'KATIE WELCH' },
  { gender: 'female', fullName: 'SANDRA LORENZO' },
  { gender: 'male', fullName: ' ' },
  { gender: 'female', fullName: 'ANDREIA ARNAUD' },
  { gender: 'female', fullName: 'DELIA DURAND' },
  { gender: 'female', fullName: 'AYA LILAND' }
]
Type "it" for more











We can use More complex expressions uisign

$substrCP => to find the substring

$toUpper => to convert to uppercase

$subtract => to subtract

$strLenCP => find the length of a string





analytics> db.persons.aggregate([
... 
... 	{
... 		$project: {
..... 		 _id:0,
..... 		 gender:1 ,
..... 		 fullName:{ 
....... 		 	$concat:[ 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.first',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.first',1,{$subtract:[{$strLenCP:'$name.first'},1]}]
......... 		 		} , 
....... 		 		' ' , 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.last',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.last',1,{$subtract:[{$strLenCP:'$name.last'},1]}]
......... 		 		}  
....... 		 	]
....... 		} 
..... 	} 
... }
... ]).pretty()
[
  { gender: 'female', fullName: ' ' },
  { gender: 'male', fullName: 'Harvey Chambers' },
  { gender: 'male', fullName: 'Gideon Van drongelen' },
  { gender: 'female', fullName: 'Maeva Wilson' },
  { gender: 'female', fullName: 'Olav Oehme' },
  { gender: 'male', fullName: 'Victor Pedersen' },
  { gender: 'male', fullName: 'Zachary Lo' },
  { gender: 'male', fullName: 'Elijah Lewis' },
  { gender: 'male', fullName: 'Carl Jacobs' },
  { gender: 'female', fullName: 'Madeleine Till' },
  { gender: 'male', fullName: 'Isolino Viana' },
  { gender: 'female', fullName: 'Shona Kemperman' },
  { gender: 'female', fullName: 'Louise Graham' },
  { gender: 'female', fullName: 'Mestan Kaplang' },
  { gender: 'female', fullName: 'Katie Welch' },
  { gender: 'female', fullName: 'Sandra Lorenzo' },
  { gender: 'male', fullName: ' ' },
  { gender: 'female', fullName: 'Andreia Arnaud' },
  { gender: 'female', fullName: 'Delia Durand' },
  { gender: 'female', fullName: 'Aya Liland' }
]
Type "it" for more
analytics> 



















______________________________________






analytics> db.persons.aggregate([
... 
... 	{
... 
... 		$project:{ 
... 			_id:0,
... 			name:1,
... 			email:1,
... 			location:{ 
..... 				type:"Point",
..... 				coordinates:[
..... 					"$location.coordinates.longitude",
..... 					"$location.coordinates.latitude"
..... 				]
..... 
... 			}
... 
... 		}
... 	},
... 	{
... 		$project: {
..... 		 gender:1 ,
..... 		 email:1,
..... 		 location:1,
..... 		 fullName:{ 
....... 		 	$concat:[ 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.first',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.first',1,{$subtract:[{$strLenCP:'$name.first'},1]}]
......... 		 		} , 
....... 		 		' ' , 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.last',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.last',1,{$subtract:[{$strLenCP:'$name.last'},1]}]
......... 		 		}  
....... 		 	]
....... 		} 
..... 	} 
... }
... ]).pretty()
[
  {
    location: { type: 'Point', coordinates: [ '34.1689', '4.6625' ] },
    email: '.@example.com',
    fullName: ' '
  },
  {
    location: { type: 'Point', coordinates: [ '168.9462', '-22.5329' ] },
    email: 'harvey.chambers@example.com',
    fullName: 'Harvey Chambers'
  },
  {
    location: { type: 'Point', coordinates: [ '-54.1364', '-86.1268' ] },
    email: 'gideon.vandrongelen@example.com',
    fullName: 'Gideon Van drongelen'
  },
  {
    location: { type: 'Point', coordinates: [ '111.3806', '-31.6359' ] },
    email: 'maeva.wilson@example.com',
    fullName: 'Maeva Wilson'
  },
  {
    location: { type: 'Point', coordinates: [ '-67.5738', '-52.8348' ] },
    email: 'olav.oehme@example.com',
    fullName: 'Olav Oehme'
  },
  {
    location: { type: 'Point', coordinates: [ '-31.0208', '-29.8113' ] },
    email: 'victor.pedersen@example.com',
    fullName: 'Victor Pedersen'
  },
  {
    location: { type: 'Point', coordinates: [ '-70.2264', '76.4507' ] },
    email: 'zachary.lo@example.com',
    fullName: 'Zachary Lo'
  },
  {
    location: { type: 'Point', coordinates: [ '-18.5996', '-42.6128' ] },
    email: 'elijah.lewis@example.com',
    fullName: 'Elijah Lewis'
  },
  {
    location: { type: 'Point', coordinates: [ '-154.6037', '-29.6721' ] },
    email: 'carl.jacobs@example.com',
    fullName: 'Carl Jacobs'
  },
  {
    location: { type: 'Point', coordinates: [ '-172.3753', '83.3998' ] },
    email: 'madeleine.till@example.com',
    fullName: 'Madeleine Till'
  },
  {
    location: { type: 'Point', coordinates: [ '101.5995', '78.8545' ] },
    email: 'isolino.viana@example.com',
    fullName: 'Isolino Viana'
  },
  {
    location: { type: 'Point', coordinates: [ '-8.5570', '-14.4912' ] },
    email: 'shona.kemperman@example.com',
    fullName: 'Shona Kemperman'
  },
  {
    location: { type: 'Point', coordinates: [ '148.0944', '35.5726' ] },
    email: 'louise.graham@example.com',
    fullName: 'Louise Graham'
  },
  {
    location: { type: 'Point', coordinates: [ '43.9085', '25.1614' ] },
    email: 'mestan.kaplang@example.com',
    fullName: 'Mestan Kaplang'
  },
  {
    location: { type: 'Point', coordinates: [ '135.9359', '71.9851' ] },
    email: 'katie.welch@example.com',
    fullName: 'Katie Welch'
  },
  {
    location: { type: 'Point', coordinates: [ '-83.3326', '-88.6846' ] },
    email: 'sandra.lorenzo@example.com',
    fullName: 'Sandra Lorenzo'
  },
  {
    location: { type: 'Point', coordinates: [ '-90.9499', '21.3388' ] },
    email: '.@example.com',
    fullName: ' '
  },
  {
    location: { type: 'Point', coordinates: [ '59.5703', '-67.6434' ] },
    email: 'andreia.arnaud@example.com',
    fullName: 'Andreia Arnaud'
  },
  {
    location: { type: 'Point', coordinates: [ '-90.4049', '-65.0877' ] },
    email: 'delia.durand@example.com',
    fullName: 'Delia Durand'
  },
  {
    location: { type: 'Point', coordinates: [ '-104.3451', '-88.4983' ] },
    email: 'aya.liland@example.com',
    fullName: 'Aya Liland'
  }
]
Type "it" for more
































analytics> db.persons.aggregate([
... 	{
..... 		$project:{ 
....... 			_id:0,
....... 			name:1,
....... 			email:1,
....... 			location:{ 
......... 				type:"Point",
......... 				coordinates:[
......... 					{$convert:{ input: "$location.coordinates.longitude",to:'double',onError:0.0,onNull:0.0}},
......... 					{$convert:{ input: "$location.coordinates.latitude",to:'double',onError:0.0,onNull:0.0}}
......... 				]
......... 
... 			}
... 
... 		}
... 	},
... 	{
... 		$project: {
..... 		 gender:1 ,
..... 		 email:1,
..... 		 location:1,
..... 		 fullName:{ 
....... 		 	$concat:[ 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.first',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.first',1,{$subtract:[{$strLenCP:'$name.first'},1]}]
......... 		 		} , 
....... 		 		' ' , 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.last',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.last',1,{$subtract:[{$strLenCP:'$name.last'},1]}]
......... 		 		}  
....... 		 	]
....... 		} 
..... 	} 
... }
... ]).pretty()
[
  {
    location: { type: 'Point', coordinates: [ 34.1689, 4.6625 ] },
    email: '.@example.com',
    fullName: ' '
  },
  {
    location: { type: 'Point', coordinates: [ 168.9462, -22.5329 ] },
    email: 'harvey.chambers@example.com',
    fullName: 'Harvey Chambers'
  },
  {
    location: { type: 'Point', coordinates: [ -54.1364, -86.1268 ] },
    email: 'gideon.vandrongelen@example.com',
    fullName: 'Gideon Van drongelen'
  },
  {
    location: { type: 'Point', coordinates: [ 111.3806, -31.6359 ] },
    email: 'maeva.wilson@example.com',
    fullName: 'Maeva Wilson'
  },
  {
    location: { type: 'Point', coordinates: [ -67.5738, -52.8348 ] },
    email: 'olav.oehme@example.com',
    fullName: 'Olav Oehme'
  },
  {
    location: { type: 'Point', coordinates: [ -31.0208, -29.8113 ] },
    email: 'victor.pedersen@example.com',
    fullName: 'Victor Pedersen'
  },
  {
    location: { type: 'Point', coordinates: [ -70.2264, 76.4507 ] },
    email: 'zachary.lo@example.com',
    fullName: 'Zachary Lo'
  },
  {
    location: { type: 'Point', coordinates: [ -18.5996, -42.6128 ] },
    email: 'elijah.lewis@example.com',
    fullName: 'Elijah Lewis'
  },
  {
    location: { type: 'Point', coordinates: [ -154.6037, -29.6721 ] },
    email: 'carl.jacobs@example.com',
    fullName: 'Carl Jacobs'
  },
  {
    location: { type: 'Point', coordinates: [ -172.3753, 83.3998 ] },
    email: 'madeleine.till@example.com',
    fullName: 'Madeleine Till'
  },
  {
    location: { type: 'Point', coordinates: [ 101.5995, 78.8545 ] },
    email: 'isolino.viana@example.com',
    fullName: 'Isolino Viana'
  },
  {
    location: { type: 'Point', coordinates: [ -8.557, -14.4912 ] },
    email: 'shona.kemperman@example.com',
    fullName: 'Shona Kemperman'
  },
  {
    location: { type: 'Point', coordinates: [ 148.0944, 35.5726 ] },
    email: 'louise.graham@example.com',
    fullName: 'Louise Graham'
  },
  {
    location: { type: 'Point', coordinates: [ 43.9085, 25.1614 ] },
    email: 'mestan.kaplang@example.com',
    fullName: 'Mestan Kaplang'
  },
  {
    location: { type: 'Point', coordinates: [ 135.9359, 71.9851 ] },
    email: 'katie.welch@example.com',
    fullName: 'Katie Welch'
  },
  {
    location: { type: 'Point', coordinates: [ -83.3326, -88.6846 ] },
    email: 'sandra.lorenzo@example.com',
    fullName: 'Sandra Lorenzo'
  },
  {
    location: { type: 'Point', coordinates: [ -90.9499, 21.3388 ] },
    email: '.@example.com',
    fullName: ' '
  },
  {
    location: { type: 'Point', coordinates: [ 59.5703, -67.6434 ] },
    email: 'andreia.arnaud@example.com',
    fullName: 'Andreia Arnaud'
  },
  {
    location: { type: 'Point', coordinates: [ -90.4049, -65.0877 ] },
    email: 'delia.durand@example.com',
    fullName: 'Delia Durand'
  },
  {
    location: { type: 'Point', coordinates: [ -104.3451, -88.4983 ] },
    email: 'aya.liland@example.com',
    fullName: 'Aya Liland'
  }
]
Type "it" for more
analytics> 




____________________________________________________Transforming the BirthDate______________________________________________________________






For transforming the date to ISODate in MongoDB


db.persons.aggregate([	
	{
		$project:{ 
			_id:0,
			name:1,
			email:1,
			birthDate:{ $convert : { input : '$dob.date' , to : 'date' } },
			age: '$dob.age',
			location:{ 
				type:"Point",
				coordinates:[
					{$convert:{ input: "$location.coordinates.longitude",to:'double',onError:0.0,onNull:0.0}},
					{$convert:{ input: "$location.coordinates.latitude",to:'double',onError:0.0,onNull:0.0}}
				]

			}

		}
	},
	{
		$project: {
		 gender:1 ,
		 email:1,
		 location:1,
		 birthDate:1,
		 age:1,
		 fullName:{ 
		 	$concat:[ 
		 		{
		 			$toUpper:{$substrCP:['$name.first',0,1]} 
		 		} ,
		 		{ 
		 			$substrCP:['$name.first',1,{$subtract:[{$strLenCP:'$name.first'},1]}]
		 		} , 
		 		' ' , 
		 		{
		 			$toUpper:{$substrCP:['$name.last',0,1]} 
		 		} ,
		 		{ 
		 			$substrCP:['$name.last',1,{$subtract:[{$strLenCP:'$name.last'},1]}]
		 		}  
		 	]
		} 
	} 
}
]).pretty()







[
  {
    location: { type: 'Point', coordinates: [ 59.5703, -67.6434 ] },
    email: 'andreia.arnaud@example.com',
    birthDate: ISODate("1960-01-31T05:16:10.000Z"),
    age: 58,
    fullName: 'Andreia Arnaud'
  },
  {
    location: { type: 'Point', coordinates: [ -90.4049, -65.0877 ] },
    email: 'delia.durand@example.com',
    birthDate: ISODate("1966-08-03T09:22:41.000Z"),
    age: 52,
    fullName: 'Delia Durand'
  },
  {
    location: { type: 'Point', coordinates: [ -104.3451, -88.4983 ] },
    email: 'aya.liland@example.com',
    birthDate: ISODate("1973-08-26T00:11:58.000Z"),
    age: 45,
    fullName: 'Aya Liland'
  }
]
















__________________________________________Using shortcuts for Transformation___________________________________________________





We convert quite a bit in our dataset and that is of course all right.

However if you just need a simple conversion like this one, where you don't specify on error and on null,

then you can also use a shortcut,

there are some special operators in mongodb

and of course you find them in the official docs under aggregation pipeline operators. There you find if

you scroll down to T, to date, to decimal, to double, to int, to long and so on operators,

so these are shortcuts if you need to do a specific transformation.





db.persons.aggregate([	
	{
		$project:{ 
			_id:0,
			name:1,
			email:1,
			birthDate:{ $toDate : '$dob.date' },
			age: '$dob.age',
			location:{ 
				type:"Point",
				coordinates:[
					{$convert:{ input: "$location.coordinates.longitude",to:'double',onError:0.0,onNull:0.0}},
					{$convert:{ input: "$location.coordinates.latitude",to:'double',onError:0.0,onNull:0.0}}
				]

			}

		}
	},
	{
		$project: {
		 gender:1 ,
		 email:1,
		 location:1,
		 birthDate:1,
		 age:1,
		 fullName:{ 
		 	$concat:[ 
		 		{
		 			$toUpper:{$substrCP:['$name.first',0,1]} 
		 		} ,
		 		{ 
		 			$substrCP:['$name.first',1,{$subtract:[{$strLenCP:'$name.first'},1]}]
		 		} , 
		 		' ' , 
		 		{
		 			$toUpper:{$substrCP:['$name.last',0,1]} 
		 		} ,
		 		{ 
		 			$substrCP:['$name.last',1,{$subtract:[{$strLenCP:'$name.last'},1]}]
		 		}  
		 	]
		} 
	} 
}
]).pretty()







If I execute this, you see we still have an ISO date but now it's a bit shorter,

so be aware of these shortcuts for simple transformations.

If you do want to specify your own on error and on null fallback because you might have incomplete data

in your dataset, then using these shortcuts is a bit more difficult,

you at least have to check their docs to see if the default value is they will assume are all right

for you.







[
 {
    location: { type: 'Point', coordinates: [ 59.5703, -67.6434 ] },
    email: 'andreia.arnaud@example.com',
    birthDate: ISODate("1960-01-31T05:16:10.000Z"),
    age: 58,
    fullName: 'Andreia Arnaud'
  },
  {
    location: { type: 'Point', coordinates: [ -90.4049, -65.0877 ] },
    email: 'delia.durand@example.com',
    birthDate: ISODate("1966-08-03T09:22:41.000Z"),
    age: 52,
    fullName: 'Delia Durand'
  },
  {
    location: { type: 'Point', coordinates: [ -104.3451, -88.4983 ] },
    email: 'aya.liland@example.com',
    birthDate: ISODate("1973-08-26T00:11:58.000Z"),
    age: 45,
    fullName: 'Aya Liland'
  }
]




____________________________________Understanding the $isWeekYear Operator______________________________________________




analytics> 

analytics> db.persons.aggregate([
... 	{
..... 		$project:{ 
....... 			_id:0,
....... 			name:1,
....... 			email:1,
....... 			birthDate:{ $toDate : '$dob.date' },
....... 			age: '$dob.age',
....... 			location:{ 
......... 				type:"Point",
......... 				coordinates:[
......... 					{$convert:{ input: "$location.coordinates.longitude",to:'double',onError:0.0,onNull:0.0}},
......... 					{$convert:{ input: "$location.coordinates.latitude",to:'double',onError:0.0,onNull:0.0}}
......... 				]
......... 
... 			}
... 
... 		}
... 	},
... 	{
... 		$project: {
..... 		 gender:1 ,
..... 		 email:1,
..... 		 location:1,
..... 		 birthDate:1,
..... 		 age:1,
..... 		 fullName:{ 
....... 		 	$concat:[ 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.first',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.first',1,{$subtract:[{$strLenCP:'$name.first'},1]}]
......... 		 		} , 
....... 		 		' ' , 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.last',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.last',1,{$subtract:[{$strLenCP:'$name.last'},1]}]
......... 		 		}  
....... 		 	]
....... 		} 
..... 	} 
... },
... 
... { $group : { _id : { birthYear:{ $isoWeekYear: "$birthDate" } },numPersons:{$sum:1} } }
... ]).pretty()
[
  { _id: { birthYear: Long("1980") }, numPersons: 86 },
  { _id: { birthYear: Long("1997") }, numPersons: 52 },
  { _id: { birthYear: Long("1985") }, numPersons: 79 },
  { _id: { birthYear: Long("1970") }, numPersons: 99 },
  { _id: { birthYear: Long("1965") }, numPersons: 98 },
  { _id: { birthYear: Long("1952") }, numPersons: 85 },
  { _id: { birthYear: Long("1944") }, numPersons: 27 },
  { _id: { birthYear: Long("1994") }, numPersons: 102 },
  { _id: { birthYear: Long("1946") }, numPersons: 100 },
  { _id: { birthYear: Long("1961") }, numPersons: 111 },
  { _id: { birthYear: Long("1990") }, numPersons: 103 },
  { _id: { birthYear: Long("1964") }, numPersons: 87 },
  { _id: { birthYear: Long("1963") }, numPersons: 98 },
  { _id: { birthYear: Long("1989") }, numPersons: 93 },
  { _id: { birthYear: Long("1993") }, numPersons: 110 },
  { _id: { birthYear: Long("1975") }, numPersons: 107 },
  { _id: { birthYear: Long("1957") }, numPersons: 82 },
  { _id: { birthYear: Long("1996") }, numPersons: 86 },
  { _id: { birthYear: Long("1987") }, numPersons: 92 },
  { _id: { birthYear: Long("1956") }, numPersons: 87 }
]
Type "it" for more
analytics> 



















analytics> 

analytics> db.persons.aggregate([
... 	{
..... 		$project:{ 
....... 			_id:0,
....... 			name:1,
....... 			email:1,
....... 			birthDate:{ $toDate : '$dob.date' },
....... 			age: '$dob.age',
....... 			location:{ 
......... 				type:"Point",
......... 				coordinates:[
......... 					{$convert:{ input: "$location.coordinates.longitude",to:'double',onError:0.0,onNull:0.0}},
......... 					{$convert:{ input: "$location.coordinates.latitude",to:'double',onError:0.0,onNull:0.0}}
......... 				]
......... 
... 			}
... 
... 		}
... 	},
... 	{
... 		$project: {
..... 		 gender:1 ,
..... 		 email:1,
..... 		 location:1,
..... 		 birthDate:1,
..... 		 age:1,
..... 		 fullName:{ 
....... 		 	$concat:[ 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.first',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.first',1,{$subtract:[{$strLenCP:'$name.first'},1]}]
......... 		 		} , 
....... 		 		' ' , 
....... 		 		{
......... 		 			$toUpper:{$substrCP:['$name.last',0,1]} 
......... 		 		} ,
....... 		 		{ 
......... 		 			$substrCP:['$name.last',1,{$subtract:[{$strLenCP:'$name.last'},1]}]
......... 		 		}  
....... 		 	]
....... 		} 
..... 	} 
... },
... 
... { $group : { _id : { birthYear:{ $isoWeekYear: "$birthDate" } },numPersons:{$sum:1} } },
... { $sort: { numPersons:-1 } }
... ]).pretty()
[
  { _id: { birthYear: Long("1955") }, numPersons: 113 },
  { _id: { birthYear: Long("1961") }, numPersons: 111 },
  { _id: { birthYear: Long("1993") }, numPersons: 110 },
  { _id: { birthYear: Long("1960") }, numPersons: 110 },
  { _id: { birthYear: Long("1975") }, numPersons: 107 },
  { _id: { birthYear: Long("1945") }, numPersons: 106 },
  { _id: { birthYear: Long("1976") }, numPersons: 105 },
  { _id: { birthYear: Long("1967") }, numPersons: 104 },
  { _id: { birthYear: Long("1990") }, numPersons: 103 },
  { _id: { birthYear: Long("1994") }, numPersons: 102 },
  { _id: { birthYear: Long("1981") }, numPersons: 102 },
  { _id: { birthYear: Long("1958") }, numPersons: 101 },
  { _id: { birthYear: Long("1995") }, numPersons: 101 },
  { _id: { birthYear: Long("1946") }, numPersons: 100 },
  { _id: { birthYear: Long("1948") }, numPersons: 100 },
  { _id: { birthYear: Long("1970") }, numPersons: 99 },
  { _id: { birthYear: Long("1983") }, numPersons: 99 },
  { _id: { birthYear: Long("1950") }, numPersons: 99 },
  { _id: { birthYear: Long("1965") }, numPersons: 98 },
  { _id: { birthYear: Long("1963") }, numPersons: 98 }
]
Type "it" for more
analytics> 























____________________________________________$Group Vs $Project____________________________________________________




Now we worked a lot with group and project and it's really important for you to understand the difference.

Group is for grouping multiple documents into one document, whereas project is a one to one relation,

you get one document and then you will return one document, that one document we'll just have changed.

So for group, you have multiple documents and you return one grouped by one or more categories

of your choice

and then also with any new fields with some summary, well statistics or summary calculations, in projection,

you have a one to one relation.

So in grouping, you do things like summing, counting, averaging and so on, in projection phases, you transform

a single document, you add new fields and so on.

This is the difference and this is really important to understand and to get right.






               $group							$project
               
               
               n : 1							1 : 1
               
               
      Sum,Count,Average,Build Array                          Include/Exclude Fields,Transform Fields
      								(Within a single Document)
      								
      								
      								
      								
      								
      								
      								
      								
      								
      								
      								
      								
      								
      								
      								
      								

_______________________________________________Pushing elements into Newly created Arrays______________________________________________






db.friends.insertMany([
  {
    "name": "Max",
    "hobbies": ["Sports", "Cooking"],
    "age": 29,
    "examScores": [
      { "difficulty": 4, "score": 57.9 },
      { "difficulty": 6, "score": 62.1 },
      { "difficulty": 3, "score": 88.5 }
    ]
  },
  {
    "name": "Manu",
    "hobbies": ["Eating", "Data Analytics"],
    "age": 30,
    "examScores": [
      { "difficulty": 7, "score": 52.1 },
      { "difficulty": 2, "score": 74.3 },
      { "difficulty": 5, "score": 53.1 }
    ]
  },
  {
    "name": "Maria",
    "hobbies": ["Cooking", "Skiing"],
    "age": 29,
    "examScores": [
      { "difficulty": 3, "score": 75.1 },
      { "difficulty": 8, "score": 44.2 },
      { "difficulty": 6, "score": 61.5 }
    ]
  }
])









db.friends.aggregate([
  
  {$group:{_id:{ age:"$age"},allHobbies: { $push : "$hobbies" }  }}

])



[
  { _id: { age: 30 }, allHobbies: [ [ 'Eating', 'Data Analytics' ] ] },
  {
    _id: { age: 29 },
    allHobbies: [ [ 'Sports', 'Cooking' ], [ 'Cooking', 'Skiing' ] ]
  }
]







Now what you see is that we have two groups, age 30 and age 29 and all hobbies is an array of arrays because

we push hobbies into our array and hobbies happens to be an array itself, here

hobbies is an array and we just push that value into our all hobbies array here.

That is what I meant, you can push any value of course, not just existing arrays but what if you wanted

to push the values of existing arrays in there but not as one array but you want to pull these values

out of this array and then add them to all hobbies.





_________________________________________Understanding the $unwind stage_____________________________________________________





The unwind stage is always a great stage when you have an array of which you want to pull out the elements.

Now to understand what unwind does, I'll temporarily move my grouping out of there so that I can just copy

that later and I'll complete the unwind stage.

Unwind has two different syntaxes and you can check the official docs for all the details as always,

in its most common usage,

you just pass the name of a field that holds an array,





contactData> 

contactData> db.friends.aggregate([
...   
...   {$unwind:"$hobbies"}
... 
... ]).pretty();
[
  {
    _id: ObjectId("628ba03adf61e96ccb0065eb"),
    name: 'Max',
    hobbies: 'Sports',
    age: 29,
    examScores: [
      { difficulty: 4, score: 57.9 },
      { difficulty: 6, score: 62.1 },
      { difficulty: 3, score: 88.5 }
    ]
  },
  {
    _id: ObjectId("628ba03adf61e96ccb0065eb"),
    name: 'Max',
    hobbies: 'Cooking',
    age: 29,
    examScores: [
      { difficulty: 4, score: 57.9 },
      { difficulty: 6, score: 62.1 },
      { difficulty: 3, score: 88.5 }
    ]
  },
  {
    _id: ObjectId("628ba03adf61e96ccb0065ec"),
    name: 'Manu',
    hobbies: 'Eating',
    age: 30,
    examScores: [
      { difficulty: 7, score: 52.1 },
      { difficulty: 2, score: 74.3 },
      { difficulty: 5, score: 53.1 }
    ]
  },
  {
    _id: ObjectId("628ba03adf61e96ccb0065ec"),
    name: 'Manu',
    hobbies: 'Data Analytics',
    age: 30,
    examScores: [
      { difficulty: 7, score: 52.1 },
      { difficulty: 2, score: 74.3 },
      { difficulty: 5, score: 53.1 }
    ]
  },
  {
    _id: ObjectId("628ba03adf61e96ccb0065ed"),
    name: 'Maria',
    hobbies: 'Cooking',
    age: 29,
    examScores: [
      { difficulty: 3, score: 75.1 },
      { difficulty: 8, score: 44.2 },
      { difficulty: 6, score: 61.5 }
    ]
  },
  {
    _id: ObjectId("628ba03adf61e96ccb0065ed"),
    name: 'Maria',
    hobbies: 'Skiing',
    age: 29,
    examScores: [
      { difficulty: 3, score: 75.1 },
      { difficulty: 8, score: 44.2 },
      { difficulty: 6, score: 61.5 }
    ]
  }
]
contactData> 




So what unwind does is it basically flattens the array by repeating the document

that held the array as often as needed to merge it with the array elements. So the original array of Max

simply has sports and cooking,

therefore Max was repeated twice,

we get two new documents, Max with sports and Max with cooking and the same is true for all other elements.

So where group merges multiple documents into one, unwind takes one document and spits out multiple

documents







Now if we use the aggregation with unwind and group together


contactData> db.friends.aggregate([
...   
...   {$unwind:"$hobbies"},
...   {$group:{_id:{ age:"$age"},allHobbies: { $push : "$hobbies" }  }}
... 
... ]).pretty();
[
  { _id: { age: 30 }, allHobbies: [ 'Eating', 'Data Analytics' ] },
  {
    _id: { age: 29 },
    allHobbies: [ 'Sports', 'Cooking', 'Cooking', 'Skiing' ]
  }
]
contactData> 




Now we have duplicate values in hobbies,Its a problem


________-_____________________________________Eliminating Duplicate Values____________________________________________-



You might not want duplicate values and to avoid that,

you can use an alternative to push. Instead of push, you can use add to set, add to set does almost the same

but if I run it, you see now we have no duplicate values because add to set essentially also pushes

but avoids duplicate values. If it finds that an entry already exists,

it just doesn't push the new value,

this is what adds to set does.

So with that, with unwind, with push in the group stage and with add to set in the group stage, you

get powerful features that should help you manage your array data efficiently and transform it into

whichever format you require.




contactData> 

contactData> db.friends.aggregate([
...   
...   {$unwind:"$hobbies"},
...   {$group:{_id:{ age:"$age"},allHobbies: { $addToSet : "$hobbies" }  }}
... 
... ]).pretty();
[
  { _id: { age: 29 }, allHobbies: [ 'Cooking', 'Skiing', 'Sports' ] },
  { _id: { age: 30 }, allHobbies: [ 'Data Analytics', 'Eating' ] }
]
contactData> 




__________________________________________________Using Projection With Arrays__________________________________________________________






contactData> db.friends.aggregate([
...   
...   {$project : { _id : 0,examScore:{ $slice: ["$examScores",-1] } }}
... 
... ])
[
  { examScore: [ { difficulty: 3, score: 88.5 } ] },
  { examScore: [ { difficulty: 5, score: 53.1 } ] },
  { examScore: [ { difficulty: 6, score: 61.5 } ] }
]
contactData> 





projecting the examScore,Only fetching the last element of the array using slice




projecting the last 2 elements

contactData> db.friends.aggregate([ { $project: { _id: 0, examScore: { $slice: ["$examScores", -2] } } }])
[
  {
    examScore: [ { difficulty: 6, score: 62.1 }, { difficulty: 3, score: 88.5 } ]
  },
  {
    examScore: [ { difficulty: 2, score: 74.3 }, { difficulty: 5, score: 53.1 } ]
  },
  {
    examScore: [ { difficulty: 8, score: 44.2 }, { difficulty: 6, score: 61.5 } ]
  }
]
contactData> db.friends.aggregate([ { $project: { _id: 0, examScore: { $slice: ["$examScores", 1] } } }])
[
  { examScore: [ { difficulty: 4, score: 57.9 } ] },
  { examScore: [ { difficulty: 7, score: 52.1 } ] },
  { examScore: [ { difficulty: 3, score: 75.1 } ] }
]
contactData> 
















contactData> db.friends.aggregate([ { $project: { _id: 0, examScore: { $slice: ["$examScores", 1] } } }])
[
  { examScore: [ { difficulty: 4, score: 57.9 } ] },
  { examScore: [ { difficulty: 7, score: 52.1 } ] },
  { examScore: [ { difficulty: 3, score: 75.1 } ] }
]
contactData> db.friends.aggregate([ { $project: { _id: 0, examScore: { $slice: ["$examScores", -1] } } }])
[
  { examScore: [ { difficulty: 3, score: 88.5 } ] },
  { examScore: [ { difficulty: 5, score: 53.1 } ] },
  { examScore: [ { difficulty: 6, score: 61.5 } ] }
]
contactData> db.friends.aggregate([ { $project: { _id: 0, examScore: { $slice: ["$examScores", -2] } } }])
[
  {
    examScore: [ { difficulty: 6, score: 62.1 }, { difficulty: 3, score: 88.5 } ]
  },
  {
    examScore: [ { difficulty: 2, score: 74.3 }, { difficulty: 5, score: 53.1 } ]
  },
  {
    examScore: [ { difficulty: 8, score: 44.2 }, { difficulty: 6, score: 61.5 } ]
  }
]


=>fetchng 2 consecutive elements starting from index 1  

contactData> db.friends.aggregate([ { $project: { _id: 0, examScore: { $slice: ["$examScores", 1,2] } } }])
[
  {
    examScore: [ { difficulty: 6, score: 62.1 }, { difficulty: 3, score: 88.5 } ]
  },
  {
    examScore: [ { difficulty: 2, score: 74.3 }, { difficulty: 5, score: 53.1 } ]
  },
  {
    examScore: [ { difficulty: 8, score: 44.2 }, { difficulty: 6, score: 61.5 } ]
  }
]
contactData> 











_________________________________________Getting the length of an Array_______________________________________________



contactData> db.friends.aggregate([
...   
...   {$project : { _id : 0,numScores : { $size : "$examScores" } }}
... 
... ])
[ { numScores: 3 }, { numScores: 3 }, { numScores: 3 } ]
contactData> 






________________________________________Using the $filter Operator_____________________________________________________




contactData> db.friends.aggregate([ { $project: { _id: 0, scores: { $filter: { input: "$examScores", as: "sc", cond: { $gt: ["$$sc.score", 80] } } } } }]). pretty();
[
  { scores: [ { difficulty: 3, score: 88.5 } ] },
  { scores: [] },
  { scores: [] }
]
contactData> db.friends.aggregate([ { $project: { _id: 0, scores: { $filter: { input: "$examScores", as: "sc", cond: { $gt: ["$$sc.score", 60] } } } } }]). pretty();
[
  {
    scores: [ { difficulty: 6, score: 62.1 }, { difficulty: 3, score: 88.5 } ]
  },
  { scores: [ { difficulty: 2, score: 74.3 } ] },
  {
    scores: [ { difficulty: 3, score: 75.1 }, { difficulty: 6, score: 61.5 } ]
  }
]
contactData> db.friends.aggregate([ { $project: { _id: 0, scores: { $filter: { input: "$examScores", as: "sc", cond: { $gt: ["$$sc.score", 50] } } } } }]). pretty();
[
  {
    scores: [
      { difficulty: 4, score: 57.9 },
      { difficulty: 6, score: 62.1 },
      { difficulty: 3, score: 88.5 }
    ]
  },
  {
    scores: [
      { difficulty: 7, score: 52.1 },
      { difficulty: 2, score: 74.3 },
      { difficulty: 5, score: 53.1 }
    ]
  },
  {
    scores: [ { difficulty: 3, score: 75.1 }, { difficulty: 6, score: 61.5 } ]
  }
]
contactData> 











_______________________________ApplyingMultiple Operations______________________________________




contactData> db.friends.aggregate([
... 
... 	{ $unwind: "$examScores" },
... 	{ $project: {_id: 0,name:1,age:1,score:"$examScores.score"}}
... 
... 	]).pretty();
[
  { name: 'Max', age: 29, score: 57.9 },
  { name: 'Max', age: 29, score: 62.1 },
  { name: 'Max', age: 29, score: 88.5 },
  { name: 'Manu', age: 30, score: 52.1 },
  { name: 'Manu', age: 30, score: 74.3 },
  { name: 'Manu', age: 30, score: 53.1 },
  { name: 'Maria', age: 29, score: 75.1 },
  { name: 'Maria', age: 29, score: 44.2 },
  { name: 'Maria', age: 29, score: 61.5 }
]
contactData> 












contactData> db.friends.aggregate([
... 
... 	{ $unwind: "$examScores" },
... 	{ $project: {_id: 0,name:1,age:1,score:"$examScores.score"}},
... 	{ $sort : { score : -1 } }
... 
... 	]).pretty();
[
  { name: 'Max', age: 29, score: 88.5 },
  { name: 'Maria', age: 29, score: 75.1 },
  { name: 'Manu', age: 30, score: 74.3 },
  { name: 'Max', age: 29, score: 62.1 },
  { name: 'Maria', age: 29, score: 61.5 },
  { name: 'Max', age: 29, score: 57.9 },
  { name: 'Manu', age: 30, score: 53.1 },
  { name: 'Manu', age: 30, score: 52.1 },
  { name: 'Maria', age: 29, score: 44.2 }
]
contactData> 











contactData> db.friends.aggregate([
... 
... 	{ $unwind: "$examScores" },
... 	{ $project: {_id: 1,name:1,age:1,score:"$examScores.score"}},
... 	{ $sort : { score : -1 } },
... 	{ $group : { _id : "$_id" ,maxScore:{$max:"$score"}} }
... 
... 	]).pretty();
[
  { _id: ObjectId("628ba03adf61e96ccb0065ed"), maxScore: 75.1 },
  { _id: ObjectId("628ba03adf61e96ccb0065ec"), maxScore: 74.3 },
  { _id: ObjectId("628ba03adf61e96ccb0065eb"), maxScore: 88.5 }
]
contactData> 











contactData> db.friends.aggregate([
... 
... 	{ $unwind: "$examScores" },
... 	{ $project: {_id: 1,name:1,age:1,score:"$examScores.score"}},
... 	{ $sort : { score : -1 } },
... 	{ $group : { _id : "$_id" , name : { $first : "$name" } ,maxScore:{$max:"$score"}} }
... 
... 	]).pretty();
[
  {
    _id: ObjectId("628ba03adf61e96ccb0065eb"),
    name: 'Max',
    maxScore: 88.5
  },
  {
    _id: ObjectId("628ba03adf61e96ccb0065ed"),
    name: 'Maria',
    maxScore: 75.1
  },
  {
    _id: ObjectId("628ba03adf61e96ccb0065ec"),
    name: 'Manu',
    maxScore: 74.3
  }
]







contactData> db.friends.aggregate([
... 
... 	{ $unwind: "$examScores" },
... 	{ $project: {_id: 1,name:1,age:1,score:"$examScores.score"}},
... 	{ $sort : { score : -1 } },
... 	{ $group : { _id : "$_id" , name : { $first : "$name" } ,maxScore:{$max:"$score"}} },
... 	{ $sort: { maxScore: -1 }}
... 
... 	]).pretty();
[
  {
    _id: ObjectId("628ba03adf61e96ccb0065eb"),
    name: 'Max',
    maxScore: 88.5
  },
  {
    _id: ObjectId("628ba03adf61e96ccb0065ed"),
    name: 'Maria',
    maxScore: 75.1
  },
  {
    _id: ObjectId("628ba03adf61e96ccb0065ec"),
    name: 'Manu',
    maxScore: 74.3
  }
]
contactData> 
















