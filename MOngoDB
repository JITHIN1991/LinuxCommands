---------------------------------------------------------------------------------------MongoDB-------------------------------------------------------------------------------------------



 [ UI ] => [ Backend(Server eg.java) (Using Mongodb driver) ]   ======>     [  MongoDB SErver -> Storage Engine -> MongoDB DataBase Storage  ]

wired tiger is the default storage engine




sudo systemctl start mongod

sudo systemctl status mongod

https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/





>MongoDB documnet can have embedded documnet upto 100 levels of nesting

>MongoDB can have arrays of embedded documemt

>MongoDB : arrays can hold any data,integer,string,or embedded document etc

>MongoDB document size limit -  16gb





show dbs - shows all dbs

use <db-name> - selects a db



db.products.find()  - to list all data in a collection ,it always gives us the cursor object through which we can cycle through the result .It doesnt give us the array of all the documents in a collection.Actually it givesthe first 20 documents and we need to type 'it' for the next 20 documents

db.products.find().toArray() - gives all the documents without any cursor


>db.passengersData.find().forEach(data=>{ printjson(data)})  -   prints the whole documents using the forEach method on the cursor returned by the find method


>db.passengersData.find({},{name:1,_id:0}).pretty()  --  prints the documents with only name,This is projection,Where the _id is specified with value 0, for others the default value will be 0(here the name is specified with 1,if it is specified with 0, then the default for others will be 1).We     dont need to specify for other fields if we dont want them in the proejection


>db.products.find().pretty() - to list all data in a collection in a pretty way

>db.flightData.find({intercontinental : true}).pretty()  -  Finds the documents that matches the filter condition

>db.flightData.find({}).pretty()  -   Finds all the documents since the filter condition is {}


>db.flightData.find({distance : {$eq:12000}}).pretty()    -   Finds the documents in which the distance is equal to 12000

>db.flightData.find({distance : {$lt:10000}}).pretty();   -   Finds the documents in which the distance is less than 10000

>db.flightData.find({distance : {$gt:10000}}).pretty();   -   Finds the documents in which the distance is greaterb than 10000


>db.flightData.findOne({distance : {$eq:12000}})    -   Finds the first document in which the distance is equal to 12000

>db.flightData.findOne({distance : {$lt:10000}})   -   Finds the first document in which the distance is less than 10000

>db.flightData.findOne({distance : {$gt:10000}})   -   Finds the first document in which the distance is greaterb than 10000

>db.passengersData.findOne({name:"Gordon Black"}).hobbies  -  gives the element(hobbies) of the document.It should be used with fineOne,not with find

   ( pretty is not supported in findOne()  )

   
 [  db.passengersData.find({hobbies:"Music"}).pretty()  -  here assume the hobbies is an array,it will give the dcuments which have the hobbies array with value Music
   


 [ db.passengersData.find({"address.house":"Mambully"})  ]  -  ACCESSING STRUCTURED DATA : Here assume that the addrss is embedded document which has the field house,it will give the result for the house is "mambully" ,we can drill into further level if it has.


 db.flightData.updateOne({"_id" : ObjectId("623b2f95d5526a384e0e40e8")},{$set:{delayed:true}})   -   update the first document that matches the filter condition
 
  db.flightData.update({"_id" : ObjectId("623b2f95d5526a384e0e40e8")},{$set:{delayed:false}})   -   update the first document that matches the filter condition


=>update and updatemany are almost similar except

   db.flightData.update({"_id":ObjectId("623b2f95d5526a384e0e40e8")},{delayed:true}) -This will work,ie without $set.It will patch the object with this id and delayed field,other fields will be lost

   update will overwrite the existing one
   
   but updateMany will not work like this
   



db.flightData.replaceOne({"distance" : 12000},{
...     "departureAirport": "LHR",
...     "arrivalAirport": "TXL",
...     "aircraft": "Airbus A320",
...     "distance": 950,
...     "intercontinental": false
...   })                               -            Here it will replace the document with the given data,But the nid remains unchanges






db.products.insertOne({name:"A pen",price:20,description:"A nice pen"}) - Insert a new document into a collection

db.flightData.insertMany([
			    {
				"departureAirport": "MUC",
				"arrivalAirport": "SFO",     
				"aircraft": "Airbus A380",     
				"distance": 12000,     
				"intercontinental": true   
			    },
			    {
			       "departureAirport": "LHR",     
			       "arrivalAirport": "TXL",     
			       "aircraft": "Airbus A320",     
			       "distance": 950,     
			       "intercontinental": false   
			    } 
			  ]);



db.flightData.deleteOne({"departureAirport" : "MUC"})    -  Deletes the firts documnet that matches the filter criteria 

db.flightData.deleteMany({"departureAirport" : "MUC"})    - Deletes all the documnets that matches the filter criteria,deletes all if filter condition is {}



db.flightData.updateOne({"distance" : 12000},{$set :{marker:"delete"}})    -   Updates the first document that matches the filter condition and set that specified field(marker) in that documnet as a new filed if its not existing or else it will update the value with "delete"





> db.flightData.updateMany({"distance" : 12000},{$set :{marker:"delete"}})  -- Updates all documents that matches the filter condition and set that specified field(marker) in that documnet as a new filed if its not existing or else it will update the value with "delete"


> db.flightData.updateMany({},{$set :{marker:"delete"}})  -- Updates all documents since the filter condition is {}, set that specified field(marker) in all documnets as a new filed if its not existing or else it will update the value with "delete"







db.passengersData.insert({name:"Jithin",age:29})   -   Inserts data ....what is the differnce between insert and insertOne or insertMany?












db.dropDatabase()   -   To drop a database

db.myCollection.drop()    -   To drop a single collection



                                             >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>SCHEMA AND STRUCTURING<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

MongoDB doesnt enforce the scheam

But we can use schema by structuring the document as we want

 
 >>>>Structuring documents

If we want completely different doc structure for all the document in a collection  we can follow the structuring in a way that all documnets having the different structure(ie, fields) - ITs a kind of chaos!!! Not recommended for practice

If we want the same structure for all the document in a collection with some extra fields in some documents,but there are common fields for all docs - we can follow the structuring ina way that all documnets having the same fields and some extra fields (if there is no value for the extra field,that extra field can be omitted or excluded from the doc)- Middle world approach

If we want the same structure for all the document in acollection  we can follow the structuring ina way that all documnets having the same fields (if there is no value for field,it will be null)- ITs SQLish approach





                                              >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>DATA TYPES<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

-----------TEXT------------

Eg : "Jithin" ,"ABC"  etc

---------BOOLEAN-----------

true or false


----------NUmber-----------
 Integer(32 bit long )  <  NumberLong ( 64bit)  <  NumberDecimal(To store high precision floating point value ,more precise than double)


In the shell,if we enter a normal value it will be treated as a float value,that is bcoz the normal shell as we use it in the  course is based on the javascript.Javascript doesnt differentoate bw integers and float values.Value with decimal place.
So everytjing willbe stored as a 64 bit float value in the shell,that is the default value



----------ObjectId-----------

ObjectId('abcdefghi2g34)  - it uses timestamp for the implementation of id
created automatically
if you create two documnets at the same time ,they will not have the same timestamp


-----------ISODate---------------------Timestamp-----------------

ISODate("2020-09-09") --------- Timestamp(12211122687)


-----------Embedded DOcumnet---------------


------------Arrays----------------


















>db.companies.insertOne({name:"Fresh Apples Inc",isStartUp : true,employees:33,funding:12345678901234567890, details:{ceo:"jithin"},tags:[{title:"Super"},{title:"Perfect"}],foundingDate:new Date(),insertedAt:new Timestamp()})


>db.companies.find().pretty();
{
	"_id" : ObjectId("623d0740bc06d37f12d9785d"),
	"name" : "Fresh Apples Inc",
	"isStartUp" : true,
	"employees" : 33,
	"funding" : 12345678901234567000,   // Not same : bcoz,it was too big number, normal number javascript accepts is a 64 bit floating point value and so that could notbe stored in MongoDB if we want to save long digit number then we should save it as a string
	"details" : {
		"ceo" : "jithin"
	},
	"tags" : [
		{
			"title" : "Super"
		},
		{
			"title" : "Perfect"
		}
	],
	"foundingDate" : ISODate("2022-03-25T00:05:20.383Z"),
	"insertedAt" : Timestamp(1648166720, 1)
}




 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Types & Limits<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
MongoDB has a couple of hard limits - most importantly, a single document in a collection (including all embedded documents it might have) must be <= 16mb. Additionally, you may only have 100 levels of embedded documents.

You can find all limits (in great detail) here: https://docs.mongodb.com/manual/reference/limits/

For the data types, MongoDB supports, you find a detailed overview on this page: https://docs.mongodb.com/manual/reference/bson-types/

Important data type limits are:

Normal integers (int32) can hold a maximum value of +-2,147,483,647

Long integers (int64) can hold a maximum value of +-9,223,372,036,854,775,807

Text can be as long as you want - the limit is the 16mb restriction for the overall document

It's also important to understand the difference between int32 (NumberInt), int64 (NumberLong) and a normal number as you can enter it in the shell. The same goes for a normal double and NumberDecimal.

NumberInt creates a int32 value => NumberInt(55)

NumberLong creates a int64 value => NumberLong(7489729384792)

If you just use a number (e.g. insertOne({a: 1}), this will get added as a normal double into the database. The reason for this is that the shell is based on JS which only knows float/ double values and doesn't differ between integers and floats.

NumberDecimal creates a high-precision double value => NumberDecimal("12.99") => This can be helpful for cases where you need (many) exact decimal places for calculations.

When not working with the shell but a MongoDB driver for your app programming language (e.g. PHP, .NET, Node.js, ...), you can use the driver to create these specific numbers.

Example for Node.js: http://mongodb.github.io/node-mongodb-native/3.1/api/Long.html

This will allow you to build a NumberLong value like this:

const Long = require('mongodb').Long;
 
db.collection('wealth').insert( {
    value: Long.fromString("121949898291")
});
By browsing the API docs for the driver you're using, you'll be able to identify the methods for building int32s, int64s etc.









>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Relations<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

>>>>>One to One Relation - Embedded


patient ---------one to one------>  diseaseSummary


>db.patients.insertOne({name:"Dileep",age:43,diseaseSummary:"disease-sum1"});

>db.diseaseSummary.insertOne({id:"disease-sum1",summary:["cold","fever"]});



Here we need 2 steps to retrieve patients diseasesummary details

1) var diseaseSum = db.patients.findOne().diseaseSummary;

2) db.diseaseSummary.find({id:diseaseSum});

{ "_id" : ObjectId("623d21d5bc06d37f12d9785f"), "id" : "disease-sum1", "summary" : [ "cold", "fever" ] }




If we use emnbedded approach we dont need 2 steps

>db.patients.insertOne({name:"Pradeep",age:44,diseaseSummary:{disease:["cold","headache"]}});

>db.patients.findOne();

{ "_id" : ObjectId("623d23dfbc06d37f12d97862"), "name" : "Pradeep", "age" : 44, "diseaseSummary" : { "disease" : [ "cold", "headache" ] } }




>>>>>>One to one Reference


It depends on the application driven requirement

if we dont want extra data which may cuase the unnecessary object mapping results in delayed response, we can avoid embedded documents,instead we can use the references

If we want to keep necessary data inside a documents,then we can use references for one-to-one relation,ie the link -that is the key take away so we can merge the data if we want to.

NB: ? we can also use different collection so as to avoid one-to-one relation,so that we dont need to  use either embedded or reference




>>>>>>>>>>>One to Many Relation - Embedded


If we use reference for the one to many relation ,the Here we need 2 steps to retrieve patients diseasesummary details

If we use emnbedded approach we dont need 2 steps


>>>>>>>>>>>One to Many Relation - Reference

Depends on the application requirement

for example, city -> citizens relations (one to many)

if we embed the citizen data in city document ,then it will be a huge data

if the city document is referenced in citizen document ,then the relation can be established (so that we can avoid the doc limit of 16 mb)


>>>>>>>>>>>Many to many relation  - Embedded


join table
no need to use join table 

insteas use array of references 

lets say
 customer - product relation
 
 order table is required for this many-to-many relations
 
 
 Instaed of using the order docment
 
 we can use the orders details in the customer document
 
 customer : {
 
	 "id": 12233,
	 "name": "jithin",
	 "age": 29,
	 orders:[
		  {
		  	"productId":1232143124,
		  	"quantity" : 5
		  },
		  {
		  	"productId":1232143434t4,
		  	"quantity" : 3
		  },
		  {
		  	"productId":123214343rf34,
		  	"quantity" : 6
		  }
	 ]
 }
 
Thus we can have the many-many reln by two documents

We can also embed the document


 customer : {
 
	 "id": 12233,
	 "name": "jithin",
	 "age": 29,
	 orders:[
		  {
		  	"title":"A book",
		  	"price":12.50
		  	"quantity" : 5
		  },
		  {
		  	"title":"A Pen",
		  	"price":5
		  	"quantity" : 10
		  }
	 ]
 }

In this approach we can see the duplication,if the same products are repaeted in the orders of other customers too
And if we change the product data in product collection,we also need to change this in the customers document also(There are some cases in which this will become an advantage,like if we change the prodcut price,this change should not be applicable for the previous orders,The prodcut should be availabel at that price,,,,But in other cases like persons age,year etc,as in book-author relation ,these details should be updated,In those cases,the reference approach will be better)


>>>>>>>>>>>>>>>>>>>Many to Many - References

Discussed above
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------










-----------------------------------------------------Relations - Options-----------------------------------------------------------------

>>>>>>>>>>>>>>>>Nested/Embedded Documents

Group data together logically

Great for data that belongs together and is not really overlapping  with other data

Avoid  super - deep  nesting (100+ levels ) or  extremely long arrays(16mb size limit  per document)


>>>>>>>>>>>>>>>>References

Split data across collections

Great for related but shared data as well as  for data  which is used in relations and standalone

Allows you to overcome nesting and size limits (by creating new documents)








--------------------------lookup aggregate method for merging reference relations-----------------------------------------

It is helpful tool allows us to fetch two related documents merged together in one documentin one step instead of having  to do two steps

>db.books.aggregate([{ $lookup:{from: "authors", localField: "authors", foreignField:"_id",as:"creators"} }])

Here we are running aggregate on books collection, and the target collection is authors

from -> from which other colection we want to relate

localField -> the local field name of that relatio keys are storedn(here in book,we have one reference field to authors collections,ie authors ,will be simply an array of object ids)

foreignField -> which field are we relating to in the target collection

as -> as an alias,that means the result of aggregate method will be under this alias name



The result will be like


{

"_id" : ObjectId("fjfbcfiwuehfiwhvskvnuwy83ry83"),
"name" : "My Book",
"authors": [
		ObjectId("657cusygcustcutw8fugvcddf"),
		ObjectId("657cusygcustcutw8fuwer3rt")
	],
	
"creators" : [

		{
			"_id" : ObjectId("657cusygcustcutw8fugvcddf"),
			"name" : "Jithin"
			"age" : 29
		
		},
				{
			"_id" : ObjectId("657cusygcustcutw8fuwer3rt"),
			"name" : "Nithin"
			"age" : 31
		
		}


	]

}




_____________________________________________________________SCHEMA VALIDATION________________________________________________________________________


IN Mongodb we can have schema ,we can restrict the collections to follow certain schema


________________________________validation level________________________________________________________________________validation action______________________________________


_________________________which document get validated?__________________________________________________________what happens if validation fals________________________________


_______________________strict=> All inserts and updates______________________________________________________error=>throw error and deny insert / update_______________________


_____________moderate=> All inserts and updates to correct documents______________________________________________warn=>Log warnign but proceed________________________________



Example=>

Normally if we want ot create a collection,then we simply add the data in a new collection simply by

db.posts.insertOne();

But if we want to add some schema validation we need to use "createCollection" as below 

db.createCollection('posts', {
  validator: {
    $jsonSchema: {
      bsonType: 'object',
      required: ['title', 'text', 'creator', 'comments'],
      properties: {
        title: {
          bsonType: 'string',
          description: 'must be a string and is required'
        },
        text: {
          bsonType: 'string',
          description: 'must be a string and is required'
        },
        creator: {
          bsonType: 'objectId',
          description: 'must be an objectid and is required'
        },
        comments: {
          bsonType: 'array',
          description: 'must be an array and is required',
          items: {
            bsonType: 'object',
            required: ['text', 'author'],
            properties: {
              text: {
                bsonType: 'string',
                description: 'must be a string and is required'
              },
              author: {
                bsonType: 'objectId',
                description: 'must be an objectid and is required'
              }
            }
          }
        }
      }
    }
  }
});



Thus we are defining each field and its expected types  of values






































>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>CRUD OPERATIONS IN MONGODB<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<



__________________________CREATE DOCUMENTS___________________________________________


insertOne()
insertMany()
insert() -> Not recommended to use bcoz it makes confusion on whether we are adding one or many documents

  -So it is error prone
  -it doesnt return the id as it does for insertOne and insertMany

mongo import -> mongoimport -d cars -c carsList --drop --jsonArray


================insertyone =>

								=================insertMany=========================

 db.hobbies.insertMany([{"_id": "sports",name: "Sports"},{"_id": "music",name: "Music"},{"_id": "movie",name: "Movie"}])
 
 if we try to add new documnet with the same id using the insertMany,then we will get error and allthe documents added before the error occured will not be roll backed
 

 saying ,
 MongoBulkWriteError: E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "sports" } 
 Result: BulkWriteResult {
  result: {
    ok: 1,
    writeErrors: [
      WriteError {
        err: {
          index: 0,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "sports" }',
          errInfo: undefined,
          op: { _id: 'sports', name: 'Sports' }
        }
      }
    ],
    writeConcernErrors: [],
    insertedIds: [
      { index: 0, _id: 'sports' },
      { index: 1, _id: 'music' },
      { index: 2, _id: 'movie' }
    ],
    nInserted: 0,
    nUpserted: 0,
    nMatched: 0,
    nModified: 0,
    nRemoved: 0,
    upserted: []
  }
}



This is the default behaviour

we can change this behaviour



{ordered :false }  => it allows the user to specifywhetehr mongdb should performan oredered indsert which is the default



 db.hobbies.insertMany([{"_id": "sports",name: "Sports"},{"_id": "music",name: "Music"},{"_id": "movie",name: "Movie"}],{ordered:false})

we will get the same error but it will add the remainign elements


MongoBulkWriteError: E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "sports" }
Result: BulkWriteResult {
  result: {
    ok: 1,
    writeErrors: [
      WriteError {
        err: {
          index: 0,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "sports" }',
          errInfo: undefined,
          op: { _id: 'sports', name: 'Sports' }
        }
      },
      WriteError {
        err: {
          index: 1,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "music" }',
          errInfo: undefined,
          op: { _id: 'music', name: 'Music' }
        }
      },
      WriteError {
        err: {
          index: 2,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.hobbies index: _id_ dup key: { _id: "movie" }',
          errInfo: undefined,
          op: { _id: 'movie', name: 'Movie' }
        }
      }
    ],
    writeConcernErrors: [],
    insertedIds: [
      { index: 0, _id: 'sports' },
      { index: 1, _id: 'music' },
      { index: 2, _id: 'movie' },
      { index: 3, _id: 'cooking' }
    ],
    nInserted: 1,
    nUpserted: 0,
    nMatched: 0,
    nModified: 0,
    nRemoved: 0,
    upserted: []
  }
}
 
 

If yoi see nInserted: 1,1 element is added even we got the error

===========================================Write concern===================================================



There is a second option that we can configure in insrtone and insertmany ,ie write concern

client ->  MongoDB Server(Mongod)    ->      Storage Engine -> 
					        |      ||
					        |      \/
					        |    Memory (First it will write to my,bcoz it is faster than working with disk)
					        |      ||
					        |      \/
                                              ||  Data on DIsk	
						\/
	                      		Jurnal(Todo)
			             
Now you can configure a so-called write concern on all the write operations like insert one with an

additional argument, the write concern argument which is in turn a document where you can set settings

	{w:1,j:undefined}

The w simply means

write

and the number here indicates to how many instances, in case you're using multiple instances on one server,


The J stands for the

journal,

the journal is an additional file which the storage engine manages which is like a To-Do file.

The journal can be kept to then for example save operations that the storage engine needs to-do that have

not been completed yet,

like the write. Now it is aware of the write and that it needs to store that data on disk just by the write

being acknowledged and being there in memory,

it doesn't need to keep a journal for that.

The idea of that journal file which is a real file on the disk is just that it is aware of this
and if the server should go down for some reason or anything else happens, that file is still there

and if you restart the server or if it recovers basically, it can look into that file and see what it

needs to-do

and that is of course a nice back up because the memory might have been wiped by then.

So your write could be lost if it's not written to the journal, if it hasn't been written to the real

data files yet, that is the idea of the journal, it's like a back up to-do list.





{w:1,j:true}

obviously enabling the journal confirmation

means that your writes will take longer because you don't just tell the server about them but you also need

to wait for the server to store that write operation in the journal
but you get higher security that the write also succeeded.

Again this is a decision you have to make depending on your application needs,



db.persons.insertOne({name:"Max",age:"30",hobbies:["Sports","Cooking"]},{writeConcern:{w:0}})
{
  acknowledged: false,
  insertedId: ObjectId("626b881e103e5a4db98f21aa")
}



W : 1 is the default,

it simply means I need to be sure that the server acknowledge this,

you can set this to 0. If you do this, you get back acknowledged false

but if I find everything, you see that Chrissy was inserted.

So you get back a different result, also without an objectID

because it can't give you one, the server hasn't really registered this write yet, you just sent the request

and you immediately return,

you don't wait for a response of this request, so to say.

So the storage engine had no chance to store it in memory and generate that objectId and therefore, you get

back acknowledged false because you sent the request, you don't even know if it reached the server.

This is of course super fast because you don't have to wait for any response here, for any ID generation





=> db.persons.insertOne({name:"Max",age:"30",hobbies:["Sports","Cooking"]},{writeConcern:{w:0,j:true}})

the journal can be set to true,

the default is undefined or false,

so if I set it to false, I have the same result as before.

Now if I change it to McKayla and we set the journal to true now, the output for us does not change and

.

it also was super fast here because everything runs locally

and it's not like the journaling will take four hours but it will have been a little bit slower because

the entry will have been added to the journal and we waited for that journal editing to finish here.

So here, we have higher security because we can also be sure that it ended up in this to do list of the

storage engine which will eventually lead to the writes happen to database files.




=>db.persons.insertOne({name:"Max",age:"30",hobbies:["Sports","Cooking"]},{writeConcern:{w:0,j:true,wtimeout:200}})
=>db.persons.insertOne({name:"Max",age:"30",hobbies:["Sports","Cooking"]},{writeConcern:{w:0,j:true,wtimeout:1}})

This will succeed in local because this is super fast here but it is an option which you can set in case

you get shaky, a shaky connection or speed really matters and your connection is generally good but you

can't rule out that once in a year,

it's kind of shaky and you would then rather have that write fail and you recognize this in your client

application of course because you'll get back an error here too.

So you'll have that write fail and therefore you can try again later but you don't wait unnecessarily




==================================Atomcity in MongoDB===============================


it also succeeded because this is super fast here but it is an option which you can set in case

you get shaky, a shaky connection or speed really matters and your connection is generally good but you

can't rule out that once in a year,

it's kind of shaky and you would then rather have that write fail and you recognize this in your client

application of course because you'll get back an error here too.

So you'll have that write fail and therefore you can try again later but you don't wait unnecessarily





====================================import==============================================


mongo import -> mongoimport  cars.json -d cars -c carsList --drop --jsonArray

d -> database

c -> Collection

jsonArray -> if the cars,json contains an array of documents,then we should use the jsonArray

drop -> if the collection already exist,then drop



mongoimport  tv-shows.json -d movieData -c movies --jsonArray --drop

----------------------------------------------------------------------------------R E A D OPERATION------------------------------------------------------------------------------------

      Access    Apply  Equality/Single
      this      This       Value
    COLLECTION  METHOD    FILTER
        |         |         |
        |         |         |
> db . movies . find( { age : 32 } );
   |                     |     |
   |                     |     |
  Access               Field  Value
  Current
  DATABASE





      Access    Apply    Equality/Single
      this      This         Value
    COLLECTION  METHOD       FILTER
        |         |    _________|____________
        |         |   |                      | 

> db . movies . find( { age : { $gt : 32} } );
   |                     |       |     |
   |                     |       |     | 
  Access               Field     |   Value
  Current                        |
  DATABASE                    Operator






___________________________________________________________________________________________________________________________________________________________________

            Read                                 Update                                  Query Modifiers                                 Aggregation
_____________________________|___________________________________________|_____________________________________________|___________________________________________

   Query & Projection                            Update                                                                         Explained in Aggregation Module

    Query Selectors				   Fields                                D E P R E C A T E D

   Projection Operators                          Arrays





___________________________________________________________________________________________________________________________________________________________________

            TYPE                                 PURPOSE                                  Changes data?                                 Example
_____________________________|___________________________________________|_____________________________________________|___________________________________________

       Query Operator                          Locate Data                                     NO                                          $eq

     Projection Operator                 Modify Data Presentation                              NO                                           $

       Update Operator                 Modify+ Add Additional data                             YES                                         $inc








 Query Selectors      Projection Operators
__________________|___________________________

Comparison                       $
Evaluation                   $elemMatch
Logical                        $meta
Array                         $slice
Element
Comment
GeoSPacial











db.movies.find( { runtime : { $eq : 60 } } )    equivalent to =>  db.movies.find({ runtime : 60 } )

db.movies.find( { runtime : { $lt : 60 } } )   no equivalent to this



-----------------------------------------------------Querying Embedded Fields and arrays


db.movies.find({"rating.average":7.8});

 db.movies.find({"rating.average":{$gt:7}});




For array field,
assume the genre filed is an array like

genre:[
	"Drama",
	"Action",
	"Anime",
	"Horror"
      ]


> db.movies.find({genres:"Drama"}).pretty();

 it will return allthe documents in collection with the array field genre containing the value Drama,even if it has any other fields as well
 
> db.movies.find({genres: ["Drama"]}).pretty();

 it will return allthe documents in collection with the array field genre exactly containing the only value Drama



--------------------------------------$in and $nin



> db.movies.find({runtime:{$in:[30,42]}}).pretty();

returns all the documents that has the runtime value in one of the item in the list [30,42]

> db.movies.find({runtime:{$nin:[30,42]}}).pretty();

returns all the documents that has the runtime value not in one of the item in the list [30,42]





-----------count

count() returns the count of documents

> db.movies.find({runtime:{$in:[30,42]}}).count();




----------------------LOgical operators

OR Operator

> db.movies.find({$or:[{"rating.average":{$lt:5}},{"rating.average":{$gt:9.3}}]}).pretty();


NOR Operator

> db.movies.find({$nor:[{"rating.average":{$lt:5}},{"rating.average":{$gt:9.3}}]}).pretty();


AND Operator

> db.movies.find({$and:[{"rating.average":{$gt:8}},{"genres":"Drama"}]}).count();


 By default mongoDb performs and operation in the filter,So that the following command will yield the same result

> db.movies.find({"rating.average":{$gt:8},"genres":"Drama"}).count();





> db.movies.find({"genres":"Horror","genres":"Drama"}).count();

This may not work as expected in mongodb drivers,bcoz Js doesnt support the same key twice in Object(ie the object will be replaced with {"genres":"Drama"} eventually)

In this case we can use AND instead

> db.movies.find({ $and : [{"genres":"Horror"},{"genres":"Drama"}]}).count();




NOT operator

db.movies.find({runtime:{$not:{$eq:60}}}).count();

is equivalent to

db.movies.find({runtime:{$ne:60}}).count();





$exist operator


db.users.insertMany([
	{
		name: "Max",
		hobbies:[
			{
				title:"Sports",
				frequency:3
			},
			{
				title:"Cooking",
				frequency:6
			}

		],
		phone:9896887587
	},
	{
		name: "Manuel",
		hobbies:[
			{
				title:"Cooking",
				frequency:5
			},
			{
				title:"Cars",
				frequency:2
			}

		],
		phone:"897374982379",
		age:30
	}

])






> db.users.find({age:{$exists:true,$gte:30}}).pretty();

This will return

[
  {
    _id: ObjectId("6271c8b4b8fbeaaf269c1e39"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 }
    ],
    phone: '897374982379',
    age: 30
  }
]


Here $exists will check whether the field exist or not





> db.users.find({age:{$exists:true,$ne:null}}).pretty();

This will also check the null values














db.users.find({phone:{$type:"number"}}).pretty();

This will return the documents with field phone is of type double


db.users.find({phone:{$type:["number","string"]}}).pretty();

This will return the documents with field phone is of type double or String







___________________evaluation_____________

REGEX 

> db.movies.find({summary:"musical"}).pretty();

this will seaech for exact match of summary field


> db.movies.find({summary:{$regex: /musical/}}).pretty();

returns the result where the summarycontains the word "musical" using the regex






EXPRESSION

Expression is useful if you want to compare two fields inside of one document and then find all documents






db.sales.insertMany(
	[	
		{	
			volume:100,
			target:120
		},
		{	
			volume:89,
			target:80
		},
		{	
			volume:200,
			target:180
		}
	]

)



We want to compare the volume and target fields ,for that we can use $expr



> db.sales.find({$expr:{$gt:["$volume","$target"]}}).pretty();

this will return the documents where volume is gt target

[
  { _id: ObjectId("6272a50db8fbeaaf269c1e3b"), volume: 89, target: 80 },
  {
    _id: ObjectId("6272a50db8fbeaaf269c1e3c"),
    volume: 200,
    target: 180
  }
]


Here we should use like "$volume" , "$target"

If we want to refer to the field names, we have to add a dollar sign at the beginning,

this tells mongodb hey please look at the volume field and use the value of that in this expression

and you can't use that in every place in your queries,

it does work on the expression query though and later in the aggregation framework module, you'll find

more places where you can use that.



Here we only find two documents where the volume indeed is higher than the target.

The first document where that was not the case is not included in the results subset and that is of

course super useful because with this dynamic approach, we have an easy time of fetching the data where

some condition within the document is met,

so where two kind of related fields have a certain kind of relation that we check here.









More complex expression.This can be useful

If we wantto implement the following expression

if( (doc.volume >=190 ? doc.volume-10 : doc.volume ) > doc.target  ){

//return the document

return doc;
}

> db.sales.find({$expr: {$gt: [{$cond:{if:{$gte:["$volume",190]},then: {$subtract:["$volume",10]} ,else: "$volume" }},"$target"]}}).pretty();

returns...

[
  { _id: ObjectId("6272a50db8fbeaaf269c1e3b"), volume: 89, target: 80 },
  {
    _id: ObjectId("6272a50db8fbeaaf269c1e3c"),
    volume: 200,
    target: 180
  }
]






____________________________Querying Array







Use the db -> user
it has 2 documents in collection users

user> db.users.find().pretty();
[
  {
    _id: ObjectId("6271c8b4b8fbeaaf269c1e38"),
    name: 'Max',
    hobbies: [
      { title: 'Sports', frequency: 3 },
      { title: 'Cooking', frequency: 6 }
    ],
    phone: 9896887587
  },
  {
    _id: ObjectId("6271c8b4b8fbeaaf269c1e39"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 }
    ],
    phone: '897374982379',
    age: 30
  }
]




> db.users.find({hobbies:"Sports"}).pretty();

This will not return any data

bcoz,the array contains object,so we need to use different filter

Like this

user> db.users.find({hobbies:{title:"Sports",frequency:3}}).pretty();
[
  {
    _id: ObjectId("6271c8b4b8fbeaaf269c1e38"),
    name: 'Max',
    hobbies: [
      { title: 'Sports', frequency: 3 },
      { title: 'Cooking', frequency: 6 }
    ],
    phone: 9896887587
  }
]





Instead of this we can use different approach using the 


user> db.users.find({ "hobbies.title":"Sports"}).pretty();



inside the hobbies array, so we can act as if hobbes would hold just an embedded document and dig into

properties of that embedded document

even though here we got multiple embedded documents in an array but mongodb understands this syntax

and what it will do for this query is it will essentially go through all the elements in hobbies and

for each element, it will dig into the document and compare title to our query value, so to sports.






should keep in mind, that you can use this path embedded approach, not only on directly embedded documents,

so if you have one embedded document in a field but also, if you have an array of embedded documents

and then you can use the same query world with greater than and everything you want as before, you don't

just have to look for equality,






_________________Using Array Query Selectors


$size

db.users.insertOne({name:"Chris",hobbies:["Sports","Cooking","Hiking"]});



 now I want to find all users who have three hobbies which should be just Chris because the

other users have two

and it doesn't matter whether a hobby is an embedded document or just a string,

it's just the amount of items in the hobbies array that matters. To find all users with exactly three

hobbies, I can look into my users with find and now the value for find is that I use hobbies and I'm looking

for a size of three, written like this.



user> db.users.find({hobbies:{$size:3}}).pretty();
[
  {
    _id: ObjectId("6272b32eb8fbeaaf269c1e3d"),
    name: 'Chris',
    hobbies: [ 'Sports', 'Cooking', 'Hiking' ]
  }
]











$all



db.moviestars.find({genre:["action","thriller"]}).pretty();


This will return the document that has the genre exactly as ["action","thriller"]

The order does matter


But what if I don't care about the order? Well then, the all operator can help you. For this,

I simply wrap my array in a document where I use $all as operator and that operator receives

my array then and we also need to close that extra curly brace.




> db.moviestars.find({genre:{ $all : ["action","thriller"]} }).pretty();


What this will do is it will now search genre for these keywords and it will make sure that these items

do have to exist in genre and these items could be numbers, could be embedded documents, could be other arrays

even, doesn't matter

but it ensures that these two elements exist in a genre

but it doesn't care about the order. And therefore now I find both documents even though the order is

different within genre.













$elemMatch



>db.users.find({$and: [{"hobbies.title":"Sports"},{"hobbies.frequency":{$gte:3}}]}).pretty();

this will return the documnents that has hobbies array in which the title= sports and frequency >=3


The thing is with this query, we're basically saying find me all documents where in hobbies,

there is a document at least one document with the title sports and a document with the frequency greater

than or equal to three,

it does not have to be the same document,


so the first part is satisfied and the second part is satisfied with that other element.

Now of course it's not that uncommon that you want to ensure that one and the same element should match

your conditions

and for that, you have the elemMatch operator. So this query

and I'll just count it so that we have it still on page, this query can be replaced with another query

that should do what we want. Instead of and,

we specify our array hobbies and then a value which is a document where we use $elemMatch,






>db.users.find({hobbies: {$elemMatch : { title:"Sports",frequency:{$gte:3} }}}).pretty();







---------------CURSOR


we potentially get back thousands or even millions of documents with find, especially if we have no

condition in there

but even with a condition, you easily have a condition that still meets like 1000 documents or more

depending on the scale of your app.

So you get back all these results and that is very inefficient because all these results have to be

fetched from the database,

they have to be sent over the wire and then they have to be loaded into memory in your client application.

So these are three things that are not optimal because chances are you will not need all thouand documents

at the same time and therefore, find gives you a cursor. A cursor is basically a pointer which has the

query you wrote stored and which can therefore quickly go to the database and say hey, give me the next

batch,





					find()
					  |
					  |
					 \"/
					
				Potentially yields 1000s
				 	or
				 millions of documnets
				 
		Client(Cursor)	 ---------------------->    MongoDB Server DB
			|	 <---------------------	|
			|	  				|
			|______  Request Batch #1 ____________|
			|______ Request Batch #2 _____________|
			|__________ .........  _______________|


cursor approach is

great because it saves resources.

If you have a query that meets 1000 documents, but let's say you have a website where you only display

10 items, let's say 10 products you fetched at a time anyways, then there is no need to load all thousand

results that matched your query right at the start.

Instead you would only fetch the first 10,

display them on the screen and then go ahead and fetch the next 10

when the user navigated to the next page or anything like that. This is the idea behind a cursor,

now we'll find out how to work with a cursor













-----------------------------Applying Cursors


db.movies.find().count() => returns the count


 const dataCursor = db.movies.find();
 
 dataCursor.hasNext() => rreturns true if data present in the cursor
 
 dataCursor.next() => returns the next element
 dataCursor.next() => returns the next element
 dataCursor.next() => returns the next element
 dataCursor.next() => returns the next element
 dataCursor.next() => returns the next element






 const dataCursor = db.movies.find();
dataCursor.forEach(d=>{printjson(d)})

If we use the cursor again after this loop we will get error

> dataCursor.next() 

MongoCursorExhaustedError: Cursor is exhausted







_________________________________Sorting Cursor result________________________________




sort isnot avaialable for fndOne



> db.movies.find().sort({"rating.average":-1}).pretty()

  sort based on the rating. average field in the doc in ascending oreder
  
  
> db.movies.find().sort({"rating.average":-1,runtime:-1}).pretty();

  sort based on the rating. average field in the doc in ascending oreder and runtime field in descending order
  
  


____________________________________Skipping and limiting Cursor Results_____________________________-


movieData> db.movies.find().count();
240
movieData> db.movies.find().skip(200).count();
40
movieData> db.movies.find().skip(200).limit(1).count();
1


So skipping does allow us to move through our data set,

if I skip 100, then we can see the ratings are much higher because we skipped all the bad ones, the 100

bad ones, we skipped them,

now skip is also used on a cursor as you can tell. Now related to skip somehow is the limit function, limit

allows you to limit the amount of elements the cursor should retrieve at a time

and that also means the amount of documents you can then move through with a cursor.

You can limit this to 10 for example,

the interesting thing is if you here add count, you still have 240



db.movies.find().skip(200).limit(1);


it will  skip 200 elements and limit 1 element

we can limit first,or skip first => orderis not important

its very usefulfor pagination 






_________________________Using projection to shape our resultSet__________________________________--



now let's talk about how we can shape the data which we do get back into the form we needed in. Because

in the example of our movies, we have all that data for every document we return, that might simply be too

much data,

not only is it a lot of redundant data that we transfer over the wire

if we don't need it, it also makes it harder for it to work with the data

if we have to manually parse all that. Now with projection, we can control which data is returned.

Let's say we are only interested in the name, the genres, the runtime and the rating and all the rest does

not matter to us. If that is the case, I can write a query here without any criteria,








movieData> db.movies.find({},{name:1,genres:1,runtime:1,rating:1})

[
 {
    _id: ObjectId("626b90a3e561b786bc19b5f4"),
    name: 'Once Upon a Time in Wonderland',
    genres: [ 'Adventure', 'Fantasy' ],
    runtime: 60,
    rating: { average: 6.7 }
  },
  {
    _id: ObjectId("626b90a3e561b786bc19b5f5"),
    name: 'True Blood',
    genres: [ 'Drama', 'Romance', 'Supernatural' ],
    runtime: 60,
    rating: { average: 8 }
  },
  {
    _id: ObjectId("626b90a3e561b786bc19b5f6"),
    name: 'The Last Ship',
    genres: [ 'Drama', 'Action', 'Thriller' ],
    runtime: 60,
    rating: { average: 7.8 }
  }
]


Here id is always included in the document

To remove this ,we need to specify the _id as 0 as shown below

movieData> db.movies.find({},{name:1,genres:1,runtime:1,rating:1,_id:0})


[
 {
    name: 'Once Upon a Time in Wonderland',
    genres: [ 'Adventure', 'Fantasy' ],
    runtime: 60,
    rating: { average: 6.7 }
  },
  {
    name: 'True Blood',
    genres: [ 'Drama', 'Romance', 'Supernatural' ],
    runtime: 60,
    rating: { average: 8 }
  },
  {
    name: 'The Last Ship',
    genres: [ 'Drama', 'Action', 'Thriller' ],
    runtime: 60,
    rating: { average: 7.8 }
  }
]







In the embedded documents ,if we are only interested in only a few fields,then we can explicitly specfy those fields(Assuming that the schedule has other fields as well)

movieData> db.movies.find({},{name:1,genres:1,runtime:1,rating:1,"schedule.time":1,_id:0})

[
  {
    name: 'Once Upon a Time in Wonderland',
    genres: [ 'Adventure', 'Fantasy' ],
    runtime: 60,
    schedule: { time: '20:00' },
    rating: { average: 6.7 }
  },
  {
    name: 'True Blood',
    genres: [ 'Drama', 'Romance', 'Supernatural' ],
    runtime: 60,
    schedule: { time: '21:00' },
    rating: { average: 8 }
  },
  {
    name: 'The Last Ship',
    genres: [ 'Drama', 'Action', 'Thriller' ],
    runtime: 60,
    schedule: { time: '21:00' },
    rating: { average: 7.8 }
  }
]







_____________________________________________-Using Projection in Array_______________________________________

	       Filter  Projection
		  |	  |
db.movies.find({   } , {   })


movieData> db.movies.find({genres:"Drama"},{"genres.$":1})
[
  { _id: ObjectId("626b90a3e561b786bc19b5e3"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e4"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e5"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e7"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e8"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5e9"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ea"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5eb"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ec"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ed"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ee"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ef"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f0"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f1"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f2"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f5"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f6"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f7"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f9"), genres: [ 'Drama' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5fa"), genres: [ 'Drama' ] }
]



here, I can use a special syntax and set genres.$ to one.

Now what this means is give me the one genre you found and therefore in my genres, I only have drama

now,

now these items will have more genres than just drama,

I only just fetch the drama,

I only just output that because that might be the only thing I'm interested

but the items behind the scenes will have more data, just as they have other fields too.

They have more genres too but with this syntax, I only find the first match for my query here,

if I had a more complex query for different genres, I would still just find the first match,




> movieData> db.movies.find({ genres: { $all: ["Drama", "Horror"] } }, { "genres.$": 1 })
[
  { _id: ObjectId("626b90a3e561b786bc19b5ec"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ed"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f0"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f1"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f7"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f9"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5fe"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b602"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b62c"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b676"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b67e"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69c"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69e"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69f"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6b1"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6bf"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6ce"), genres: [ 'Horror' ] }
]



might look strange at first,

the reason for this is that all works such that it goes through the arrays and checks for the existence

of drama and horror,

so the first element to me both is well found when horror is confirmed to be in there too and that

is why we output horror because that technically is the first matching element,

drama alone didn't match anything,

the main thing here is that it doesn't return both but only one.

Now sometimes you could also have the case where you want to pull out some items from an array in your

document that are not the items you queried for.









> movieData> db.movies.find({ genres: { $all: ["Drama", "Horror"] } }, { "genres":{ $elemMatch:{$eq: "Horror"}}})
[
  { _id: ObjectId("626b90a3e561b786bc19b5ec"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5ed"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f0"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f1"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f7"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5f9"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b5fe"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b602"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b62c"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b676"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b67e"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69c"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69e"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b69f"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6b1"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6bf"), genres: [ 'Horror' ] },
  { _id: ObjectId("626b90a3e561b786bc19b6ce"), genres: [ 'Horror' ] }
]




















_________________________________________Understanding $slice _____________________________________________


> movieData> db.movies.find({ genres: { $all: ["Drama", "Horror"] } }, { name:1,"genres":{$slice:2}})



[
  {
    _id: ObjectId("626b90a3e561b786bc19b6b1"),
    name: 'Being Human',
    genres: [ 'Drama', 'Horror' ]
  },
  {
    _id: ObjectId("626b90a3e561b786bc19b6bf"),
    name: 'The River',
    genres: [ 'Drama', 'Horror' ]
  },
  {
    _id: ObjectId("626b90a3e561b786bc19b6ce"),
    name: 'Ravenswood',
    genres: [ 'Drama', 'Horror' ]
  }
]








Here the array of genres is reduced to 2 elements 



movieData> db.movies.find({ genres: { $all: ["Drama", "Horror"] } }, { name:1,"genres":{$slice:[1,2]}})

Here it will skip the first item in the array and shows thye next two items,(ie 2nd and 3rd elements)








___________________________________________________________________UPDATE DOCUMENT____________________________________________________________________



UpdateOne simply takes the first document that matches your filter criteria and updates that even if

multiple documents would normally match your criteria,

updateMany will take your criteria, your filter and update all documents that match it.










we can use a variety of update operators.

Now you can find all update operators in the official docs in the reference under update operators



update operators,we want to update a field or a couple of fields actually.

Now for that, we use $set

and we saw that earlier in the course already. $set simply takes a document where you describe

some fields that should be changed or added to the existing document,


> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$set:{hobbies:[{title:"Sports",frequency:20},{title:"Cooking",frequency:3}]}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}





so $set does not override the existing values

instead it simply just defines some changes that mongodb evaluates and then if they make sense,

it changes the existing document by adding or overriding these fields. All the existing fields are left

untouched,

they are not removed.

You can remove fields and I'll come to that in this module but by default, it simply just adds or edits

the fields which you specify,

so this is update one.






users> db.users.updateMany({"hobbies.title":"Sports"},{$set:{isSporty:true}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 3,
  modifiedCount: 3,
  upsertedCount: 0
}









__________________Updating multiple fields with $set____________________



users> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$set:{age:40,phone:3847345439}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}










__________________________incrementing and decrementing values___________________________




users> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$inc:{age:1},$set:{phone:2384734543911111}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}


This will increment the age by 1 and set the phone field also




> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$inc:{age:-1}});

This will decrement the age by -1

>>>Updating the same filed using inc and set willnot work

users> db.users.updateOne({_id:ObjectId("627e825a03670d27402f6ad9")},{$inc:{age:1},$set:{age:30}});
MongoServerError: Updating the path 'age' would create a conflict at 'age'







__________________________using  min max and mul________________________________________



a scenario you might encounter, that you want to set some field to a certain value but only if it currently

is higher and not if it is lower,



users> db.users.updateOne({name:"Chris"},{$min:{age:35}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}




if the user is alraedy lessthan a value it will not update

users> db.users.updateOne({name:"Chris"},{$min:{age:38}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 0,
  upsertedCount: 0
}




Like wise max will update the value if it is less than the specified value


users> db.users.updateOne({name:"Chris"},{$max:{age:50}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}



$mul will multiply the value


users> db.users.updateOne({name:"Chris"},{$mul:{age:2}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}





_______________________________getting rid of the fields_______________________________




users> db.users.updateMany({isSporty:true},{$set:{phone:null}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 3,
  modifiedCount: 3,
  upsertedCount: 0
}



This will set the field value as null


users> db.users.updateMany({isSporty:true},{$unset:{phone:""}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 3,
  modifiedCount: 3,
  upsertedCount: 0
}

This will drop the field fromthe documents


______________________________Renaming the fields______________________-




users> db.users.updateMany({},{$rename:{age:"totalAge"}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 4,
  modifiedCount: 3,
  upsertedCount: 0
}

This will rename the age field to a new name -> totalAge





_________________________________________Understanding Upsert____________________________________


let's say we want to update some document where we are not sure whether it exists in the collection

or not

beause you have an application where you don't know if the data was saved to the database yet and if

it wasn't saved yet, you now want to create a new document,

if it was, you want to override the existing or update the existing document and that is something you can



Here the user Maria doesnt exist,SO this will not work,ie will not update

users> db.users.updateOne({name:"Maria"},{$set:{age:29,hobbies:[{title:"Good Food",frequency:3}],isSporty:true}})
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 0,
  modifiedCount: 0,
  upsertedCount: 0
}









users> db.users.updateOne({name:"Maria"},{$set:{age:29,hobbies:[{title:"Good Food",frequency:3}],isSporty:true}},{upsert:true})
{
  acknowledged: true,
  insertedId: ObjectId("627f9ad146369aecc5196922"),
  matchedCount: 0,
  modifiedCount: 0,
  upsertedCount: 1
}



update one method and there, there is a nice option you can set which is called upsert and you can set this

to true,

the default is false and you don't need to set the default of course. Now upsert

simply is a combination of the word update and insert and means that if the document does not exist,

it will be created.

So now if I set this to true and I hit enter, you see it actually did not find anything, did not update

anything but it upserted a document with this new ID.

And if I now look into my objects, you see that this document was added

and please note that it even set the name to Maria even though I did not add this in my update one

operation, I filtered for this name

but when I set values, I only set the age, the hobbies and isSporty.







So upsert can be very useful for

working with updates where you don't know if something or if a certain document already exists.









__________________________________________Updating matched array elements____________________________________________



This will update the matched array element(only the matched array elements will be updated,Not the others)

users> db.users.updateMany({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } },{ $set : {"hobbies.$":{title:"Sports",frequency:10}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> 




This will add the new field highFrequency in all the matched array elements,other array elements remains unchanged

users> db.users.updateMany({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } },{ $set : {"hobbies.$.highFrequency":true}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 2,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } });
[
  {
    _id: ObjectId("627e825a03670d27402f6ad8"),
    name: 'Max',
    hobbies: [
      { title: 'Sports', frequency: 10, highFrequency: true },
      { title: 'Cooking', frequency: 6 }
    ],
    isSporty: true
  },
  {
    _id: ObjectId("627e825a03670d27402f6ad9"),
    name: 'Chris',
    hobbies: [
      { title: 'Sports', frequency: 20, highFrequency: true },
      { title: 'Cooking', frequency: 5 }
    ],
    isSporty: true,
    totalAge: 100
  }
]





Here $ sign refers to the matchced array elements(refers to the first match in the array ?)

if we dont use $ it will update the all array elements









___________________________________________Updating all array elements__________________________________________________





This will update the all elements in an array with the matched document




users> db.users.updateMany({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } },{ $set : {"hobbies.$[].highFrequency":true}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 2,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({hobbies:{$elemMatch:{title:"Sports",frequency:{$gte:3} } } });
[
  {
    _id: ObjectId("627e825a03670d27402f6ad8"),
    name: 'Max',
    hobbies: [
      { title: 'Sports', frequency: 10, highFrequency: true },
      { title: 'Cooking', frequency: 6, highFrequency: true }
    ],
    isSporty: true
  },
  {
    _id: ObjectId("627e825a03670d27402f6ad9"),
    name: 'Chris',
    hobbies: [
      { title: 'Sports', frequency: 20, highFrequency: true },
      { title: 'Cooking', frequency: 5, highFrequency: true }
    ],
    isSporty: true,
    totalAge: 100
  }
]

















__________________________________________finding and updating specific fields____________________________________________




users> db.users.updateMany({"hobbies.frequency":{$gt:10}},{$set:{"hobbies.$[el].goodFrequency":true}},{arrayFilters:[{"el.frequency":{$gt:10}}]});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({"hobbies.frequency":{$gt:10}}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6ad9"),
    name: 'Chris',
    hobbies: [
      {
        title: 'Sports',
        frequency: 20,
        highFrequency: true,
        goodFrequency: true
      },
      {
        title: 'Cooking',
        frequency: 5,
        highFrequency: true,
        goodFrequency: false
      }
    ],
    isSporty: true,
    totalAge: 100,
    'hobbies:$[]': { frequency: -3 }
  }
]








Here array filters works together with this [el] syntax, here

you can define some conditions by which you want to filter elements and these conditions can even differ

from the first conditions here,

so they don't have to be equal.

You could be looking for something totally different

here like age greater than 30 and then still filter out certain array elements in this array and you could even

do that for multiple arrays because with the el here, you set an identifier for the condition you want

to apply for this update expression here. Now in array filters,

you therefore have an array

of the different filters for the different arrays you might be updating.

There you have multiple documents, one for each filter and then you have to repeat your identifier,

so in my case it's el, if you named this differently which you can,

you have to name it differently here too.

Now for us here, el is one element in hobbies which happens to be an embedded document,

so if I want to include or check some fields, some field in that embedded document, I can use el dot and

then frequency here as an example and then check whether frequency is greater than 2.

With that I'm rebuilding this query up here

but you don't have to do that,

you can have totally different queries here.





____________________________________________Adding new elemnents to array__________________________________________



$push will add one element into the array

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]
users> db.users.updateOne({name:"Manuel"},{$push:{hobbies:{title:"Sports",frequency:"2"}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> 

users> 

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Sports', frequency: '2' }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]



















This will add multiple elements into the array and also have the option to sort the elements before adding


users> db.users.updateOne({name:"Manuel"},{$push:{hobbies:{$each: [ {title:"Good wine",frequency:"2"},{title:"Hiking",frequency:1} ] , $sort:{frequency:-1}  } }});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Good wine', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]






___________________________________Removing elements from array using $pull and $pop__________________________________________



$pop is used when we want to remove the first orlast elements from an array

$pull is used to remove an elements based on the matching condition



users> db.users.updateOne({name:"Manuel"},{$pull:{hobbies:{title:"Good wine"}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> 

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]





























$pop

Removing element from the end

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]
users> db.users.updateOne({name:"Manuel"},{$pop:{hobbies: 1}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]





$pop

Removing element from the beginning



users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Sports', frequency: '2' },
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]
users> db.users.updateOne({name:"Manuel"},{$pop:{hobbies: -1}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]


















____________________________Understanding $addToSet____________________________________


$push will add elements,it may be duplicate element,But addToSet will not allow duplicates






users> db.users.updateOne({name:"Manuel"},{$push:{hobbies:{title:"Sports",frequency:"2"}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 1,
  upsertedCount: 0
}
users> db.users.updateOne({name:"Manuel"},{$addToSet:{hobbies:{title:"Sports",frequency:"2"}}});
{
  acknowledged: true,
  insertedId: null,
  matchedCount: 1,
  modifiedCount: 0,
  upsertedCount: 0
}
users> 

users> db.users.find({name:"Manuel"}).pretty();
[
  {
    _id: ObjectId("627e825a03670d27402f6adb"),
    name: 'Manuel',
    hobbies: [
      { title: 'Cooking', frequency: 5 },
      { title: 'Cars', frequency: 2 },
      { title: 'Hiking', frequency: 1 },
      { title: 'Sports', frequency: '2' }
    ],
    mobileNo: '012177972',
    totalAge: 30
  }
]











############################################################# D E L E T E   OPERATION  #############################################################

Delete One

users> db.users.deleteOne({totalAge:{$exists:false},isSporty:true});
{ acknowledged: true, deletedCount: 1 }
users> 



Delete Many

users> db.users.deleteMany({totalAge:{$exists:false},isSporty:true});
{ acknowledged: true, deletedCount: 2 }





_______________________Deleting all Entries in a collection_____________________________

users>db.users.deleteMany({})

it is a filter matching all documents in a collection


To drop a collection

db.users.drop();




db.dropDatabase();








##################################################   I N D E X E S  ############################################################


Retrieving Data Efficiently




Now we'll have a look at indexes in this module and indexes are a feature that can drastically speed

up your queries, though if used incorrectly,

they can also slow down some of your operations.

Now we'll take a look at all of that and the different kinds of queries in this module,











So why would we use an index

and what is index to begin with? An index can speed up our find, update or delete queries,









So all the queries where we are looking for certain documents that should match some criteria.



by default if I don't

have an index on seller set,

mongodb will go ahead and do a so-called collection scan,

now that simply means that mongodb to fulfill this query will go through the entire collection,

look at every single document and see if seller equals Max

and as you can imagine for very large collections with thousands or millions of documents, this can take

a while and we'll see this in practice with an example in a second.

So this is the default approach mongodb takes or the only approach it can take when you have no index




Now you can create an index though, an index is not a replacement for a collection but an addition you

could say,

so you would create an index for the seller key of the products collection here and that index then

exists additionally to the collection and the index is essentially an ordered list of all the values

that are placed or stored in the seller key for all the documents.





					db.products.find({seller:"Max"})
						|
						|
		              ______No Index___|_______________Index of Seller_________IndexSCAN___     [Ordered]				
	Products	      |                                                                Products
         {...}											Seller Index
	 {...}	    	      C																
	 {...}		      O								   "Anna"
         {...}	   	      L	 							   "Chris"
         {...}		      L								   "Manu"
	 {...}		      S     =>  							   "Max"	
	 {...}		      C                         				           "Max"
			      A
			      N  [scan all documents]

	

So it's not an ordered list of the documents, just of the values for the field for which you created that

index


and it's not just an ordered list of the values, of course every value, every item in the index has a

pointer to the full document

it belongs to.

Now this allows mongodb to do a so-called index scan to fulfill this query, which means it sees that

for seller, such an index exists and it therefore simply goes to that seller index and can quickly jump

to the right values because there, unlike for the collection,

it knows that the values are sorted by that key,


So it can very efficiently go through that index and then find the matching products because of that ordering

and because of that pointer, every element in this index has, so mongodb finds the value for this query

and then finds the related documents it can return this,

so it's this direct access that mongodb can use here and that speeds up your queries.








creating such indexes can drastically speed up your queries.

However you also shouldn't overdo it with the indexes because you could of course think well ok I got

my product selection and every product has ID, name, age and hobby

and then I could simply create indexes for all fields and I will have the best performance ever, right?

Because no matter for what I look, I got an index for that.

Well this might speed up your find queries,

that is correct, indexes on all fields would speed up find queries because you can query for every field

efficiently but an index does not come for free,

you will pay some performance cost on inserts because that extra index that has to be maintained needs

to be updated with every insert,




 Therefore,

indexes don't come for free and you really have to find out which indexes makes sense and which indexes

don't








_____________________________________Adding a single fieldindex________________________________











now in order to determine whether an index can help us or to see what mongodb actually does,

mongodb gives us a nice tool that we can use to analyze how it executed the query

and this tool is a simple method we add to our query. Here after you reach out to the collection,

you can add the explain method and then chain your normal query,

explain works for find, update, delete

not for insert,




contactData> db.contacts.explain().find({"dob.age":{$gt:60}});
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { 'dob.age': { '$gt': 60 } },
    queryHash: 'FC9E47D2',
    planCacheKey: 'A5FF588D',
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'COLLSCAN',
      filter: { 'dob.age': { '$gt': 60 } },
      direction: 'forward'
    },
    rejectedPlans: []
  },
  command: {
    find: 'contacts',
    filter: { 'dob.age': { '$gt': 60 } },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}




Here the winnignPlan gives tells how the mongodb searched the query

  winningPlan: {
      stage: 'COLLSCAN',
      filter: { 'dob.age': { '$gt': 60 } },
      direction: 'forward'
    },
    
    
    
    
    
    
    
    
=> this will give the executionTime and details    
    
contactData> db.contacts.explain("executionStats").find({"dob.age":{$gt:60}})
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { 'dob.age': { '$gt': 60 } },
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'COLLSCAN',
      filter: { 'dob.age': { '$gt': 60 } },
      direction: 'forward'
    },
    rejectedPlans: []
  },
  executionStats: {
    executionSuccess: true,
    nReturned: 1222,
    executionTimeMillis: 2,
    totalKeysExamined: 0,
    totalDocsExamined: 5000,
    executionStages: {
      stage: 'COLLSCAN',
      filter: { 'dob.age': { '$gt': 60 } },
      nReturned: 1222,
      executionTimeMillisEstimate: 0,
      works: 5002,
      advanced: 1222,
      needTime: 3779,
      needYield: 0,
      saveState: 5,
      restoreState: 5,
      isEOF: 1,
      direction: 'forward',
      docsExamined: 5000
    }
  },
  command: {
    find: 'contacts',
    filter: { 'dob.age': { '$gt': 60 } },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}




Creating index

contactData> db.contacts.createIndex({"dob.age":1})
dob.age_1


After creating the index,lets use explain

contactData> db.contacts.explain("executionStats").find({"dob.age":{$gt:60}})
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { 'dob.age': { '$gt': 60 } },
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'FETCH',
      inputStage: {
        stage: 'IXSCAN',
        keyPattern: { 'dob.age': 1 },
        indexName: 'dob.age_1',
        isMultiKey: false,
        multiKeyPaths: { 'dob.age': [] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { 'dob.age': [ '(60, inf.0]' ] }
      }
    },
    rejectedPlans: []
  },
  executionStats: {
    executionSuccess: true,
    nReturned: 1222,
    executionTimeMillis: 2,
    totalKeysExamined: 1222,
    totalDocsExamined: 1222,
    executionStages: {
      stage: 'FETCH',
      nReturned: 1222,
      executionTimeMillisEstimate: 0,
      works: 1223,
      advanced: 1222,
      needTime: 0,
      needYield: 0,
      saveState: 1,
      restoreState: 1,
      isEOF: 1,
      docsExamined: 1222,
      alreadyHasObj: 0,
      inputStage: {
        stage: 'IXSCAN',
        nReturned: 1222,
        executionTimeMillisEstimate: 0,
        works: 1223,
        advanced: 1222,
        needTime: 0,
        needYield: 0,
        saveState: 1,
        restoreState: 1,
        isEOF: 1,
        keyPattern: { 'dob.age': 1 },
        indexName: 'dob.age_1',
        isMultiKey: false,
        multiKeyPaths: { 'dob.age': [] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { 'dob.age': [ '(60, inf.0]' ] },
        keysExamined: 1222,
        seeks: 1,
        dupsTested: 0,
        dupsDropped: 0
      }
    }
  },
  command: {
    find: 'contacts',
    filter: { 'dob.age': { '$gt': 60 } },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}


This has reduced the execution time

























--------------------Indexes Behind the Scenes---------------------------

What does createIndex() do in detail?

Whilst we can't really see the index, you can think of the index as a simple list of values + pointers to the original document.

Something like this (for the "age" field):

(29, "address in memory/ collection a1")

(30, "address in memory/ collection a2")

(33, "address in memory/ collection a3")

The documents in the collection would be at the "addresses" a1, a2 and a3. The order does not have to match the order in the index (and most likely, it indeed won't).

The important thing is that the index items are ordered (ascending or descending - depending on how you created the index). createIndex({age: 1}) creates an index with ascending sorting, createIndex({age: -1}) creates one with descending sorting.

MongoDB is now able to quickly find a fitting document when you filter for its age as it has a sorted list. Sorted lists are way quicker to search because you can skip entire ranges (and don't have to look at every single document).

Additionally, sorting (via sort(...)) will also be sped up because you already have a sorted list. Of course this is only true when sorting for the age.





Dropping an index

contactData> db.contacts.dropIndex({"dob.age":1})
{ nIndexesWas: 2, ok: 1 }







________________________________Restriction on Indexes___________________________________________________-

if you return all elements but even for the majority it would be faster because

with a full collection scan, you already have all the documents in memory and then an index doesn't offer you

any more because that just is an extra step.

Instead here we got all the documents in memory,

we would have needed to go to the documents anyways to fetch them from the pointers the index gives

us,

so now we already have them and since we need most of them, this is now faster.

So if you have queries that regularly return the majority or all of your documents, an index will not

really help you there,

it might even slow down the execution

and that is important to keep in mind as a first restriction that you need to know when planning your

queries.

If you have a dataset where your queries typically only return fractions, like 10 or 20 percent or lower

than that of the documents, then indexes will almost certainly always speed it up.

If you've got a lot of queries that give you back all the documents or close to all the documents,

indexes can't do that much work for you and logically, that makes sense because the idea of index is to

quickly let you get to a narrow subset of your document list and not to the majority of that.









_______________________________________Creating compound index_______________________________________


contactData> db.contacts.createIndex({"dob.age":1,gender:1})
dob.age_1_gender_1




and this index will not just have the gender but actually as a first key, let's say I want to look for

dob.age and that sorts this in ascending order too.

Now the order of these two fields here does matter because a compound index simply is an index with

more than one field, like here

we got two fields and this will essentially store one index where each entry in the index is now not on

a single value but two combined values. So it does not create two indexes, that's important,

it creates one index but one index where every element is a well, connected value. So now it will simply

create pairs of ages and genders, so we'll have 30 male, 30 male, 30 female, 31 male, 31 female and so on

in the index list and the order here defines which kind of pairs mongodb creates,


So this is a compound index and this speeds up our queries for requests that are well, going to these

two fields because we have these two in an index. Another query that is sped up by that same index



But the compound index can be used from left to right so to say,

so if you have age and gender in there and the leftmost value as you created the index was age and then

the second value was gender, then you can use this index either for all finds that look just for the age,

so for the left part or left and gender. Gender alone won't work though,

so if I try to look for all males with gender male, you'll see that of course works but it uses a collection

scan and not an index scan because it can't look into that second value standalone



If we query gender alone,That wont work here..It will use collection scan



These are some restrictions you have on compound indexes but compound indexes in general allow you

to speed up queries that use multiple values

if you create a compound index on these multiple values.




_________________________________Using indexes for Sorting_____________________________________________



Now this is another cool feature of indexes, since we have an ordered list of values already, mongodb

can utilize that to quickly give us back the order of documents we need.

Now also important to understand or to know here is that if you are not using indexes and you do a sort

on a large amount of documents, you can actually timeout because mongodb has a threshold of

32 megabytes in memory for sorting

and if you have no index, mongodb will essentially fetch all your documents into memory and do the

sort there

and for large collections and large amounts of fetched documents, this can simply be too much to then

sort.

So sometimes, you also need an index not just to speed up the query which always makes sense but also

to be able to sort at all.



contactData> db.contacts.explain().find({"dob.age":35}).sort({gender:1})
{
  explainVersion: '1',
  queryPlanner: {
    namespace: 'contactData.contacts',
    indexFilterSet: false,
    parsedQuery: { 'dob.age': { '$eq': 35 } },
    queryHash: '4E9D85A4',
    planCacheKey: '6398D3CC',
    maxIndexedOrSolutionsReached: false,
    maxIndexedAndSolutionsReached: false,
    maxScansToExplodeReached: false,
    winningPlan: {
      stage: 'FETCH',
      inputStage: {
        stage: 'IXSCAN',
        keyPattern: { 'dob.age': 1, gender: 1 },
        indexName: 'dob.age_1_gender_1',
        isMultiKey: false,
        multiKeyPaths: { 'dob.age': [], gender: [] },
        isUnique: false,
        isSparse: false,
        isPartial: false,
        indexVersion: 2,
        direction: 'forward',
        indexBounds: { 'dob.age': [ '[35, 35]' ], gender: [ '[MinKey, MaxKey]' ] }
      }
    },
    rejectedPlans: []
  },
  command: {
    find: 'contacts',
    filter: { 'dob.age': 35 },
    sort: { gender: 1 },
    '$db': 'contactData'
  },
  serverInfo: {
    host: 'jithin-NKi511TL165S',
    port: 27017,
    version: '5.0.6',
    gitVersion: '212a8dbb47f07427dae194a9c75baec1d81d9259'
  },
  serverParameters: {
    internalQueryFacetBufferSizeBytes: 104857600,
    internalQueryFacetMaxOutputDocSizeBytes: 104857600,
    internalLookupStageIntermediateDocumentMaxSizeBytes: 104857600,
    internalDocumentSourceGroupMaxMemoryBytes: 104857600,
    internalQueryMaxBlockingSortMemoryUsageBytes: 104857600,
    internalQueryProhibitBlockingMergeOnMongoS: 0,
    internalQueryMaxAddToSetBytes: 104857600,
    internalDocumentSourceSetWindowFieldsMaxMemoryBytes: 104857600
  },
  ok: 1
}






__________________________Understanding the default indexes____________________________________






contactData> db.contacts.getIndexes()
[
  { v: 2, key: { _id: 1 }, name: '_id_' }, //default index..available for all collections
  {
    v: 2,
    key: { 'dob.age': 1, gender: 1 },
    name: 'dob.age_1_gender_1'
  }
]



the first one is actually one on the ID field and this is a default index mongodb maintains for

you and then come your own indexes but you have this default index out of the box for every collection

you create and therefore this is an index that will always be maintained by mongodb here automatically.

And this means that if you are filtering for ID or sorting by ID which is then the default sort order

or the order by which the documents are fetched, you utilize the index for that at least.

















______________________________________Configuring indexes____________________________________________











_id is a unique index
SImilar;y we can create other unique indexes






contactData> db.contacts.createIndex({email:1},{unique:true})
MongoServerError: Index build failed: 67b9c39e-9f13-4cad-9978-78b5c1b92648: Collection contactData.contacts ( fa92ceda-9522-4928-9e93-d5ee75063109 ) :: caused by :: E11000 duplicate key error collection: contactData.contacts index: email_1 dup key: { email: "abigail.clark@example.com" }
contactData> 

This error occurred bcoz the duplicate email ids exist in the collection


and this is already one advantage of the unique index,

we get such a warning if we want to add it or if we already had it in place and we tried to add a document

with a value that already existed, we would have gotten an error during that insert operation.

So unique indexes can help you as a developer

ensure data consistency and help you avoid duplicate data for fields that you need to have unique,

so the id, _id is unique by default but you have other use cases like maybe that email here

too

and the unique index is a great way for you to not just speed up your find queries but also to guarantee

that you have unique values for that given field in that collection.






______________________________Understanding partial filters_________________________________________________



and of course an index

also eats up size on your disk,

additionally the bigger the index is, well the more performance certain queries will take nonetheless.

So if you know that certain values will not be looked at or only very very rarely and you would be fine

using a collection scan if that happens, you can actually create a partial index where you only add the

values you're regularly going to look at,







contactData> db.contacts.createIndex({"dob.age":1},{partialFilterExpression:{"dob.age":{$gte:50}}})
dob.age_1


a side note,

you can also add this to compound index of course because now here, I will define which field is my interesting

field for narrowing down the set of values I want to add and I will use my dob.age field.

Now you could also use a totally different field by the way,



Lets use the below one

contactData> db.contacts.createIndex({"dob.age":1},{partialFilterExpression:{gender:"male"}})
dob.age_1


But partial indexes would not be used if the filter query is not matching for the index keypatterns

as below


contactData> db.contacts.explain().find({"dob.age":{$gte:60}})  => COLLSCAN



because mongodb saw that yes we were looking for a field that is part of an index but it also

determined that since we say nothing about the gender in our query here, it would be too risky to use

the index for that because the index is a partial index and mongodb as a top priority ensures

that you don't lose any data.

So it does not work in a way of naturally filtering out your result sets,

instead what you have to do to use that index is you also have to filter for the gender here,

Here in this case you should use the condition => gender:"male" in the filter along with the dob.age



contactData> db.contacts.explain().find({"dob.age":{$gte:60},gender:"male"})    => IXSCAN

contactData> db.contacts.explain().find({"dob.age":{$gte:60},gender:"female"})  => COLLSCAN






index. And now you might be asking, ok what's the difference between a partial index and a compound index then

if I have to specify both values here? The difference is that for the partial index, the overall index simply

is smaller,

there really are only the ages of males stored in there,

the female keys are not stored in the index and therefore, the index size is smaller leading to a lower

impact on your hard drive and also your right queries are of course also sped up because if you insert

a new female, that will never have to be added to your index.

So this still makes a lot of sense if you often filter for this combination,

so for the age and then only males,

so then a partial index can make sense if you rarely look for your other result, if you rarely look for

women,

this makes a lot of sense.







_____________________________________Applying the partial index_________________________________________________


contactData> db.users.insertMany([{name:"Max",email:"max@test.com"},{name:"Manu"}])
{
  acknowledged: true,
  insertedIds: {
    '0': ObjectId("628276530d7fc3a282425a37"),
    '1': ObjectId("628276530d7fc3a282425a38")
  }
}
contactData> db.users.createIndex({email:1})
email_1
contactData> db.users.dropIndex({email:1})
{ nIndexesWas: 2, ok: 1 }

contactData> db.users.createIndex({email:1},{unique:true})
email_1







But now let me insert some new document, db users insert one and there, I'll insert Anna

also without an email.








contactData> db.users.insertMany([{name:"Anna"}])
Uncaught:
MongoBulkWriteError: E11000 duplicate key error collection: contactData.users index: email_1 dup key: { email: null }
Result: BulkWriteResult {
  result: {
    ok: 1,
    writeErrors: [
      WriteError {
        err: {
          index: 0,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.users index: email_1 dup key: { email: null }',
          errInfo: undefined,
          op: { name: 'Anna', _id: ObjectId("6282776d0d7fc3a282425a39") }
        }
      }
    ],
    writeConcernErrors: [],
    insertedIds: [ { index: 0, _id: ObjectId("6282776d0d7fc3a282425a39") } ],
    nInserted: 0,
    nUpserted: 0,
    nMatched: 0,
    nModified: 0,
    nRemoved: 0,
    upserted: []
  }
}






 And now I get an error, I get a duplicate key error because that non-existing e-mail

for which I have an index is treated as a duplicate key because now I have a no value, so no value stored

twice.

So that is an interesting behavior but some behavior you just have to be aware of, mongodb treats

nonexisting values still as values in your index, so as a not there value

you could say, as a null value and therefore if you have two documents with no value for an indexed field

and that index is unique, you will get this error.




if we do it  like this ,then t will execute



contactData> db.users.dropIndex({email:1})
{ nIndexesWas: 2, ok: 1 }

contactData> db.users.createIndex({email:1},{unique:true,partialFilterExpression:{email:{$exists:true}}})
email_1
contactData> db.users.insertMany([{name:"Anna"}])
{
  acknowledged: true,
  insertedIds: { '0': ObjectId("628277f90d7fc3a282425a3a") }
}
contactData> 

















contactData> db.users.insertMany([{name:"Anna",email:"aaaa@gmail.com"}])
{
  acknowledged: true,
  insertedIds: { '0': ObjectId("6282784c0d7fc3a282425a3b") }
}
contactData> db.users.insertMany([{name:"Anna",email:"aaaa@gmail.com"}])
Uncaught:
MongoBulkWriteError: E11000 duplicate key error collection: contactData.users index: email_1 dup key: { email: "aaaa@gmail.com" }
Result: BulkWriteResult {
  result: {
    ok: 1,
    writeErrors: [
      WriteError {
        err: {
          index: 0,
          code: 11000,
          errmsg: 'E11000 duplicate key error collection: contactData.users index: email_1 dup key: { email: "aaaa@gmail.com" }',
          errInfo: undefined,
          op: {
            name: 'Anna',
            email: 'aaaa@gmail.com',
            _id: ObjectId("6282784f0d7fc3a282425a3c")
          }
        }
      }
    ],
    writeConcernErrors: [],
    insertedIds: [ { index: 0, _id: ObjectId("6282784f0d7fc3a282425a3c") } ],
    nInserted: 0,
    nUpserted: 0,
    nMatched: 0,
    nModified: 0,
    nRemoved: 0,
    upserted: []
  }
}






___________________________________________Understanding TTL index____________________________________________________



This is a special feature mongodb offers and that only works on date indexes or on date fields, on other

fields it will just be ignored,

you could add it but it will be ignored

and there I could say every element should be removed after 10 seconds.





contactData> db.sessions.createIndex({createdAt:1},{expireAfterSeconds:10})
createdAt_1
contactData> db.sessions.find()

contactData> db.sessions.insertOne({data:"Check",createdAt:new Date()})
{
  acknowledged: true,
  insertedId: ObjectId("62827b890d7fc3a282425a46")
}
contactData> db.sessions.find()
[
  {
    _id: ObjectId("62827b890d7fc3a282425a46"),
    data: 'Check',
    createdAt: ISODate("2022-05-16T16:27:53.729Z")
  }
]

contactData> db.sessions.find()

contactData> 




After 10 secnds all docs were deleted.

The reason for that is

adding a new element basically triggered mongodb to now re-evaluate the entire collection,

so also the already existing documents and see whether this field which is indexed fulfills this criteria

of only being valid for 10 seconds

and therefore then it also reconsidered the existing documents,

it just doesn't do that right

when you add the index but it does do it whenever you add a new element.

So this can be very useful because it allows you to maintain a collection of documents which destroy

themselves after a certain time span and for a lot of applications,

this can be useful things like for example as I just said, session data for a user of your website

or maybe in an online shop where you want to clear the cart after one day,

so whenever you have a use case where data should clean up itself, you don't need to write a complex

script for that,

you can use a time to live index with that expiry after seconds addition we added in our index.

Important to know here by the way,

you can only use that on single field indexes,

it does not work on compound indexes and as I mentioned, it works on date objects.






__________________________________________Query Diagnosis and Query Planning________________________________________________



						explain()
						    |
						    |
						    |
	 __________________________________________|____________________________________________
	 |                                         |						   |
	 |                                         |                                            |
	 |                                         |                                            |
	 |                                         |                                            |
    "queryPlanner"                           "executionStats"                             "allPlansExecution"
    
    
    
    
    
    
    queryPlanner =>  Show summaryn for executed query
    
    executionStats =>	Show detailed summary for executed Query + winning plan + Possibly Rejected Plan
    
    allPlansExceution =>  Show  Detailed Summary for Executed query + winning plan + winning plan decisions
    
    
    
	 
	 
	 
	 
	 
    					 Efficient queries and Query planning
	 
	
	
	 
	 For determining whether a query is efficient,

it's obviously interesting to look at the milliseconds process time and also compare this to a solution

where you don't use an index, so that you'll also have a look whether index scan really beats a collection

scan which it typically does though

but I did already show you some use cases in cases where you fetch almost everything where the index

scan can be slower

and another important measure is that you compare the number of keys in the index, that is what it means

in the output are examined, how many documents that are examined and how many documents that are returned

and the keys and document should be close together and documents or documents, examine the documents returned

should be closed or documents should be zero so that it looked at zero documents



                                  ---------------------Milliseconds Process Time-------------------------------
                                  
                                  
                                  IXSCAN       ----->     Beats   ----->      COLLSCAN
                                                       
                                                       
                                                       no of keys (in index)
                                            __________ examined
         Should be as close as             |            
         possible or                     <=|            
         no of documents should be 0       |           no of documents__________ 
                                           |__________ examined		   |
                                                       			   |	
                                                       			   |=>  Should be as close as possible or 	
                                                       no of documents _________|    no of dcs should be 0
                                                       returned
                                                       
                                                       
                                                       
                                                       
                                                       
                                                       
