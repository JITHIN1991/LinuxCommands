







----------------------------------------------TO RESOLVE SOLVE SLOWNESS IN PORTAL------------------------------------------

zip -d ROOT.war WEB-INF/lib/cron-utils-7.0.2.jar



------------------------------------------------to search a jar file  inside a war file---------------------------------

go to the directory where the war file is placed and open the terminal

find . | grep -i log4 | grep jar




---------------------------------------------------compress a folder--------------------------------------------------


to compress a folder

sudo tar -cvzf <fileName>.tar.gz <folder-name>
Eg:
sudo tar -cvzf postgres-data.tar.gz postgres-data/

to untar a folder
sudo tar -xvf <fileName>.tar.gz 

sudo tar -xvf postgres-data.tar.gz 



--------------------------------------------------------------------------------------------------------------------------

grep -i "serving" runtime-mcgw.log | grep "18:57:00" | wc -l






docker credentials

shady189
airtel@189

sandeeps96
seqato@123



-------------------------------------COUCHBASE COMMANDS------------------------------------------------




>>>>>COUCH BASE BACKUP AND RESTORE COMMANDS

=>CouchBase backup command

 cbbackup http://localhost:8091 <path to backup in container> -u Administrator -p sift123 -b config


=>CouchBase Restore command 

 cbrestore <path of data to restore inside the container> http://localhost:8091 -b config

 cbrestore /opt/couchbase/var/true_omantel_bck/2021-07-26T060707Z/2021-07-26T060707Z-full http://localhost:8091 -b config


=>Place the back up file under the directory knowesis/sift/persist/var

=>How to restore couchBase backUp

1.Get into the container - sift-persist

 docker exec -it 91b13ec32c1a sh

 (After this go the couchbase UI and go tho the expand the config bucket and click on flush : But Its not mandatory)

2.Go to the bin folder

 cd /opt/couchbase/bin

3.Run the following restore command

 cbrestore /opt/couchbase/var/true_omantel_bck/2021-07-26T060707Z/2021-07-26T060707Z-full http://localhost:8091 -b config






>>>>>URL to get all documents in  a view

curl --location --request GET 'http://10.164.231.9:8091/couchBase/config/_design/dev_pandalytics/_view/view_allEvents'




---------------------------------------------INSTALL CURL IN A CONTAINER-------------------------------------------------

docker exec -it --user root be7cf00604eb bash

docker exec -it --user root <containerid> bash
apk add curl

----------------------------------------------RUNNING CONTAINER IN A SAME NETWORK-----------------------------------------


docker network create -d overlay --attachable persist_network

docker run -p 127.0.0.1:8080:8080 -itd --network=portal_siftnetwork knowesis/sift-portal:6.0

docker run -p 127.0.0.1:8080:8080 -itd --network=portal_siftnetwork knowesis/sift-portal:6.0


--------------------------------------JOURNEY MULTIPLE SAVE CALL--------------------------------------------------------

=>For simulating the race-condition, please use the following command with attached file(journey_issue.json)


seq 1 100 | xargs -n1 -P100 curl -H "Content-Type: application/json" -d @journey_issue.json http://127.0.0.1:10042/design/api/v2/journey/save & 

seq 1 100 | xargs -n1 -P100 curl -H "Content-Type: application/json" -d @journey_issue.json http://127.0.0.1:10042/design/api/v2/journey/validate &

-------------------------------------------------------------------------------------------------------------------------


systemctl status redis

 kill -9 28439 28440 28445
 ps aux|grep redis
 systemctl status redis
/var/log/redis

/etc/redis=>redis.conf

docker cp f4c86db44753:/var/lib/postgresql/keycloak.bak .

Creating a new file in server =>   > filename

curl -X POST 'http://localhost:8081/auth/realms/Demo-Realm/protocol/openid-connect/token'  --header 'Content-Type: application/x-www-form-urlencoded'  --data-urlencode 'grant_type=password'  --data-urlencode 'client_id=springboot-microservice'  --data-urlencode --data-urlencode 'username=jithin'  --data-urlencode 'password=jithin'

docker exec -it opolodesigntime sh -c "curl -XPOST -d 'client_id=opolo' -d 'client_secret=44bdd1c9-9ee7-4c19-aac6-b2f5c752be37' -d 'username=testuser2' -d 'password=sift@123' -d 'grant_type=password' 'http://keycloak:8080/auth/realms/opolo/protocol/openid-connect/token'"



mapping port to our local -> ssh -i ali-opdev-1 -L 8000:127.0.0.1:8000 siftuser@47.74.90.36

                             ssh -i ali-opdev-1 -L 8080:127.0.0.1:8080 siftuser@47.74.90.36



---------------------------------------------------LINUX COMMANDS--------------------------------------------------------

sudo systemctl stop redis

ps -aux | grep redis

netstat -plnt


grep -A10 '"name": "Opolo SMS"' runtime-mcgw.log

grep -B10 '"name": "Opolo SMS"' runtime-mcgw.log

grep -C10 '"name": "Opolo SMS"' runtime-mcgw.log


grep -C10 'Parsing error' runtime-mcgw.log

grep -C10 'activated' sfmcgw.log

grep -C2 'fetched key' sfmcgw.log

 sudo apt-get update => The sudo apt-get update command is used to download package information from all configured    sources.So when you run update command, it downloads the package information from the Internet.

 sudo apt-get install openjdk-8-jdk => Command to install JDK version 1.8

 echo $JAVA_HOME

 which java

 vi ~/.bashrc

 sudo gedit ~/.bashrc

 bash

 sudo apt install git

 mvn

 sudo apt install maven

 cd 

 ls

 ls |grep java

 sudo snap install docker

 cd ~

 tar -xvf eclipse-jee-photon-R-linux-gtk-x86_64.tar.gz

 unzip opolo.zip

 sudo snap install postman

 ls -a

 cd .hiddenfile

 java -jar lombok-1.18.10.jar 
 
 sudo -s

 sudo apt install curl

 curl www.google.com

 ./so-env.sh

 ./so-sfmcgw.sh start

 ./so-sfmcgw.sh status

 cat sfmcgw.log 

 tail -10f  sfmcgw.log 

 tail -50f  sfmcgw.log 

 chmod -R 777 postgres-data

 rm -rf postgres-data

 unzip postgres-data.zip

 echo "docker-compose up -d" >> deploy.sh

 cat deploy.sh

 rm deploy.sh 

 echo "sudo docker-compose up -d" >> deploy.sh

 chmod 777 deploy.sh

 ./deploy.sh

 ./sift-api.sh start : To start a script file

--------------------------------------SERVER DEPLOYMENT SSH AND OTHER COMMANDS--------------------------------------

 scp -i ali-tel-sift.pem sfmcgw-2.10.9.jar siftuser@47.74.86.187:~

 ssh -i ali-tel-sift.pem siftuser@47.74.86.187

 ( passwprd:sift@123 )

 chmod 400 ali-tel-sift.pem 

 pwd

 cd /data/gateway/

 cd designtime/

 cd flow

 mv sfmcgw-2.10.7.jar ../releases/

 mv ~/sfmcgw-2.10.8.jar .

 chmod 777 sfmcgw-2.10.8.jar 

 docker tag knowesis/opolo-gw:v2.10.10 knowesis/opolo-gw:v2.10.10.bkp

 docker build --pull -t knowesis/opolo-gw:v2.10.10 .

 cat shell_config.props 

 vi shell_config.props 

 cd ../..

 cat docker-compose.yaml

 tail -50f sfmcgw.log 

 docker service rm <container_id>

 docker service ls|grep gw

 ./deployOpolo.sh 


-----------------------------------------------------DOCKER-----------------------------------------------------

 docker-compose up -d

 docker-compose down

 docker ps

 docker ps -a

 docker container logs <container-id>

 docker exec -it 083354319fb3 sh

 docker exec -it <id> sh

 docker cp design-sfmcgw-init.sql <docker-id>:/

 docker exec -it <docker-id> sh

 docker container logs <container_id>

 sudo chmod -R 777 postgres-data

 docker build --pull -t <name> .

 docker build --pull -t knowesis/mcgw-runtime:v4.5.4 .

 docker build --pull -t knowesis/mcgw-runtime:v4.5.4 .

 docker run -ti --entrypoint /bin/sh 125107c944ce

 docker tag knowesis/opolo-gw:v2.10.9 knowesis/opolo-gw:v2.10.9.bkp

 docker build --pull -t knowesis/opolo-gw:v2.10.9 .

 docker service ls|grep gw


 docker save -o imagename.tar  imagename  : tar
 docker load -i imagename.tar  : untar


-----------------------------------------------KAFKA-----------------------------------------------------

 bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test

 bin/kafka-topics.sh --list --bootstrap-server localhost:9092

 bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test

 bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

 kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic test

 kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test --from-beginning

 kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic sift.register.in --from-beginning

----------------------------------------------GIT COMMANDS------------------------------------------------
 
 git config --global user.email "my_name@example.com

 git config

 git config --global user.email jithin.ms@seqato.com

 git config --global user.name jithin

 git config -l

                                     --------< REPOSITORIES >--------

GATEWAY REPO
git clone https://ajayjkurup_knowesis@bitbucket.org/knowesis/opolo-orchestrator.git

app password - L77AErYQhZWmGJuvVBdp

SIFT-API REPO
git clone https://sarathknowesis@bitbucket.org/knowesis/api-camel.git  : for SIFT API

PORTAL REPO
git clone https://sarathknowesis@bitbucket.org/knowesis/portal.git     : for portal

PORTAL-SERVICE REPO
git clone https://sarathknowesis@bitbucket.org/knowesis/portal-service.git  : For Portal service

SFMC-API REPO
git clone https://sarathknowesis@bitbucket.org/kd_knowesis/sfmc-api-server.git : sfmc-api


https://bitbucket.org/kd_knowesis/sfmc-api-server/

--------------------------------------------POSTGRES COMMANDS----------------------------------------------

psql -U opoloportaluser rtuEybxYChjmVYb
sudo -u postgres psql


--------------------------------------------------CREATE DATABASE---------------------------------------------------

postgres=# create database keycloak;
postgres=# create user keycloak with encrypted password 'Pa55w0rd';
postgres=# grant all privileges on database keycloak to keycloak;

(
create database keycloak;
create user keycloak with encrypted password 'Pa55w0rd';
grant all privileges on database keycloak to keycloak;
)

-------------------------------------------------TO DROP DATABASE---------------------------------------------------

REVOKE CONNECT ON DATABASE TARGET_DB FROM public;

SELECT pg_terminate_backend(pg_stat_activity.pid) FROM pg_stat_activity WHERE pg_stat_activity.datname = 'keycloak';

DROP DATABASE dbname;

-------------------------------------------------TO TAKE DB DUMP-----------------------------------------------------

pg_dump dbname > dbname.bak

-----------------------------------------------TO RESTORE DATABASE---------------------------------------------------

psql -d database_name -f backup.sql

---------------------------------------------------------------------------------------------------------------------


 su - postgres

 postgres@postgres:~$ psql :to connect postgresql

 postgres=# \l   :  to list all databases

 postgres=# \c dbname : to connect a database

 postgres=# \dn  : to list all schemas

 postgres=# \dt opolo.  : to list tables in a schema
 
 postgres=# set opolo to
 
 postgres=# select * from opolo.journey2; (to list all values from the table journey2)





/ # psql -U opoloportaluser rtuEybxYChjmVYb

rtuEybxYChjmVYb=# ALTER TABLE  public.contacthistory2 ALTER COLUMN journeyid DROP NOT NULL;






 psql -U john -d postgresDB 

 \dt 

 set opolo to

 \dt opolo.

 ALTER TABLE opolo.executetrigger2 ADD OPOLO_KEY varchar;

---------------------------------------------DOCKER COMMANDS-----------------------------------------------

 git config --global user.email "my_name@example.com

 docker build --pull -t  knowesis/opolo-gw:v2.10.8 .

 docker image ls

 docker image ls|grep gw

 docker service rm <container_id>

 docker service ls|grep gw

 ./deployOpolo.sh 


 docker run -it knowesis/sift-api:v1.0 /bin/sh


--------------------------------------------JAVA COMMANDS-----------------------------------------------

 java -jar -Dspring.config.location=/opt/knowesis/sift/portal/sfmcAPI/application.properties 

 Dlog4j.configurationFile=/opt/knowesis/sift/portal/sfmcAPI/log4j2.properties sfmc-api-0.0.1-SNAPSHOT.jar




-------------------------------------------------KUBERNETES-------------------------------------------------

minikube start --driver=docker

minikube status

minikube dashboard


kubectl create deployment first-app --image=jithinms1991/kub-first-app

kubectl get deployments

kubectl get pods

kubectl expose deployment first-app --type=ClusterIP --port=8080
(NodePort,LoadBalancer)

kubectl get services

minikube service first-app

kubectl scale deployment/first-app --replicas=3

kubectl set image deployment/first-app kub-first-app=jithinms1991/kub-first-app

kubectl rollout status deployment/first-app

kubectl rollout undo deployment/first-app

kubectl rollout history deployment/first-app

kubectl rollout history deployment/first-app --revision=3

kubectl rollout undo deployment/first-app --to-revision=1

kubectl delete service first-app

kubectl delete deployment first-app


-----DECLARATIVE APPROACH COMMANDS-----

kubectl apply -f=deployment.yaml

kubectl apply -f service.yaml

minikube service backend

kubectl delete -f=deployment.yaml,service.yaml

kubectl delete -f=deployment.yaml -f=service.yaml


-------------------------------------------------------------------------------------------------------------

sudo usermod -aG docker $USER

ps -ef

ps aux

kill command

top

--------------------------------------------KNOWESIS MAIL URL------------------------------------------------

jithin@knowesis.com

https://outlook.office.com/mail/inbox/id/AAQkADgwOTUyODBiLWFlMzMtNDNkOC1hMjEzLTJlN2M3ZGQxY2FlNgAQAFGp6YJ1TUyWoVaXceL4eVE%3D


teams password: knw123...

skype password: <own password>


---------------------------------------------------------------------------------------MongoDB-------------------------------------------------------------------------------------------



 [ UI ] => [ Backend(Server eg.java) (Using Mongodb driver) ]   ======>     [  MongoDB SErver -> Storage Engine -> MongoDB DataBase Storage  ]

wired tiger is the default storage engine




sudo systemctl start mongod

sudo systemctl status mongod

https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/





show dbs - shows all dbs

use <db-name> - selects a db



db.products.find()  - to list all data in a collection 

db.products.find().pretty() - to list all data in a collection in a pretty way

db.flightData.find({intercontinental : true}).pretty()  -  Finds the documents that matches the filter condition

db.flightData.find({}).pretty()  -   Finds all the documents since the filter condition is {}


db.flightData.find({distance : {$eq:12000}}).pretty()    -   Finds the documents in which the distance is equal to 12000

db.flightData.find({distance : {$lt:10000}}).pretty();   -   Finds the documents in which the distance is less than 10000

db.flightData.find({distance : {$gt:10000}}).pretty();   -   Finds the documents in which the distance is greaterb than 10000


db.flightData.findOne({distance : {$eq:12000}})    -   Finds the first document in which the distance is equal to 12000

db.flightData.findOne({distance : {$lt:10000}})   -   Finds the first document in which the distance is less than 10000

db.flightData.findOne({distance : {$gt:10000}})   -   Finds the first document in which the distance is greaterb than 10000
   
   ( pretty is not supported in findOne()  )




 db.flightData.updateOne({"_id" : ObjectId("623b2f95d5526a384e0e40e8")},{$set:{delayed:true}})   -   update the first document that matches the filter condition
 
  db.flightData.update({"_id" : ObjectId("623b2f95d5526a384e0e40e8")},{$set:{delayed:false}})   -   update the first document that matches the filter condition


=>update and updatemany are almost similar except

   db.flightData.update({"_id":ObjectId("623b2f95d5526a384e0e40e8")},{delayed:true}) -This will work,ie without $set.It will patch the object with this id and delayed field,other fields will be lost

   update will overwrite the existing one
   
   but updateMany will not work like this
   



db.flightData.replaceOne({"distance" : 12000},{
...     "departureAirport": "LHR",
...     "arrivalAirport": "TXL",
...     "aircraft": "Airbus A320",
...     "distance": 950,
...     "intercontinental": false
...   })                               -            Here it will replace the document with the given data,But the nid remains unchanges






db.products.insertOne({name:"A pen",price:20,description:"A nice pen"}) - Insert a new document into a collection

db.flightData.insertMany([
			    {
				"departureAirport": "MUC",
				"arrivalAirport": "SFO",     
				"aircraft": "Airbus A380",     
				"distance": 12000,     
				"intercontinental": true   
			    },
			    {
			       "departureAirport": "LHR",     
			       "arrivalAirport": "TXL",     
			       "aircraft": "Airbus A320",     
			       "distance": 950,     
			       "intercontinental": false   
			    } 
			  ]);



db.flightData.deleteOne({"departureAirport" : "MUC"})    -  Deletes the firts documnet that matches the filter criteria 

db.flightData.deleteMany({"departureAirport" : "MUC"})    - Deletes all the documnets that matches the filter criteria,deletes all if filter condition is {}



db.flightData.updateOne({"distance" : 12000},{$set :{marker:"delete"}})    -   Updates the first document that matches the filter condition and set that specified field(marker) in that documnet as a new filed if its not existing or else it will update the value with "delete"





> db.flightData.updateMany({"distance" : 12000},{$set :{marker:"delete"}})  -- Updates all documents that matches the filter condition and set that specified field(marker) in that documnet as a new filed if its not existing or else it will update the value with "delete"


> db.flightData.updateMany({},{$set :{marker:"delete"}})  -- Updates all documents since the filter condition is {}, set that specified field(marker) in all documnets as a new filed if its not existing or else it will update the value with "delete"




















------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

